<!DOCTYPE html>
<!-- saved from url=(0065)http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<link rel="dns-prefetch" href="http://apps.bdimg.com/">
<meta http-equiv="X-UA-Compatible" content="IE=11,IE=10,IE=9,IE=8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=0, minimum-scale=1.0, maximum-scale=1.0">
<meta name="apple-mobile-web-app-title" content="码农场">
<meta http-equiv="Cache-Control" content="no-siteapp">
<title>EM算法及其推广-码农场</title>
<link rel="dns-prefetch" href="http://apps.bdimg.com/">
<link rel="dns-prefetch" href="http://s.w.org/">
		<script async="" src="./em-algorithm-and-its-generalization_files/analytics.js.下载"></script><script src="./em-algorithm-and-its-generalization_files/ca-pub-1152644711996772.js.下载"></script><script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/2.2.1\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/2.2.1\/svg\/","svgExt":".svg","source":{"concatemoji":"http:\/\/www.hankcs.com\/wp-includes\/js\/wp-emoji-release.min.js?ver=4.7.5"}};
			!function(a,b,c){function d(a){var b,c,d,e,f=String.fromCharCode;if(!k||!k.fillText)return!1;switch(k.clearRect(0,0,j.width,j.height),k.textBaseline="top",k.font="600 32px Arial",a){case"flag":return k.fillText(f(55356,56826,55356,56819),0,0),!(j.toDataURL().length<3e3)&&(k.clearRect(0,0,j.width,j.height),k.fillText(f(55356,57331,65039,8205,55356,57096),0,0),b=j.toDataURL(),k.clearRect(0,0,j.width,j.height),k.fillText(f(55356,57331,55356,57096),0,0),c=j.toDataURL(),b!==c);case"emoji4":return k.fillText(f(55357,56425,55356,57341,8205,55357,56507),0,0),d=j.toDataURL(),k.clearRect(0,0,j.width,j.height),k.fillText(f(55357,56425,55356,57341,55357,56507),0,0),e=j.toDataURL(),d!==e}return!1}function e(a){var c=b.createElement("script");c.src=a,c.defer=c.type="text/javascript",b.getElementsByTagName("head")[0].appendChild(c)}var f,g,h,i,j=b.createElement("canvas"),k=j.getContext&&j.getContext("2d");for(i=Array("flag","emoji4"),c.supports={everything:!0,everythingExceptFlag:!0},h=0;h<i.length;h++)c.supports[i[h]]=d(i[h]),c.supports.everything=c.supports.everything&&c.supports[i[h]],"flag"!==i[h]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[i[h]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(g=function(){c.readyCallback()},b.addEventListener?(b.addEventListener("DOMContentLoaded",g,!1),a.addEventListener("load",g,!1)):(a.attachEvent("onload",g),b.attachEvent("onreadystatechange",function(){"complete"===b.readyState&&c.readyCallback()})),f=c.source||{},f.concatemoji?e(f.concatemoji):f.wpemoji&&f.twemoji&&(e(f.twemoji),e(f.wpemoji)))}(window,document,window._wpemojiSettings);
		</script><script src="./em-algorithm-and-its-generalization_files/wp-emoji-release.min.js.下载" type="text/javascript" defer=""></script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
<link rel="stylesheet" id="_bootstrap-css" href="./em-algorithm-and-its-generalization_files/bootstrap.min.css" type="text/css" media="all">
<link rel="stylesheet" id="_fontawesome-css" href="./em-algorithm-and-its-generalization_files/font-awesome.min.css" type="text/css" media="all">
<link rel="stylesheet" id="_main-css" href="./em-algorithm-and-its-generalization_files/main.css" type="text/css" media="all">
<script type="text/javascript" src="./em-algorithm-and-its-generalization_files/jquery.min.js.下载"></script>
<link rel="https://api.w.org/" href="http://www.hankcs.com/wp-json/">
<link rel="prev" title="POJ 2975 Nim 题解《挑战程序设计竞赛》" href="http://www.hankcs.com/program/algorithm/poj-2975-nim.html">
<link rel="next" title="POJ 3537 Crosses and Crosses 题解《挑战程序设计竞赛》" href="http://www.hankcs.com/program/algorithm/poj-3537-crosses-and-crosses.html">
<link rel="canonical" href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html">
<link rel="shortlink" href="http://www.hankcs.com/?p=7368">
<link rel="alternate" type="application/json+oembed" href="http://www.hankcs.com/wp-json/oembed/1.0/embed?url=http%3A%2F%2Fwww.hankcs.com%2Fml%2Fem-algorithm-and-its-generalization.html">
<link rel="alternate" type="text/xml+oembed" href="http://www.hankcs.com/wp-json/oembed/1.0/embed?url=http%3A%2F%2Fwww.hankcs.com%2Fml%2Fem-algorithm-and-its-generalization.html&amp;format=xml">
<meta name="keywords" content="《统计学习方法》, 机器学习">
<meta name="description" content="本文是《统计学习方法》第九章的笔记，注解了原著的部分公式推导，补充了另一个经典的双硬币模型，并且注释了一份数十行的EM算法Python简明实现。如果概率模型的变量都是观测变量（数据中可见的变量），则可以直接用极大似然估计，或者用贝叶斯估计模型参数。但是，当模型含有隐变量（数据中看不到的变量）时，就不能简单地使用这些估计方法，而应该使用含有隐变量的概率模型参数">
<link rel="icon" href="http://www.hankcs.com/wp-content/uploads/2017/04/cropped-Hankcs_512-32x32.png" sizes="32x32">
<link rel="icon" href="http://www.hankcs.com/wp-content/uploads/2017/04/cropped-Hankcs_512-192x192.png" sizes="192x192">
<link rel="apple-touch-icon-precomposed" href="http://www.hankcs.com/wp-content/uploads/2017/04/cropped-Hankcs_512-180x180.png">
<meta name="msapplication-TileImage" content="http://www.hankcs.com/wp-content/uploads/2017/04/cropped-Hankcs_512-270x270.png">
<link rel="shortcut icon" href="http://www.hankcs.com/favicon.ico">
<!--[if lt IE 9]><script src="http://www.hankcs.com/wp-content/themes/dux/js/libs/html5.min.js"></script><![endif]-->
<!--
	generated 44918 seconds ago
	generated in 0.241 seconds
	served from batcache in 0.003 seconds
	expires in 41482 seconds
-->
<script async="" data-requirecontext="_" data-requiremodule="main" src="./em-algorithm-and-its-generalization_files/main.js.下载"></script><script src="./em-algorithm-and-its-generalization_files/share.js.下载"></script><script async="" data-requirecontext="_" data-requiremodule="lazyload" src="./em-algorithm-and-its-generalization_files/lazyload.min.js.下载"></script><script async="" data-requirecontext="_" data-requiremodule="prettyprint" src="./em-algorithm-and-its-generalization_files/prettyprint.js.下载"></script><script async="" data-requirecontext="_" data-requiremodule="signpop" src="./em-algorithm-and-its-generalization_files/signpop.js.下载"></script><script async="" data-requirecontext="_" data-requiremodule="comment" src="./em-algorithm-and-its-generalization_files/comment.js.下载"></script><link href="./em-algorithm-and-its-generalization_files/share.css" rel="styleSheet" type="text/css"></head>
<body class="post-template-default single single-post postid-7368 single-format-standard comment-open site-layout-2">
<header class="header">
	<div class="container">
		<div class="logo"><a href="http://www.hankcs.com/" title="码农场-自然语言处理、机器学习算法"><img src="./em-algorithm-and-its-generalization_files/logo.png">码农场</a></div>		<a href="http://www.hankcs.com/" title="码农场-自然语言处理、机器学习算法" class="brand">放牧代码和思想
<br>专注自然语言处理、机器学习算法</a>		<ul class="site-nav site-navbar">
			<li id="menu-item-1834" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1834"><a href="http://www.hankcs.com/program/cpp/">C++</a></li>
<li id="menu-item-1835" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1835"><a href="http://www.hankcs.com/program/java/">Java</a></li>
<li id="menu-item-5754" class="menu-item menu-item-type-taxonomy menu-item-object-category current-post-ancestor current-menu-parent current-post-parent menu-item-5754"><a href="http://www.hankcs.com/ml/">机器学习</a></li>
<li id="menu-item-2954" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-2954"><a href="http://www.hankcs.com/nlp/">NLP</a>
<ul class="sub-menu">
	<li id="menu-item-4344" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-4344"><a href="http://www.hankcs.com/nlp/corpus/">语料库</a></li>
	<li id="menu-item-4342" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-4342"><a href="http://www.hankcs.com/nlp/segment/">中文分词</a></li>
	<li id="menu-item-4343" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-4343"><a href="http://www.hankcs.com/nlp/ner/">命名实体识别</a></li>
	<li id="menu-item-4479" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-4479"><a href="http://www.hankcs.com/nlp/parsing/">句法分析</a></li>
</ul>
</li>
<li id="menu-item-1837" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1837"><a href="http://www.hankcs.com/program/algorithm/">算法</a></li>
<li id="menu-item-1839" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1839"><a href="http://www.hankcs.com/software/">软件</a></li>
<li id="menu-item-1838" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-1838"><a href="http://www.hankcs.com/nihongonote/">日语</a>
<ul class="sub-menu">
	<li id="menu-item-1860" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1860"><a href="http://www.hankcs.com/nihongonote/riyurimen/">日语入门</a></li>
	<li id="menu-item-1861" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1861"><a href="http://www.hankcs.com/nihongonote/listening/">日语听力</a></li>
	<li id="menu-item-1863" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-1863"><a href="http://www.hankcs.com/nihongonote/tekusuto/">日语综合教程</a>
	<ul class="sub-menu">
		<li id="menu-item-2190" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2190"><a href="http://www.hankcs.com/nihongonote/tekusuto/disance/">第三册</a></li>
		<li id="menu-item-2192" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2192"><a href="http://www.hankcs.com/nihongonote/tekusuto/daiyonnsatu/">第四册</a></li>
		<li id="menu-item-2191" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2191"><a href="http://www.hankcs.com/nihongonote/tekusuto/5/">第五册</a></li>
		<li id="menu-item-2702" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2702"><a href="http://www.hankcs.com/nihongonote/tekusuto/%e7%ac%ac%e5%85%ad%e5%86%8c/">第六册</a></li>
		<li id="menu-item-3604" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3604"><a href="http://www.hankcs.com/nihongonote/tekusuto/%e7%ac%ac%e4%b8%83%e5%86%8c/">第七册</a></li>
	</ul>
</li>
	<li id="menu-item-1859" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-1859"><a href="http://www.hankcs.com/nihongonote/fd2/">新编日语阅读文选</a>
	<ul class="sub-menu">
		<li id="menu-item-2187" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2187"><a href="http://www.hankcs.com/nihongonote/fd2/c1/">第一册</a></li>
		<li id="menu-item-2189" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2189"><a href="http://www.hankcs.com/nihongonote/fd2/c2/">第二册</a></li>
		<li id="menu-item-2188" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2188"><a href="http://www.hankcs.com/nihongonote/fd2/c3/">第三册</a></li>
	</ul>
</li>
	<li id="menu-item-1858" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1858"><a href="http://www.hankcs.com/nihongonote/jpkaiwa/">日语商务贸易会话</a></li>
</ul>
</li>
<li id="menu-item-1843" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1843"><a href="http://www.hankcs.com/about/">关于</a></li>
							<li class="navto-search"><a href="javascript:;" class="search-show active"><i class="fa fa-search"></i></a></li>
					</ul>
		<div class="topbar">
			<ul class="site-nav topmenu">
				<li id="menu-item-5755" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-5755"><a href="http://www.hankcs.com/about/#comments"><i class="fa fa-comment"></i> 留言板</a></li>
				<li><a target="_blank" rel="external nofollow" href="https://github.com/hankcs"><i class="fa fa-github-alt"></i> GitHub</a></li>                                <li><a target="_blank" rel="external nofollow" href="http://weibo.com/hankcs"><i class="fa fa-weibo"></i> 微博</a></li>                                <li><a target="_blank" rel="external nofollow" href="https://twitter.com/hankcs"><i class="fa fa-twitter"></i> Twitter</a></li>                                <li><a target="_blank" href="http://www.hankcs.com/feed"><i class="fa fa-rss"></i> RSS订阅</a></li>			</ul>
							&nbsp; &nbsp; <i class="fa fa-bullhorn url"></i> <a href="http://www.hankcs.com/about/" target="_blank">我是一个浪人，这里是我的个人博客。我没有师门，都是瞎写的，不用太认真，也不要过于期待。</a><a href="http://www.hankcs.com/about/#comments" target="_blank" textvalue="">留言板</a>。					</div>
		<i class="fa fa-bars m-icon-nav"></i>
	</div>
</header>
<div class="site-search">
	<div class="container">
		<form method="get" class="site-search-form" action="http://www.hankcs.com/"><input class="search-input" name="s" type="text" placeholder="输入关键字" value=""><button class="search-btn" type="submit"><i class="fa fa-search"></i></button></form>	</div>
</div><section class="container">
	<div class="content-wrap">
	<div class="content">
				<header class="article-header">
			<h1 class="article-title"><a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html">EM算法及其推广</a></h1>
			<div class="article-meta">
				<span class="item">
					<a href="http://www.hankcs.com/">码农场</a> <small>&gt;</small> <a href="http://www.hankcs.com/ml/">机器学习</a><span class="muted"></span>				</span>
				<span class="item">2016-05-30</span>
																<span class="item post-views">阅读(1508)</span>				<span class="item"><a class="pc" href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#comments">评论(8)</a></span>				<span class="item"></span>
			</div>
		</header>
		<article class="article-content">
			<div class="asb asb-post asb-post-01"><script async="" src="./em-algorithm-and-its-generalization_files/adsbygoogle.js.下载"></script>
<!-- 文章页 - 页面标题下 728 90 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-1152644711996772" data-ad-slot="5413029241" data-adsbygoogle-status="done"><ins id="aswift_0_expand" style="display:inline-table;border:none;height:90px;margin:0;padding:0;position:relative;visibility:visible;width:728px;background-color:transparent"><ins id="aswift_0_anchor" style="display:block;border:none;height:90px;margin:0;padding:0;position:relative;visibility:visible;width:728px;background-color:transparent"><iframe width="728" height="90" frameborder="0" marginwidth="0" marginheight="0" vspace="0" hspace="0" allowtransparency="true" scrolling="no" allowfullscreen="true" onload="var i=this.id,s=window.google_iframe_oncopy,H=s&amp;&amp;s.handlers,h=H&amp;&amp;H[i],w=this.contentWindow,d;try{d=w.document}catch(e){}if(h&amp;&amp;d&amp;&amp;(!d.body||!d.body.firstChild)){if(h.call){setTimeout(h,0)}else if(h.match){try{h=s.upd(h,i)}catch(e){}w.location.replace(h)}}" id="aswift_0" name="aswift_0" style="left:0;position:absolute;top:0;width:728px;height:90px;" src="./em-algorithm-and-its-generalization_files/saved_resource.html"></iframe></ins></ins></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></div>			<div class="post_nav" style="width: 0px;"><div class="post_nav_side" style="height: 100%;"><div class="post_nav_top"><p>目录</p></div><div class="post_nav_bottom"></div><span class="post_nav_close icon-remove" title="关闭目录" style="opacity: 0; display: none;"><i class="fa fa-times"></i></span></div><ul class="post_nav_content"><li class="h2_nav"><a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#h2-0">EM算法的引入</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#h3-1">三硬币模型</a><i class="post_nav_dot"></i></li>
<li class="h3_nav active"><a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#h3-2">EM算法简单理解</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#h3-3">EM算法的标准定义</a><i class="post_nav_dot"></i></li>
<li class="h2_nav"><a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#h2-4">EM算法的导出</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#h3-5">EM算法的收敛性</a><i class="post_nav_dot"></i></li>
<li class="h2_nav"><a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#h2-6">EM算法的简明实现</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#h3-7">双硬币模型</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#h3-8">建立数据集</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#h3-9">初始化</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#h3-10">第一个迭代的E步</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#h3-11">第一个迭代的M步</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#h3-12">EM算法主循环</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#h3-13">调用</a><i class="post_nav_dot"></i></li>
<li class="h2_nav"><a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#h2-14">Reference</a><i class="post_nav_dot"></i></li>
</ul></div><p style="text-indent: 2em;">本文是<a href="http://www.hankcs.com/tag/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B/" target="_blank">《统计学习方法》</a>第九章的笔记，注解了原著的部分公式推导，补充了另一个经典的双硬币模型，并且注释了一份数十行的EM算法Python简明实现。</p>
<p style="text-indent: 2em;">如果概率模型的变量都是观测变量（数据中可见的变量），则可以直接用极大似然估计，或者用贝叶斯估计模型参数。但是，当模型含有隐变量（数据中看不到的变量）时，就不能简单地使用这些估计方法，而应该使用含有隐变量的概率模型参数的极大似然估计法，也即EM算法。<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4b95mzejvj20p60t0qab.jpg" title="EM算法.png" alt="EM算法.png" style="text-align: center; white-space: normal; text-indent: 32px; width: 0px; height: 0px;" width="0" height="0" border="0" vspace="0" data-tag="bdshare"></p>
<h2 id="h2-0">EM算法的引入</h2>
<p style="text-indent: 2em;">引入EM算法有两个常见的例子，一个是三硬币模型，一个是双硬币模型。<a href="http://www.hankcs.com/tag/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B/" target="_blank" style="text-indent: 32px; white-space: normal;">《统计学习方法》</a>介绍的是三硬币模型，本文引述该模型后，再补充双硬币模型。</p>
<h3 id="h3-1">三硬币模型<br></h3>
<p style="text-indent: 2em;">有ABC三枚硬币，单次投掷出现正面的概率分别为π、p、q。利用这三枚硬币进行如下实验：</p>
<p style="text-indent: 2em;">1、第一次先投掷A，若出现正面则投掷B，否则投掷C</p>
<p style="text-indent: 2em;">2、记录第二次投掷的硬币出现的结果，正面记作1，反面记作0</p>
<p style="text-indent: 2em;">独立重复1和2十次，产生如下观测结果：</p>
<p style="text-indent: 2em;">1 1 0 1 0 0 1 0 1 1</p>
<p style="text-indent: 2em;">假设只能观测到掷硬币的最终结果，无法观测第一次投掷的是哪一枚硬币，求<span style="text-indent: 32px;">π、p、q，即三硬币模型的参数。</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">记模型参数为<span style="text-indent: 32px;"><span class="mi" id="MathJax-Span-19" style="box-sizing: border-box; color: rgb(102, 102, 102); transition: none; display: inline; position: static; border: 0px; padding: 0px; margin: 0px; vertical-align: 0px; font-size: 18px; font-family: STIXGeneral-Italic;">θ<span style="position: static; padding: 0px; margin: 0px; vertical-align: 0px; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-20" style="box-sizing: border-box; color: rgb(102, 102, 102); transition: none; display: inline; position: static; border: 0px; padding: 0px 0px 0px 0.336em; margin: 0px; vertical-align: 0px; font-size: 18px; font-family: STIXGeneral-Regular;">=(</span><span class="mi" id="MathJax-Span-22" style="box-sizing: border-box; color: rgb(102, 102, 102); transition: none; display: inline; position: static; border: 0px; padding: 0px; margin: 0px; vertical-align: 0px; font-size: 18px; font-family: STIXGeneral-Italic;">π<span style="position: static; padding: 0px; margin: 0px; vertical-align: 0px; overflow: hidden; height: 1px; width: 0.058em;"></span></span><span class="mo" id="MathJax-Span-23" style="box-sizing: border-box; color: rgb(102, 102, 102); transition: none; display: inline; position: static; border: 0px; padding: 0px; margin: 0px; vertical-align: 0px; font-size: 18px; font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-24" style="box-sizing: border-box; color: rgb(102, 102, 102); transition: none; display: inline; position: static; border: 0px; padding: 0px 0px 0px 0.169em; margin: 0px; vertical-align: 0px; font-size: 18px; font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-25" style="box-sizing: border-box; color: rgb(102, 102, 102); transition: none; display: inline; position: static; border: 0px; padding: 0px; margin: 0px; vertical-align: 0px; font-size: 18px; font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-26" style="box-sizing: border-box; color: rgb(102, 102, 102); transition: none; display: inline; position: static; border: 0px; padding: 0px 0px 0px 0.169em; margin: 0px; vertical-align: 0px; font-size: 18px; font-family: STIXGeneral-Italic;">q</span><span class="mo" id="MathJax-Span-27" style="box-sizing: border-box; color: rgb(102, 102, 102); transition: none; display: inline; position: static; border: 0px; padding: 0px; margin: 0px; vertical-align: 0px; font-size: 18px; font-family: STIXGeneral-Regular;">)</span></span>，无法观测的第一次投掷的硬币为随机变量z，可以观测的第二次投掷的硬币为随机变量y，则观测数据的似然函数为：</span></p>
<p style="text-align:center"><span style="text-indent: 32px;"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4c5zjsgchj209101lt8l.jpg" title="屏幕快照 2016-05-29 下午12.55.28.png" alt="屏幕快照 2016-05-29 下午12.55.28.png" width="182" height="32" border="0" vspace="0" style="width: 182px; height: 32px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;">这是个一目了然的式子，两个事件，第一个事件选出那枚看不到的硬币，第二个事件利用这枚硬币进行一次投掷。利用硬币结果只可能是0或1这个特性，可以将这个式子展开为：</p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ca9xi34yj20ek01wdfs.jpg" title="屏幕快照 2016-05-29 下午3.23.13.png" alt="屏幕快照 2016-05-29 下午3.23.13.png" width="309" height="40" border="0" vspace="0" style="width: 309px; height: 40px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">y的观测序列给定了，怎么找出一个模型参数，使得这个序列的概率（似然函数的值）最大呢，也就是求模型参数的极大似然估计：</p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4caedtrrij206n01cweb.jpg" title="屏幕快照 2016-05-29 下午3.27.34.png" alt="屏幕快照 2016-05-29 下午3.27.34.png" width="159" height="32" border="0" vspace="0" style="width: 159px; height: 32px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">这个问题我认为是个NP问题，一方面，给定模型参数，可以在多项式时间求出似然函数的值，然而模型参数的组合是无穷的，谁也不知道它是否是最优的。</p>
<h3 id="h3-2">EM算法简单理解</h3>
<p style="text-indent: 2em;">EM算法是求解这个问题的一种迭代算法（我认为并非精确算法，而是近似算法），它有3步：</p>
<p style="text-indent: 2em;">初始化：选取模型参数的初值：<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cajl80ezj205y012mwz.jpg" title="屏幕快照 2016-05-29 下午3.33.10.png" alt="屏幕快照 2016-05-29 下午3.33.10.png" width="113" height="20" border="0" vspace="0" style="width: 113px; height: 20px;" data-tag="bdshare">，循环如下两步迭代</p>
<p style="text-indent: 2em;">E步：计算在当前迭代的模型参数下，观测数据y来自硬币B的概率：</p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4camxgat5j20hj02k74e.jpg" title="屏幕快照 2016-05-29 下午3.36.22.png" alt="屏幕快照 2016-05-29 下午3.36.22.png" width="439" height="64" border="0" vspace="0" style="width: 439px; height: 64px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">这个式子也是一目了然的，分子代表选定B并进行一次投掷试验，分母代表选定B或C并进行一次投掷试验，两个一除就得到试验结果来自B的概率。</p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">M步：估算下一个迭代的新的模型估算值：</span></p>
<p style="text-align:center"><span style="text-indent: 32px;"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4caolevyyj206h0alaa9.jpg" title="屏幕快照 2016-05-29 下午3.37.46.png" alt="屏幕快照 2016-05-29 下午3.37.46.png" width="157" height="256" border="0" vspace="0" style="width: 157px; height: 256px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">这个也好说，把这n个{试验结果来自B的概率}求和得到期望，平均后，得到B出正面的似然估计，同理有p和q。</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">重复迭代，直到收敛为止。</span></p>
<p style="text-indent: 2em;">这个模型中，观测数据Y和隐数据Z组合在一起称为完全数据，单独的观测数据Y称为不完全数据。在隐数据未知的情况，无法直接估计Y的概率分布。但当模型概率给定时，就可以估计Y的条件概率分布了。</p>
<p style="text-indent: 2em;">Y的条件概率分布估计出来后有什么用呢？利用Y的条件概率分布，又可以更新模型参数……那问题来了，为什么要这么做，这么做能否找到最优解，原理是什么？</p>
<p style="text-indent: 2em;">带着这些问题啃书本稍微有趣一些，在探索这个问题之前，有必要规范地描述EM算法，并引入一些正规的符号和定义：</p>
<h3 id="h3-3">EM算法的标准定义</h3>
<p style="text-indent: 2em;">输入：观测变量数据Y，隐变量数据Z,联合分布<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cdb1w5obj203100y742.jpg" title="屏幕快照 2016-05-29 下午5.08.31.png" alt="屏幕快照 2016-05-29 下午5.08.31.png" width="64" height="20" border="0" vspace="0" style="width: 64px; height: 20px;" data-tag="bdshare">，条件分布<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cdc5eqcbj203100y742.jpg" title="屏幕快照 2016-05-29 下午5.09.23.png" alt="屏幕快照 2016-05-29 下午5.09.23.png" width="64" height="20" border="0" vspace="0" style="width: 64px; height: 20px;" data-tag="bdshare">；</p>
<p style="text-indent: 2em;">输出：模型参数<span style="color: rgb(102, 102, 102); font-family: STIXGeneral-Italic; font-size: 18px; text-indent: 32px;">θ</span>。</p>
<p style="text-indent: 2em;">(1)&nbsp; 选择参数的初值<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cdt287xpj20140120or.jpg" title="屏幕快照 2016-05-29 下午5.26.08.png" alt="屏幕快照 2016-05-29 下午5.26.08.png" width="26" height="25" border="0" vspace="0" style="width: 26px; height: 25px;" data-tag="bdshare">,开始迭代；</p>
<p style="text-indent: 2em;">(2) &nbsp;E步：记<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cdh9g7svj201100t0rd.jpg" title="屏幕快照 2016-05-29 下午5.11.10.png" alt="屏幕快照 2016-05-29 下午5.11.10.png" width="26" height="20" border="0" vspace="0" style="width: 26px; height: 20px;" data-tag="bdshare">为第i次迭代参数<span style="color: rgb(102, 102, 102); font-family: STIXGeneral-Italic; font-size: 18px; text-indent: 32px;">θ</span>的估计值，在第i+1次迭代的E步，计算</p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cdy9plpkj20bn02n74c.jpg" title="屏幕快照 2016-05-29 下午5.31.04.png" alt="屏幕快照 2016-05-29 下午5.31.04.png" width="282" height="64" border="0" vspace="0" style="width: 282px; height: 64px;" data-tag="bdshare"></p>
<p>&nbsp;</p>
<p style="text-indent: 2em;">这里，<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cdz112l2j203k00ydfm.jpg" title="屏幕快照 2016-05-29 下午5.31.50.png" alt="屏幕快照 2016-05-29 下午5.31.50.png" width="75" height="20" border="0" vspace="0" style="width: 75px; height: 20px;" data-tag="bdshare">是在给定观测数据Y和当前的参数估计<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cdzpvkyrj20110100or.jpg" title="屏幕快照 2016-05-29 下午5.32.32.png" alt="屏幕快照 2016-05-29 下午5.32.32.png" width="21" height="20" border="0" vspace="0" style="width: 21px; height: 20px;" data-tag="bdshare">下隐变量数据z的条件概率分布；</p>
<p style="text-indent: 2em;">(3) M步：求使<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ce0cis34j202o0173ya.jpg" title="屏幕快照 2016-05-29 下午5.33.09.png" alt="屏幕快照 2016-05-29 下午5.33.09.png" width="56" height="25" border="0" vspace="0" style="width: 56px; height: 25px;" data-tag="bdshare">极大化的<span style="color: rgb(102, 102, 102); font-family: STIXGeneral-Italic; font-size: 18px; text-indent: 32px;">θ</span>，确定第i+1次迭代的参数的估计值<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ce1j13clj201f00v0sh.jpg" title="屏幕快照 2016-05-29 下午5.34.06.png" alt="屏幕快照 2016-05-29 下午5.34.06.png" width="33" height="20" border="0" vspace="0" style="width: 33px; height: 20px;" data-tag="bdshare"></p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ce2ht1emj2073018glg.jpg" title="屏幕快照 2016-05-29 下午5.35.08.png" alt="屏幕快照 2016-05-29 下午5.35.08.png" width="185" height="32" border="0" vspace="0" style="width: 185px; height: 32px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">(4）重复第(2)步和第(3)步，直到收敛。</p>
<p style="text-indent: 2em;">式<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cdy9plpkj20bn02n74c.jpg" title="屏幕快照 2016-05-29 下午5.31.04.png" alt="屏幕快照 2016-05-29 下午5.31.04.png" width="282" height="64" border="0" vspace="0" style="text-align: center; white-space: normal; width: 282px; height: 64px;" data-tag="bdshare">的函数<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ce0cis34j202o0173ya.jpg" title="屏幕快照 2016-05-29 下午5.33.09.png" alt="屏幕快照 2016-05-29 下午5.33.09.png" width="56" height="25" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 56px; height: 25px;" data-tag="bdshare">是EM算法的核心，称为Q函数（Q function)。</p>
<p style="text-indent: 2em;"><strong>定义</strong>(Q函数）完全数据的对数似然函数<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ce69smbkj203z014jr6.jpg" title="屏幕快照 2016-05-29 下午5.38.46.png" alt="屏幕快照 2016-05-29 下午5.38.46.png" width="71" height="20" border="0" vspace="0" style="width: 71px; height: 20px;" data-tag="bdshare">关于在给定观测数据Y和当前参数<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cdh9g7svj201100t0rd.jpg" title="屏幕快照 2016-05-29 下午5.11.10.png" alt="屏幕快照 2016-05-29 下午5.11.10.png" width="26" height="20" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 26px; height: 20px;" data-tag="bdshare">下对未观测数据Z的条件概率分布<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ce7p1x8vj203l018gle.jpg" title="屏幕快照 2016-05-29 下午5.40.08.png" alt="屏幕快照 2016-05-29 下午5.40.08.png" width="80" height="27" border="0" vspace="0" style="width: 80px; height: 27px;" data-tag="bdshare">的期望称为Q函数，即</p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ce99es08j20an011gli.jpg" title="屏幕快照 2016-05-29 下午5.41.00.png" alt="屏幕快照 2016-05-29 下午5.41.00.png" width="259" height="25" border="0" vspace="0" style="width: 259px; height: 25px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">下面关于EM算法作几点说明：</p>
<p style="text-indent: 2em;">步骤（1)参数的初值可以任意选择，但需注意EM算法对初值是敏感的。</p>
<p style="text-indent: 2em;">步骤(2)E步求<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ce0cis34j202o0173ya.jpg" title="屏幕快照 2016-05-29 下午5.33.09.png" alt="屏幕快照 2016-05-29 下午5.33.09.png" width="56" height="25" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 56px; height: 25px;" data-tag="bdshare">。Q函数式中Z是未观测数据，Y是观测数据。注意，<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ce0cis34j202o0173ya.jpg" title="屏幕快照 2016-05-29 下午5.33.09.png" alt="屏幕快照 2016-05-29 下午5.33.09.png" width="56" height="25" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 56px; height: 25px;" data-tag="bdshare">的第1个变元表示要极大化的参数，第2个变元表示参数的当前估计值。每次迭代实际在求Q函数及其极大。</p>
<p style="text-indent: 2em;">步骤(3)M步求<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4dontn3ajj205001yt8j.jpg" title="屏幕快照 2016-05-30 下午8.27.14.png" alt="屏幕快照 2016-05-30 下午8.27.14.png" width="57" height="22" border="0" vspace="0" style="width: 57px; height: 22px;" data-tag="bdshare">的极大化，得到<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4doo2k9g9j202s01wt8h.jpg" title="屏幕快照 2016-05-30 下午8.27.33.png" alt="屏幕快照 2016-05-30 下午8.27.33.png" width="32" height="22" border="0" vspace="0" style="width: 32px; height: 22px;" data-tag="bdshare">，完成一次迭代<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4doocibbqj206c01ua9v.jpg" title="屏幕快照 2016-05-30 下午8.27.47.png" alt="屏幕快照 2016-05-30 下午8.27.47.png" width="76" height="22" border="0" vspace="0" style="width: 76px; height: 22px;" data-tag="bdshare">。后面将证明每次迭代使似然函数增大或达到局部极值。</p>
<p style="text-indent: 2em;">步骤(4)给出停止迭代的条件，一般是对较小的正数<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cecj8k7hj201h00x3y9.jpg" title="屏幕快照 2016-05-29 下午5.44.47.png" alt="屏幕快照 2016-05-29 下午5.44.47.png" width="40" height="25" border="0" vspace="0" style="width: 40px; height: 25px;" data-tag="bdshare">,若满足</p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cedcbuc7j20gj01ct8o.jpg" title="屏幕快照 2016-05-29 下午5.45.27.png" alt="屏幕快照 2016-05-29 下午5.45.27.png" width="335" height="27" border="0" vspace="0" style="width: 335px; height: 27px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">则停止迭代。</p>
<h2 id="h2-4">EM算法的导出<br></h2>
<p style="text-indent: 2em;">看完了冗长的标准定义，认识了一点也不Q的Q函数，终于可以了解EM算法是怎么来的了。</p>
<p style="text-indent: 2em;">寻找模型参数的目标（或称标准）是找到的参数使观测数据的似然函数最大，一般用对数似然函数取代似然函数，这样可以把连乘变为累加，方便优化，也就是极大化</p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cerwrpddj20as03l74d.jpg" title="屏幕快照 2016-05-29 下午5.59.36.png" alt="屏幕快照 2016-05-29 下午5.59.36.png" width="265" height="88" border="0" vspace="0" style="width: 265px; height: 88px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">这个式子里面有未知的隐变量Y，无法直接优化。</p>
<p style="text-indent: 2em;">但是如同在“EM算法简单理解”中看到那样，给定模型参数，就可以估计Y的条件概率（后验概率，已经有Z这个结果，求原因Y的概率）。所以我们就挑一个模型参数的初值，也就是EM算法的第1步。</p>
<p style="text-indent: 2em;">有了初值，就可以代入似然函数得到一个值，但这个值不一定是最大的，我们想要更大，所以需要调整参数，这也是EM算法为什么要迭代的原因。</p>
<p style="text-indent: 2em;">事实上，EM算法是通过迭代逐步近似极大化似然函数的。假设在第i次迭代后<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cf4tp115j200n00x0i8.jpg" title="屏幕快照 2016-05-29 下午6.12.05.png" alt="屏幕快照 2016-05-29 下午6.12.05.png" width="14" height="20" border="0" vspace="0" style="width: 14px; height: 20px;" data-tag="bdshare">的估计值是<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cf5ahxv7j201000x0pt.jpg" title="屏幕快照 2016-05-29 下午6.12.31.png" alt="屏幕快照 2016-05-29 下午6.12.31.png" width="24" height="22" border="0" vspace="0" style="width: 24px; height: 22px;" data-tag="bdshare">。我们希望新估计值<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cf4tp115j200n00x0i8.jpg" title="屏幕快照 2016-05-29 下午6.12.05.png" alt="屏幕快照 2016-05-29 下午6.12.05.png" width="14" height="20" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 14px; height: 20px;" data-tag="bdshare">能使<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cf5sstzhj201h014741.jpg" title="屏幕快照 2016-05-29 下午6.06.06.png" alt="屏幕快照 2016-05-29 下午6.06.06.png" width="29" height="22" border="0" vspace="0" style="width: 29px; height: 22px;" data-tag="bdshare">增加，即<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cf6dwj8fj203y00zgle.jpg" title="屏幕快照 2016-05-29 下午6.13.28.png" alt="屏幕快照 2016-05-29 下午6.13.28.png" width="89" height="22" border="0" vspace="0" style="width: 89px; height: 22px;" data-tag="bdshare">,并逐步达到极大值。为此，考虑两者的差：</p>
<p style="text-align: center;"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cf6y2r3qj20h70283yj.jpg" title="屏幕快照 2016-05-29 下午6.14.05.png" alt="屏幕快照 2016-05-29 下午6.14.05.png" width="387" height="50" border="0" vspace="0" style="width: 387px; height: 50px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">利用Jensen不等式（Jensen inequality)</p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ckprg58wj20fc052q37.jpg" title="屏幕快照 2016-05-29 下午9.23.30.png" alt="屏幕快照 2016-05-29 下午9.23.30.png" width="233" height="77" border="0" vspace="0" style="width: 233px; height: 77px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">得到其下界：</p>
<p style="text-align:center"><span style="text-indent: 32px;"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ck9nje38j21520c8ac9.jpg" title="屏幕快照 2016-05-29 下午9.09.35.png" alt="屏幕快照 2016-05-29 下午9.09.35.png" width="430" height="128" border="0" vspace="0" style="width: 430px; height: 128px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">式子有点长，而且用了些技巧，慢慢看。首先第一行的<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ckvyfphej206y02cq2s.jpg" title="屏幕快照 2016-05-29 下午9.31.06.png" alt="屏幕快照 2016-05-29 下午9.31.06.png" width="74" height="25" border="0" vspace="0" style="width: 74px; height: 25px;" data-tag="bdshare">是人为加上去的，先乘以这一项再除以这一项得到的依然是<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ckj8prmej202w020a9u.jpg" title="屏幕快照 2016-05-29 下午9.18.56.png" alt="屏幕快照 2016-05-29 下午9.18.56.png" width="32" height="22" border="0" vspace="0" style="width: 32px; height: 22px;" data-tag="bdshare">，然后第二行就利用了琴生不等式，将log运算符移入求和项中。但<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ckvyfphej206y02cq2s.jpg" title="屏幕快照 2016-05-29 下午9.31.06.png" alt="屏幕快照 2016-05-29 下午9.31.06.png" width="74" height="25" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 74px; height: 25px;" data-tag="bdshare">为何变成了<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ckcl35q5j206y02m3yd.jpg" title="屏幕快照 2016-05-29 下午9.12.24.png" alt="屏幕快照 2016-05-29 下午9.12.24.png" width="75" height="28" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 75px; height: 28px;" data-tag="bdshare">呢？我认为这是李航博士的笔误，第一行就应该分子分母同时乘以<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ckcl35q5j206y02m3yd.jpg" title="屏幕快照 2016-05-29 下午9.12.24.png" alt="屏幕快照 2016-05-29 下午9.12.24.png" width="75" height="28" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 75px; height: 28px;" data-tag="bdshare">的。参考普林斯顿大学的讲义《</span><img src="./em-algorithm-and-its-generalization_files/icon_pdf.gif" style="line-height: 16px; vertical-align: middle; margin-right: 2px;" data-tag="bdshare"><a href="http://www.hankcs.com/wp-content/uploads/2016/05/COS%20424-%20Interacting%20with%20Data.pdf" title="COS 424- Interacting with Data.pdf" style="line-height: 16px; font-size: 12px; color: rgb(0, 102, 204);">COS 424- Interacting with Data.pdf</a><span style="line-height: 16px;">》：</span></p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cl9tgc6aj20xc0gmq9n.jpg" title="屏幕快照 2016-05-29 下午9.44.19.png" alt="屏幕快照 2016-05-29 下午9.44.19.png" width="763" height="380" border="0" vspace="0" style="width: 763px; height: 380px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">应该乘以Z的概率分布，也就是<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ckcl35q5j206y02m3yd.jpg" title="屏幕快照 2016-05-29 下午9.12.24.png" alt="屏幕快照 2016-05-29 下午9.12.24.png" width="75" height="28" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 75px; height: 28px;" data-tag="bdshare">。</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">然后第三行的变换其实很简单，将log拆成log乘以<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ckcl35q5j206y02m3yd.jpg" title="屏幕快照 2016-05-29 下午9.12.24.png" alt="屏幕快照 2016-05-29 下午9.12.24.png" width="75" height="28" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 75px; height: 28px;" data-tag="bdshare">对Z求和的形式，再将每一项中的-log跟前一个求和中的每一项中的log合并，log的减法变成除法就得到最终结果了。</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">好了，言归正传，将<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4clt6d7bbj203y01w0sj.jpg" title="屏幕快照 2016-05-29 下午10.02.38.png" alt="屏幕快照 2016-05-29 下午10.02.38.png" width="46" height="22" border="0" vspace="0" style="width: 46px; height: 22px;" data-tag="bdshare">移到等号右边去，得到一个函数，取个名字：<br></span></p>
<p style="text-align:center"><span style="text-indent: 32px;"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cmg1upauj2100048js1.jpg" title="屏幕快照 2016-05-29 下午10.15.18.png" alt="屏幕快照 2016-05-29 下午10.15.18.png" width="375" height="44" border="0" vspace="0" style="width: 375px; height: 44px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">那么就有</span></p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cmiiwzfvj209u028t8m.jpg" title="屏幕快照 2016-05-29 下午10.27.20.png" alt="屏幕快照 2016-05-29 下午10.27.20.png" width="102" height="23" border="0" vspace="0" style="width: 102px; height: 23px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"></span>得到了<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ckj8prmej202w020a9u.jpg" title="屏幕快照 2016-05-29 下午9.18.56.png" alt="屏幕快照 2016-05-29 下午9.18.56.png" width="32" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 32px; height: 22px;" data-tag="bdshare">的一个下界，如果将<span style="color: rgb(102, 102, 102); font-family: STIXGeneral-Italic; font-size: 18px; text-indent: 32px;">θ&nbsp;</span>=&nbsp;<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cmq7yvyjj201u022jr5.jpg" title="屏幕快照 2016-05-29 下午10.34.46.png" alt="屏幕快照 2016-05-29 下午10.34.46.png" width="20" height="22" border="0" vspace="0" style="width: 20px; height: 22px;" data-tag="bdshare">，代入<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cmg1upauj2100048js1.jpg" title="屏幕快照 2016-05-29 下午10.15.18.png" alt="屏幕快照 2016-05-29 下午10.15.18.png" width="375" height="44" border="0" vspace="0" style="text-align: center; text-indent: 32px; white-space: normal; width: 375px; height: 44px;" data-tag="bdshare">，我们会发现，在模型参数一致的情况下，log项中的分子分母都是同一个(Y,Z)的联合分布，所以分子分母相等，后面这个求和项等于0，直接得到：</p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d7m2h8g1j20ca02kjrc.jpg" title="屏幕快照 2016-05-30 上午10.37.19.png" alt="屏幕快照 2016-05-30 上午10.37.19.png" width="120" height="25" border="0" vspace="0" style="width: 120px; height: 25px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">说明<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cmiiwzfvj209u028t8m.jpg" title="屏幕快照 2016-05-29 下午10.27.20.png" alt="屏幕快照 2016-05-29 下午10.27.20.png" width="102" height="23" border="0" vspace="0" style="text-align: center; white-space: normal; width: 102px; height: 23px;" data-tag="bdshare">等号成立的条件是<span style="text-indent: 32px; color: rgb(102, 102, 102); font-family: STIXGeneral-Italic; font-size: 18px;">θ&nbsp;</span><span style="text-indent: 32px;">=&nbsp;</span><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cmq7yvyjj201u022jr5.jpg" title="屏幕快照 2016-05-29 下午10.34.46.png" alt="屏幕快照 2016-05-29 下午10.34.46.png" width="20" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 20px; height: 22px;" data-tag="bdshare">，换句话说只要<span style="text-indent: 32px; color: rgb(102, 102, 102); font-family: STIXGeneral-Italic; font-size: 18px;">θ&nbsp;</span><span style="text-indent: 32px;">不等于</span><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4cmq7yvyjj201u022jr5.jpg" title="屏幕快照 2016-05-29 下午10.34.46.png" alt="屏幕快照 2016-05-29 下午10.34.46.png" width="20" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 20px; height: 22px;" data-tag="bdshare">，就一定能让<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ckj8prmej202w020a9u.jpg" title="屏幕快照 2016-05-29 下午9.18.56.png" alt="屏幕快照 2016-05-29 下午9.18.56.png" width="32" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 32px; height: 22px;" data-tag="bdshare">变大一点。换句话说，任何能使<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d7qvba8aj205i028glg.jpg" title="屏幕快照 2016-05-30 上午10.42.00.png" alt="屏幕快照 2016-05-30 上午10.42.00.png" width="54" height="22" border="0" vspace="0" style="width: 54px; height: 22px;" data-tag="bdshare">增大的<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d7roeiiaj201k01y3y9.jpg" title="屏幕快照 2016-05-30 上午10.42.48.png" alt="屏幕快照 2016-05-30 上午10.42.48.png" width="18" height="22" border="0" vspace="0" style="width: 18px; height: 22px;" data-tag="bdshare">，都能使<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ckj8prmej202w020a9u.jpg" title="屏幕快照 2016-05-29 下午9.18.56.png" alt="屏幕快照 2016-05-29 下午9.18.56.png" width="32" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 32px; height: 22px;" data-tag="bdshare">增大（通过优化对数似然函数的下界来间接优化它）。为了尽可能显著地增大<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4ckj8prmej202w020a9u.jpg" title="屏幕快照 2016-05-29 下午9.18.56.png" alt="屏幕快照 2016-05-29 下午9.18.56.png" width="32" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 32px; height: 22px;" data-tag="bdshare">，需要选择<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d7u94577j203801u3ya.jpg" title="屏幕快照 2016-05-30 上午10.45.17.png" alt="屏幕快照 2016-05-30 上午10.45.17.png" width="39" height="22" border="0" vspace="0" style="width: 39px; height: 22px;" data-tag="bdshare">使得<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d7qvba8aj205i028glg.jpg" title="屏幕快照 2016-05-30 上午10.42.00.png" alt="屏幕快照 2016-05-30 上午10.42.00.png" width="54" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 54px; height: 22px;" data-tag="bdshare">达到极大：</span></p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d7v2qu5aj20f202saa2.jpg" title="屏幕快照 2016-05-30 上午10.46.02.png" alt="屏幕快照 2016-05-30 上午10.46.02.png" width="173" height="32" border="0" vspace="0" style="width: 173px; height: 32px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"></span>现在来推导<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d7u94577j203801u3ya.jpg" title="屏幕快照 2016-05-30 上午10.45.17.png" alt="屏幕快照 2016-05-30 上午10.45.17.png" width="39" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 39px; height: 22px;" data-tag="bdshare">的表达式，去掉上式中所有与<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d7roeiiaj201k01y3y9.jpg" title="屏幕快照 2016-05-30 上午10.42.48.png" alt="屏幕快照 2016-05-30 上午10.42.48.png" width="18" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 18px; height: 22px;" data-tag="bdshare">无关的常数项，有：</p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d7wxbhdqj215m0fg0v5.jpg" title="屏幕快照 2016-05-30 上午10.47.47.png" alt="屏幕快照 2016-05-30 上午10.47.47.png" width="404" height="150" border="0" vspace="0" style="width: 404px; height: 150px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">推到最后发现<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d7u94577j203801u3ya.jpg" title="屏幕快照 2016-05-30 上午10.45.17.png" alt="屏幕快照 2016-05-30 上午10.45.17.png" width="39" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 39px; height: 22px;" data-tag="bdshare">等于最大化Q函数时的参数，也就是<span style="text-indent: 32px;">M步执行的那样。</span></span></p>
<p style="text-indent: 2em;">EM算法是通过不断求解下界的极大化逼近求解对数似然函数极大化的算法。如图：</p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d881g25tj20sk0kedh7.jpg" title="屏幕快照 2016-05-30 上午10.58.15.png" alt="屏幕快照 2016-05-30 上午10.58.15.png" width="359" height="256" border="0" vspace="0" style="width: 359px; height: 256px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"><span style="text-indent: 32px;"></span></span>在一个迭代内保证对数似然函数的增加的，迭代结束时无法保证对数似然函数是最大的。也就是说，EM算法不能保证找到全局最优值。严密的证明请接着看下一节。</p>
<h3 id="h3-5">EM算法的收敛性</h3>
<p style="text-indent: 2em;"><strong>对数似然函数单调递增定理</strong> 设<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d8fic8ctj205401yq2r.jpg" title="屏幕快照 2016-05-30 上午11.05.32.png" alt="屏幕快照 2016-05-30 上午11.05.32.png" width="58" height="22" border="0" vspace="0" style="width: 58px; height: 22px;" data-tag="bdshare">为观测数据的似然函数，<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d8g08kdaj209o02cjr9.jpg" title="屏幕快照 2016-05-30 上午11.06.08.png" alt="屏幕快照 2016-05-30 上午11.06.08.png" width="91" height="22" border="0" vspace="0" style="width: 91px; height: 22px;" data-tag="bdshare">为EM算法得到的参数估计序列，<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d8giwue6j20d8022wef.jpg" title="屏幕快照 2016-05-30 上午11.06.41.png" alt="屏幕快照 2016-05-30 上午11.06.41.png" width="142" height="22" border="0" vspace="0" style="width: 142px; height: 22px;" data-tag="bdshare">为对应的似然函数序列，则<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d8gxh9mqj2060024web.jpg" title="屏幕快照 2016-05-30 上午11.07.06.png" alt="屏幕快照 2016-05-30 上午11.07.06.png" width="63" height="22" border="0" vspace="0" style="width: 63px; height: 22px;" data-tag="bdshare">是单调递增的，即</p>
<p style="text-align: center;"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d8hde06jj20ee024749.jpg" title="屏幕快照 2016-05-30 上午11.07.30.png" alt="屏幕快照 2016-05-30 上午11.07.30.png" width="150" height="22" border="0" vspace="0" style="width: 150px; height: 22px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">证明参考《统计学习方法》161页。</p>
<p style="text-indent: 2em;"><strong>收敛性定理</strong>&nbsp;<span style="text-indent: 2em;">设<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d8ntyektj20bc026q2v.jpg" title="屏幕快照 2016-05-30 上午11.13.40.png" alt="屏幕快照 2016-05-30 上午11.13.40.png" width="115" height="22" border="0" vspace="0" style="width: 115px; height: 22px;" data-tag="bdshare">为观测数据的对数似然函数，<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d8g08kdaj209o02cjr9.jpg" title="屏幕快照 2016-05-30 上午11.06.08.png" alt="屏幕快照 2016-05-30 上午11.06.08.png" width="91" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 91px; height: 22px;" data-tag="bdshare">为EM算法得到的参数估计序列，<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d8ooc697j20be0240sn.jpg" title="屏幕快照 2016-05-30 上午11.14.31.png" alt="屏幕快照 2016-05-30 上午11.14.31.png" width="119" height="22" border="0" vspace="0" style="width: 119px; height: 22px;" data-tag="bdshare">为对应的对数似然函数序列。</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">（1）如果<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d8pjpkvvj205a022jr7.jpg" title="屏幕快照 2016-05-30 上午11.15.03.png" alt="屏幕快照 2016-05-30 上午11.15.03.png" width="57" height="22" border="0" vspace="0" style="width: 57px; height: 22px;" data-tag="bdshare">有上界，则<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d8q3qrz0j20dm02aaa1.jpg" title="屏幕快照 2016-05-30 上午11.15.51.png" alt="屏幕快照 2016-05-30 上午11.15.51.png" width="131" height="22" border="0" vspace="0" style="width: 131px; height: 22px;" data-tag="bdshare">收敛到某一值<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d8qh6sk9j201o01u3y9.jpg" title="屏幕快照 2016-05-30 上午11.16.09.png" alt="屏幕快照 2016-05-30 上午11.16.09.png" width="20" height="22" border="0" vspace="0" style="width: 20px; height: 22px;" data-tag="bdshare">;</span></p>
<p style="text-indent: 2em;">（2）在函数<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d8qy7kuij2052020744.jpg" title="屏幕快照 2016-05-30 上午11.16.40.png" alt="屏幕快照 2016-05-30 上午11.16.40.png" width="56" height="22" border="0" vspace="0" style="width: 56px; height: 22px;" data-tag="bdshare">与<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d8rgg7gdj203a024gle.jpg" title="屏幕快照 2016-05-30 上午11.16.59.png" alt="屏幕快照 2016-05-30 上午11.16.59.png" width="34" height="22" border="0" vspace="0" style="width: 34px; height: 22px;" data-tag="bdshare">满足一定条件下，由EM算法得到的参数估计序列<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d8sjcns0j202i022we9.jpg" title="屏幕快照 2016-05-30 上午11.17.43.png" alt="屏幕快照 2016-05-30 上午11.17.43.png" width="27" height="22" border="0" vspace="0" style="width: 27px; height: 22px;" data-tag="bdshare">的收敛值<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d8t4nemhj201w01ua9t.jpg" title="屏幕快照 2016-05-30 上午11.18.43.png" alt="屏幕快照 2016-05-30 上午11.18.43.png" width="23" height="22" border="0" vspace="0" style="width: 23px; height: 22px;" data-tag="bdshare">是<img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4d8tkuvupj203801wjr6.jpg" title="屏幕快照 2016-05-30 上午11.19.12.png" alt="屏幕快照 2016-05-30 上午11.19.12.png" width="38" height="22" border="0" vspace="0" style="width: 38px; height: 22px;" data-tag="bdshare">的稳定点。</p>
<p style="text-indent: 2em;">证明依然参考<span style="text-indent: 32px;">《统计学习方法》162页，事实上，连原著都省略了（2）的证明。</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">既然EM算法不能保证找到全局最优解，而且初值会影响最终结果，那么实际应用中有什么技巧呢？答案是多选几个初值，择优录取。</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">原著接下来介绍了EM算法在高斯混合模型中的应用，以及EM算法的推广。这在超出了我目前对<span style="text-indent: 32px;">理论的需求，所以暂时打住，进入实践环节。</span></span></p>
<h2 id="h2-6"><span style="text-indent: 32px;"><span style="text-indent: 32px;">EM算法的简明实现</span></span></h2>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"><span style="text-indent: 32px;">当然是教学用的简明实现了，这份实现是针对双硬币模型的。</span></span></p>
<h3 id="h3-7"><span style="text-indent: 32px;"><span style="text-indent: 32px;">双硬币模型</span></span></h3>
<p style="text-indent: 2em;">假设有两枚硬币A、B，以相同的概率随机选择一个硬币，进行如下的抛硬币实验：共做5次实验，每次实验独立的抛十次，结果如图中a所示，例如某次实验产生了H、T、T、T、H、H、T、H、T、H，H代表正面朝上。</p>
<p style="text-indent: 2em;">假设试验数据记录员可能是实习生，业务不一定熟悉，造成a和b两种情况</p>
<p style="text-indent: 2em;">a表示实习生记录了详细的试验数据，我们可以观测到试验数据中每次选择的是A还是B</p>
<p style="text-indent: 2em;">b表示实习生忘了记录每次试验选择的是A还是B，我们无法观测实验数据中选择的硬币是哪个</p>
<p style="text-indent: 2em;">问在两种情况下分别如何估计两个硬币正面出现的概率？</p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4b95mzejvj20p60t0qab.jpg" title="EM算法.png" alt="EM算法.png" style="text-indent: 32px; white-space: normal;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">a情况相信大家都很熟悉，既然能观测到试验数据是哪枚硬币产生的，就可以统计正反面的出现次数，直接利用最大似然估计即可。</p>
<p style="text-indent: 2em;">b情况就无法直接进行最大似然估计了，只能用EM算法，接下来引用nipunbatra博主的简明EM算法Python实现。</p>
<h3 id="h3-8">建立数据集</h3>
<p style="text-indent: 2em;">针对这个问题，首先采集数据，用1表示H（正面），0表示T（反面）：</p>
<pre class="prettyprint lang-python linenums"><ol class="linenums"><li class="L0"><span class="com">#&nbsp;硬币投掷结果观测序列</span></li><li class="L1"><span class="pln">observations&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;np</span><span class="pun">.</span><span class="pln">array</span><span class="pun">([[</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">],</span></li><li class="L2"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="pun">[</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">],</span></li><li class="L3"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="pun">[</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">],</span></li><li class="L4"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="pun">[</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">],</span></li><li class="L5"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="pun">[</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">]])</span></li></ol></pre>
<h3 id="h3-9">初始化</h3>
<p style="text-indent: 2em;">选定初值，比如</p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4didnb8m9j206a04ywef.jpg" title="屏幕快照 2016-05-30 下午4.49.49.png" alt="屏幕快照 2016-05-30 下午4.49.49.png" width="70" height="55" border="0" vspace="0" style="width: 70px; height: 55px;" data-tag="bdshare"></p>
<h3 id="h3-10">第一个迭代的E步<br></h3>
<p style="text-indent: 2em;">抛硬币是一个二项分布，可以用<span style="text-indent: 2em;">scipy中的binom来计算。对于第一行数据，正反面各有5次，所以：</span></p>
<pre class="prettyprint lang-python linenums"><ol class="linenums"><li class="L0"><span class="pln">coin_A_pmf_observation_1&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;stats</span><span class="pun">.</span><span class="pln">binom</span><span class="pun">.</span><span class="pln">pmf</span><span class="pun">(</span><span class="lit">5</span><span class="pun">,</span><span class="lit">10</span><span class="pun">,</span><span class="lit">0.6</span><span class="pun">)</span></li></ol></pre>
<p style="text-indent: 2em;"><span style="text-indent: 2em;"></span>输出</p>
<pre class="prettyprint lang-python linenums"><ol class="linenums"><li class="L0"><span class="lit">0.20065812480000034</span></li></ol></pre>
<p style="text-indent: 2em;">类似地，可以计算第一行数据由B生成的概率：</p>
<pre class="prettyprint lang-python linenums"><ol class="linenums"><li class="L0"><span class="pln">coin_B_pmf_observation_1&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;stats</span><span class="pun">.</span><span class="pln">binom</span><span class="pun">.</span><span class="pln">pmf</span><span class="pun">(</span><span class="lit">5</span><span class="pun">,</span><span class="lit">10</span><span class="pun">,</span><span class="lit">0.5</span><span class="pun">)</span></li></ol></pre>
<p style="text-indent: 2em;">输出：</p>
<pre class="prettyprint lang-plain linenums"><ol class="linenums"><li class="L0"><span class="lit">0.24609375000000025</span></li></ol></pre>
<p style="text-indent: 2em;">将两个概率正规化，得到数据来自硬币A的概率：</p>
<pre class="prettyprint lang-python linenums"><ol class="linenums"><li class="L0"><span class="pln">normalized_coin_A_pmf_observation_1&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;coin_A_pmf_observation_1</span><span class="pun">/(</span><span class="pln">coin_A_pmf_observation_1</span><span class="pun">+</span><span class="pln">coin_B_pmf_observation_1</span><span class="pun">)</span></li><li class="L1"><span class="kwd">print</span><span class="pln">&nbsp;</span><span class="str">"%0.2f"</span><span class="pln">&nbsp;</span><span class="pun">%</span><span class="pln">normalized_coin_A_pmf_observation_1</span></li></ol></pre>
<p style="text-indent: 2em;">这个值类似于三硬币模型中的μ，只不过多了一个下标，代表是第几行数据（数据集由5行构成）。同理，可以算出剩下的4行数据的μ。</p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">有了μ，就可以估计数据中AB分别产生正反面的次数了。μ代表数据来自硬币A的概率的估计，将它乘上正面的总数，得到正面来自硬币A的总数，同理有反面，同理有B的正反面。</span></p>
<pre class="prettyprint lang-python linenums"><ol class="linenums"><li class="L0"><span class="com">#&nbsp;更新在当前参数下A、B硬币产生的正反面次数</span></li><li class="L1"><span class="pln">counts</span><span class="pun">[</span><span class="str">'A'</span><span class="pun">][</span><span class="str">'H'</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;weight_A&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;num_heads</span></li><li class="L2"><span class="pln">counts</span><span class="pun">[</span><span class="str">'A'</span><span class="pun">][</span><span class="str">'T'</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;weight_A&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;num_tails</span></li><li class="L3"><span class="pln">counts</span><span class="pun">[</span><span class="str">'B'</span><span class="pun">][</span><span class="str">'H'</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;weight_B&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;num_heads</span></li><li class="L4"><span class="pln">counts</span><span class="pun">[</span><span class="str">'B'</span><span class="pun">][</span><span class="str">'T'</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;weight_B&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;num_tails</span></li></ol></pre>
<h3 id="h3-11">第一个迭代的M步<br></h3>
<p style="text-indent: 2em;">当前模型参数下，AB分别产生正反面的次数估计出来了，就可以计算新的模型参数了：</p>
<pre class="prettyprint lang-python linenums"><ol class="linenums"><li class="L0"><span class="pln">new_theta_A&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;counts</span><span class="pun">[</span><span class="str">'A'</span><span class="pun">][</span><span class="str">'H'</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">/</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">counts</span><span class="pun">[</span><span class="str">'A'</span><span class="pun">][</span><span class="str">'H'</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;counts</span><span class="pun">[</span><span class="str">'A'</span><span class="pun">][</span><span class="str">'T'</span><span class="pun">])</span></li><li class="L1"><span class="pln">new_theta_B&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;counts</span><span class="pun">[</span><span class="str">'B'</span><span class="pun">][</span><span class="str">'H'</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">/</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">counts</span><span class="pun">[</span><span class="str">'B'</span><span class="pun">][</span><span class="str">'H'</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;counts</span><span class="pun">[</span><span class="str">'B'</span><span class="pun">][</span><span class="str">'T'</span><span class="pun">])</span></li></ol></pre>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">对于第一个迭代，新的模型参数分别为：<br></span></p>
<p style="text-align:center"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4djc4bl92j20kg028mxv.jpg" title="屏幕快照 2016-05-30 下午5.22.28.png" alt="屏幕快照 2016-05-30 下午5.22.28.png" width="405" height="44" border="0" vspace="0" style="width: 405px; height: 44px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">与论文是一致的，于是就可以整理一下，给出EM算法单个迭代的代码：</p>
<pre class="prettyprint lang-python linenums"><ol class="linenums"><li class="L0"><span class="kwd">def</span><span class="pln">&nbsp;em_single</span><span class="pun">(</span><span class="pln">priors</span><span class="pun">,</span><span class="pln">&nbsp;observations</span><span class="pun">):</span></li><li class="L1"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="str">"""</span></li><li class="L2"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;EM算法单次迭代</span></li><li class="L3"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;Arguments</span></li><li class="L4"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;---------</span></li><li class="L5"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;priors&nbsp;:&nbsp;[theta_A,&nbsp;theta_B]</span></li><li class="L6"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;observations&nbsp;:&nbsp;[m&nbsp;X&nbsp;n&nbsp;matrix]</span></li><li class="L7"><span class="str">&nbsp;</span></li><li class="L8"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;Returns</span></li><li class="L9"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;--------</span></li><li class="L0"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;new_priors:&nbsp;[new_theta_A,&nbsp;new_theta_B]</span></li><li class="L1"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;:param&nbsp;priors:</span></li><li class="L2"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;:param&nbsp;observations:</span></li><li class="L3"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;:return:</span></li><li class="L4"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;"""</span></li><li class="L5"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;counts&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="pun">{</span><span class="str">'A'</span><span class="pun">:</span><span class="pln">&nbsp;</span><span class="pun">{</span><span class="str">'H'</span><span class="pun">:</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="str">'T'</span><span class="pun">:</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">},</span><span class="pln">&nbsp;</span><span class="str">'B'</span><span class="pun">:</span><span class="pln">&nbsp;</span><span class="pun">{</span><span class="str">'H'</span><span class="pun">:</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="str">'T'</span><span class="pun">:</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">}}</span></li><li class="L6"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;theta_A&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;priors</span><span class="pun">[</span><span class="lit">0</span><span class="pun">]</span></li><li class="L7"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;theta_B&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;priors</span><span class="pun">[</span><span class="lit">1</span><span class="pun">]</span></li><li class="L8"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="com">#&nbsp;E&nbsp;step</span></li><li class="L9"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="kwd">for</span><span class="pln">&nbsp;observation&nbsp;</span><span class="kwd">in</span><span class="pln">&nbsp;observations</span><span class="pun">:</span></li><li class="L0"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;len_observation&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;len</span><span class="pun">(</span><span class="pln">observation</span><span class="pun">)</span></li><li class="L1"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;num_heads&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;observation</span><span class="pun">.</span><span class="pln">sum</span><span class="pun">()</span></li><li class="L2"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;num_tails&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;len_observation&nbsp;</span><span class="pun">-</span><span class="pln">&nbsp;num_heads</span></li><li class="L3"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;contribution_A&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;stats</span><span class="pun">.</span><span class="pln">binom</span><span class="pun">.</span><span class="pln">pmf</span><span class="pun">(</span><span class="pln">num_heads</span><span class="pun">,</span><span class="pln">&nbsp;len_observation</span><span class="pun">,</span><span class="pln">&nbsp;theta_A</span><span class="pun">)</span></li><li class="L4"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;contribution_B&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;stats</span><span class="pun">.</span><span class="pln">binom</span><span class="pun">.</span><span class="pln">pmf</span><span class="pun">(</span><span class="pln">num_heads</span><span class="pun">,</span><span class="pln">&nbsp;len_observation</span><span class="pun">,</span><span class="pln">&nbsp;theta_B</span><span class="pun">)</span><span class="pln">&nbsp;&nbsp;&nbsp;</span><span class="com">#&nbsp;两个二项分布</span></li><li class="L5"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weight_A&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;contribution_A&nbsp;</span><span class="pun">/</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">contribution_A&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;contribution_B</span><span class="pun">)</span></li><li class="L6"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weight_B&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;contribution_B&nbsp;</span><span class="pun">/</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">contribution_A&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;contribution_B</span><span class="pun">)</span></li><li class="L7"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="com">#&nbsp;更新在当前参数下A、B硬币产生的正反面次数</span></li><li class="L8"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;counts</span><span class="pun">[</span><span class="str">'A'</span><span class="pun">][</span><span class="str">'H'</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;weight_A&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;num_heads</span></li><li class="L9"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;counts</span><span class="pun">[</span><span class="str">'A'</span><span class="pun">][</span><span class="str">'T'</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;weight_A&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;num_tails</span></li><li class="L0"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;counts</span><span class="pun">[</span><span class="str">'B'</span><span class="pun">][</span><span class="str">'H'</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;weight_B&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;num_heads</span></li><li class="L1"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;counts</span><span class="pun">[</span><span class="str">'B'</span><span class="pun">][</span><span class="str">'T'</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;weight_B&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;num_tails</span></li><li class="L2"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="com">#&nbsp;M&nbsp;step</span></li><li class="L3"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;new_theta_A&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;counts</span><span class="pun">[</span><span class="str">'A'</span><span class="pun">][</span><span class="str">'H'</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">/</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">counts</span><span class="pun">[</span><span class="str">'A'</span><span class="pun">][</span><span class="str">'H'</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;counts</span><span class="pun">[</span><span class="str">'A'</span><span class="pun">][</span><span class="str">'T'</span><span class="pun">])</span></li><li class="L4"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;new_theta_B&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;counts</span><span class="pun">[</span><span class="str">'B'</span><span class="pun">][</span><span class="str">'H'</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">/</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">counts</span><span class="pun">[</span><span class="str">'B'</span><span class="pun">][</span><span class="str">'H'</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;counts</span><span class="pun">[</span><span class="str">'B'</span><span class="pun">][</span><span class="str">'T'</span><span class="pun">])</span></li><li class="L5"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="kwd">return</span><span class="pln">&nbsp;</span><span class="pun">[</span><span class="pln">new_theta_A</span><span class="pun">,</span><span class="pln">&nbsp;new_theta_B</span><span class="pun">]</span></li></ol></pre>
<h3 id="h3-12">EM算法主循环<br></h3>
<p style="text-indent: 2em;">给定循环的两个终止条件：模型参数变化小于阈值；循环达到最大次数，就可以写出EM算法的主循环了：</p>
<pre class="prettyprint lang-python linenums"><ol class="linenums"><li class="L0"><span class="kwd">def</span><span class="pln">&nbsp;em</span><span class="pun">(</span><span class="pln">observations</span><span class="pun">,</span><span class="pln">&nbsp;prior</span><span class="pun">,</span><span class="pln">&nbsp;tol</span><span class="pun">=</span><span class="lit">1e-6</span><span class="pun">,</span><span class="pln">&nbsp;iterations</span><span class="pun">=</span><span class="lit">10000</span><span class="pun">):</span></li><li class="L1"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="str">"""</span></li><li class="L2"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;EM算法</span></li><li class="L3"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;:param&nbsp;observations:&nbsp;观测数据</span></li><li class="L4"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;:param&nbsp;prior:&nbsp;模型初值</span></li><li class="L5"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;:param&nbsp;tol:&nbsp;迭代结束阈值</span></li><li class="L6"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;:param&nbsp;iterations:&nbsp;最大迭代次数</span></li><li class="L7"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;:return:&nbsp;局部最优的模型参数</span></li><li class="L8"><span class="str">&nbsp;&nbsp;&nbsp;&nbsp;"""</span></li><li class="L9"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="kwd">import</span><span class="pln">&nbsp;math</span></li><li class="L0"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;iteration&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span></li><li class="L1"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="kwd">while</span><span class="pln">&nbsp;iteration&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;iterations</span><span class="pun">:</span></li><li class="L2"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new_prior&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;em_single</span><span class="pun">(</span><span class="pln">prior</span><span class="pun">,</span><span class="pln">&nbsp;observations</span><span class="pun">)</span></li><li class="L3"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;delta_change&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;np</span><span class="pun">.</span><span class="pln">abs</span><span class="pun">(</span><span class="pln">prior</span><span class="pun">[</span><span class="lit">0</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">&nbsp;new_prior</span><span class="pun">[</span><span class="lit">0</span><span class="pun">])</span></li><li class="L4"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="kwd">if</span><span class="pln">&nbsp;delta_change&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;tol</span><span class="pun">:</span></li><li class="L5"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="kwd">break</span></li><li class="L6"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="kwd">else</span><span class="pun">:</span></li><li class="L7"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prior&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;new_prior</span></li><li class="L8"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;iteration&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;</span><span class="lit">1</span></li><li class="L9"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="kwd">return</span><span class="pln">&nbsp;</span><span class="pun">[</span><span class="pln">new_prior</span><span class="pun">,</span><span class="pln">&nbsp;iteration</span><span class="pun">]</span></li></ol></pre>
<h3 id="h3-13"><span style="text-indent: 32px;">调用<br></span></h3>
<p style="text-indent: 2em;">给定数据集和初值，就可以调用EM算法了：</p>
<pre class="prettyprint lang-python linenums"><ol class="linenums"><li class="L0"><span class="kwd">print</span><span class="pln">&nbsp;em</span><span class="pun">(</span><span class="pln">observations</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="pun">[</span><span class="lit">0.6</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0.5</span><span class="pun">])</span></li></ol></pre>
<p style="text-indent: 2em;">得到</p>
<pre class="prettyprint lang-plain linenums"><ol class="linenums"><li class="L0"><span class="pun">[[</span><span class="lit">0.79678875938310978</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0.51958393567528027</span><span class="pun">],</span><span class="pln">&nbsp;</span><span class="lit">14</span><span class="pun">]</span></li></ol></pre>
<p style="text-indent: 2em;">与论文中的结果是一致的（我们多迭代了4次，毕竟我们不清楚论文作者设置的终止条件）：</p>
<p style="text-align: center;"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f4djjb6q66j204s03wglp.jpg" title="屏幕快照 2016-05-30 下午5.29.24.png" alt="屏幕快照 2016-05-30 下午5.29.24.png" width="68" height="55" border="0" vspace="0" style="width: 68px; height: 55px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">我们可以改变初值，试验初值对EM算法的影响。</p>
<pre class="prettyprint lang-python linenums"><ol class="linenums"><li class="L0"><span class="pln">em</span><span class="pun">(</span><span class="pln">observations</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="pun">[</span><span class="lit">0.5</span><span class="pun">,</span><span class="lit">0.6</span><span class="pun">])</span></li></ol></pre>
<p style="text-indent: 2em;">得到</p>
<pre class="prettyprint lang-plain linenums"><ol class="linenums"><li class="L0"><span class="pun">[[</span><span class="lit">0.51958345063012845</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0.79678895444393927</span><span class="pun">],</span><span class="pln">&nbsp;</span><span class="lit">15</span><span class="pun">]</span></li></ol></pre>
<p style="text-indent: 2em;">看来EM算法还是很健壮的</p>
<p style="text-indent: 2em;">如果把初值设为相等会怎样？</p>
<p style="text-indent: 2em;">调用</p>
<pre class="prettyprint lang-python linenums"><ol class="linenums"><li class="L0"><span class="pln">em</span><span class="pun">(</span><span class="pln">observations</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="pun">[</span><span class="lit">0.3</span><span class="pun">,</span><span class="lit">0.3</span><span class="pun">])</span></li></ol></pre>
<p style="text-indent: 2em;">得到</p>
<pre class="prettyprint lang-python linenums"><ol class="linenums"><li class="L0"><span class="pun">[[</span><span class="lit">0.66000000000000003</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0.66000000000000003</span><span class="pun">],</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">]</span></li></ol></pre>
<p style="text-indent: 2em;">这显然是不是个好主意，再试试很极端的情况：</p>
<pre class="prettyprint lang-python linenums"><ol class="linenums"><li class="L0"><span class="pln">em</span><span class="pun">(</span><span class="pln">observations</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="pun">[</span><span class="lit">0.9999</span><span class="pun">,</span><span class="lit">0.00000001</span><span class="pun">])</span></li></ol></pre>
<p style="text-indent: 2em;">得到</p>
<pre class="prettyprint lang-plain linenums"><ol class="linenums"><li class="L0"><span class="pun">[[</span><span class="lit">0.79678850504581944</span><span class="pun">,</span><span class="pln">&nbsp;</span><span class="lit">0.51958235686544463</span><span class="pun">],</span><span class="pln">&nbsp;</span><span class="lit">13</span><span class="pun">]</span></li></ol></pre>
<p style="text-indent: 2em;">可见EM算法仍然很聪明。</p>
<h2 id="h2-14">Reference</h2>
<p style="text-indent: 2em;">《统计学习方法》</p>
<p style="text-indent: 2em;"><img src="./em-algorithm-and-its-generalization_files/icon_pdf.gif" style="text-indent: 32px; white-space: normal; line-height: 16px; vertical-align: middle; margin-right: 2px;" data-tag="bdshare"><a href="http://www.hankcs.com/wp-content/uploads/2016/05/COS%20424-%20Interacting%20with%20Data.pdf" title="COS 424- Interacting with Data.pdf" style="text-indent: 32px; white-space: normal; line-height: 16px; font-size: 12px; color: rgb(0, 102, 204);">COS 424- Interacting with Data.pdf</a></p>
<p style="text-indent: 2em;"><img src="./em-algorithm-and-its-generalization_files/icon_pdf.gif" style="line-height: 16px; vertical-align: middle; margin-right: 2px;" data-tag="bdshare"><a href="http://www.hankcs.com/wp-content/uploads/2016/05/em_tutorial.pdf" title="em_tutorial.pdf" style="line-height: 16px; font-size: 12px; color: rgb(0, 102, 204);">em_tutorial.pdf</a></p>
<p style="text-indent: 2em;"><a href="http://chenrudan.github.io/blog/2015/12/02/emexample.html" _src="http://chenrudan.github.io/blog/2015/12/02/emexample.html" target="_blank" rel="external nofollow">http://chenrudan.github.io/blog/2015/12/02/emexample.html</a> </p>
<p style="text-indent: 2em;"><a href="http://nipunbatra.github.io/2014/04/em/" _src="http://nipunbatra.github.io/2014/04/em/" target="_blank" rel="external nofollow">http://nipunbatra.github.io/2014/04/em/</a> </p>
<p style="text-indent: 2em;"></p>
<p style="text-indent: 2em;"></p>
<p class="post-copyright"><a href="http://www.hankcs.com/license/" target="_blank"><img alt="知识共享许可协议" style="border-width: 0px;margin: 0 !important;" src="./em-algorithm-and-its-generalization_files/CC-BY-NC-SA-icon-88x31.png" width="88" height="31" border="0" vspace="0" title="知识共享许可协议" data-tag="bdshare"></a>&nbsp;<a href="http://www.hankcs.com/license/" target="_blank" textvalue="知识共享署名-非商业性使用-相同方式共享">知识共享署名-非商业性使用-相同方式共享</a>：<a href="http://www.hankcs.com/">码农场</a> » <a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html">EM算法及其推广</a></p>		</article>
								<div class="action-share bdsharebuttonbox bdshare-button-style0-24" data-bd-bind="1498533125717">
			<span>分享到：</span><a class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a><a class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a><a class="bds_weixin" data-cmd="weixin" title="分享到微信"></a><a class="bds_tqq" data-cmd="tqq" title="分享到腾讯微博"></a><a class="bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a><a class="bds_bdhome" data-cmd="bdhome" title="分享到百度新首页"></a><a class="bds_tqf" data-cmd="tqf" title="分享到腾讯朋友"></a><a class="bds_renren" data-cmd="renren" title="分享到人人网"></a><a class="bds_diandian" data-cmd="diandian" title="分享到点点网"></a><a class="bds_youdao" data-cmd="youdao" title="分享到有道云笔记"></a><a class="bds_ty" data-cmd="ty" title="分享到天涯社区"></a><a class="bds_kaixin001" data-cmd="kaixin001" title="分享到开心网"></a><a class="bds_taobao" data-cmd="taobao"></a><a class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a><a class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a><a class="bds_twi" data-cmd="twi" title="分享到Twitter"></a><a class="bds_mail" data-cmd="mail" title="分享到邮件分享"></a><a class="bds_copy" data-cmd="copy" title="分享到复制网址"></a><a class="bds_more" data-cmd="more">更多</a> <span>(</span><a class="bds_count" data-cmd="count" title="累计分享29次">29</a><span>)</span>		</div>
		<div class="article-tags">继续浏览有关 <a href="http://www.hankcs.com/ml/"><i class="fa fa-folder-open"></i> 机器学习</a><a href="http://www.hankcs.com/tag/%e3%80%8a%e7%bb%9f%e8%ae%a1%e5%ad%a6%e4%b9%a0%e6%96%b9%e6%b3%95%e3%80%8b/" rel="tag">《统计学习方法》</a> 的文章</div>		<div class="asb asb-post asb-post-02"><script async="" src="./em-algorithm-and-its-generalization_files/adsbygoogle.js.下载"></script>
<!-- 文章页正文下 页首横幅 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-1152644711996772" data-ad-slot="2657945648" data-adsbygoogle-status="done"><ins id="aswift_1_expand" style="display:inline-table;border:none;height:90px;margin:0;padding:0;position:relative;visibility:visible;width:728px;background-color:transparent"><ins id="aswift_1_anchor" style="display:block;border:none;height:90px;margin:0;padding:0;position:relative;visibility:visible;width:728px;background-color:transparent"><iframe width="728" height="90" frameborder="0" marginwidth="0" marginheight="0" vspace="0" hspace="0" allowtransparency="true" scrolling="no" allowfullscreen="true" onload="var i=this.id,s=window.google_iframe_oncopy,H=s&amp;&amp;s.handlers,h=H&amp;&amp;H[i],w=this.contentWindow,d;try{d=w.document}catch(e){}if(h&amp;&amp;d&amp;&amp;(!d.body||!d.body.firstChild)){if(h.call){setTimeout(h,0)}else if(h.match){try{h=s.upd(h,i)}catch(e){}w.location.replace(h)}}" id="aswift_1" name="aswift_1" style="left:0;position:absolute;top:0;width:728px;height:90px;" src="./em-algorithm-and-its-generalization_files/saved_resource(2).html"></iframe></ins></ins></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></div>		<nav class="article-nav">
			<span class="article-nav-prev">上一篇 <a href="http://www.hankcs.com/ml/adaboost.html" rel="prev">提升方法</a></span>
			<span class="article-nav-next"><a href="http://www.hankcs.com/ml/hidden-markov-model.html" rel="next">隐马尔可夫模型</a> 下一篇</span>
		</nav>
				<div class="asb asb-post asb-post-03"><script async="" src="./em-algorithm-and-its-generalization_files/adsbygoogle.js.下载"></script>
<!-- 匹配内容 -->
<ins class="adsbygoogle" style="display: block; height: 466px;" data-ad-client="ca-pub-1152644711996772" data-ad-slot="7343699642" data-ad-format="autorelaxed" data-adsbygoogle-status="done"><ins id="aswift_2_expand" style="display:inline-table;border:none;height:466px;margin:0;padding:0;position:relative;visibility:visible;width:778px;background-color:transparent"><ins id="aswift_2_anchor" style="display:block;border:none;height:466px;margin:0;padding:0;position:relative;visibility:visible;width:778px;background-color:transparent"><iframe width="778" height="466" frameborder="0" marginwidth="0" marginheight="0" vspace="0" hspace="0" allowtransparency="true" scrolling="no" allowfullscreen="true" onload="var i=this.id,s=window.google_iframe_oncopy,H=s&amp;&amp;s.handlers,h=H&amp;&amp;H[i],w=this.contentWindow,d;try{d=w.document}catch(e){}if(h&amp;&amp;d&amp;&amp;(!d.body||!d.body.firstChild)){if(h.call){setTimeout(h,0)}else if(h.match){try{h=s.upd(h,i)}catch(e){}w.location.replace(h)}}" id="aswift_2" name="aswift_2" style="left:0;position:absolute;top:0;width:778px;height:466px;" src="./em-algorithm-and-its-generalization_files/saved_resource(3).html"></iframe></ins></ins></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></div>		<div class="title" id="comments">
	<h3>评论 <b>8</b></h3>
</div>
<div id="respond" class="no_webshot">
		
	<form action="http://www.hankcs.com/wp-comments-post.php" method="post" id="commentform">
		<div class="comt">
			<div class="comt-title">
				<img alt="" data-src="http://0.gravatar.com/avatar/?s=50&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g" srcset="http://0.gravatar.com/avatar/?s=100&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g 2x" class="avatar avatar-50 photo avatar-default" height="50" width="50" src="./em-algorithm-and-its-generalization_files/saved_resource" style="display: inline;">				<p><a id="cancel-comment-reply-link" href="javascript:;">取消</a></p>
			</div>
			<div class="comt-box">
				<textarea placeholder="此处不受理任何开源项目问题，请在GitHub上发issue ，大家一起讨论，谢谢。" class="input-block-level comt-area" name="comment" id="comment" cols="100%" rows="3" tabindex="1" onkeydown="if(event.ctrlKey&amp;&amp;event.keyCode==13){document.getElementById(&#39;submit&#39;).click();return false};"></textarea>
				<div class="comt-ctrl">
					<div class="comt-tips"><input type="hidden" name="comment_post_ID" value="7368" id="comment_post_ID">
<input type="hidden" name="comment_parent" id="comment_parent" value="0">
<p style="display: none;"><input type="hidden" id="akismet_comment_nonce" name="akismet_comment_nonce" value="81f1b58e29"></p><label for="comment_mail_notify" class="checkbox inline hide" style="padding-top:0"><input type="checkbox" name="comment_mail_notify" id="comment_mail_notify" value="comment_mail_notify" checked="checked">有人回复时邮件通知我</label><p style="display: none;"></p><div class="comt-tip comt-loading" style="display: none;">评论提交中...</div><div class="comt-tip comt-error" style="display: none;">#</div></div>
					<button type="submit" name="submit" id="submit" tabindex="5">提交评论</button>
					<!-- <span data-type="comment-insert-smilie" class="muted comt-smilie"><i class="icon-thumbs-up icon12"></i> 表情</span> -->
				</div>
			</div>

												<div class="comt-comterinfo" id="comment-author-info">
						<ul>
							<li class="form-inline"><label class="hide" for="author">昵称</label><input class="ipt" type="text" name="author" id="author" value="" tabindex="2" placeholder="昵称"><span class="text-muted">昵称 (必填)</span></li>
							<li class="form-inline"><label class="hide" for="email">邮箱</label><input class="ipt" type="text" name="email" id="email" value="" tabindex="3" placeholder="邮箱"><span class="text-muted">邮箱 (必填)</span></li>
							<li class="form-inline"><label class="hide" for="url">网址</label><input class="ipt" type="text" name="url" id="url" value="" tabindex="4" placeholder="网址"><span class="text-muted">网址</span></li>
						</ul>
					</div>
									</div>

	<input type="hidden" id="ak_js" name="ak_js" value="1498533125258"></form>
	</div>
<div id="postcomments">
	<ol class="commentlist">
		<li class="comment even thread-even depth-1" id="comment-6226"><span class="comt-f">#6</span><div class="comt-avatar"><img alt="" data-src="http://1.gravatar.com/avatar/abc9ad695a9e9e1775cd04539bffb025?s=50&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g" srcset="http://1.gravatar.com/avatar/abc9ad695a9e9e1775cd04539bffb025?s=100&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g 2x" class="avatar avatar-50 photo" height="50" width="50" src="./em-algorithm-and-its-generalization_files/avatar-default.png"></div><div class="comt-main" id="div-comment-6226"><p>代码里写错了吧，<br>
contribution_B = stats.binom.pmf(num_heads, len_observation, theta_B)<br>
应该是contribution_B = stats.binom.pmf(num_tails, len_observation, theta_B)</p>
<div class="comt-meta"><span class="comt-author">jason</span>4天前<a rel="nofollow" class="comment-reply-link" href="javascript:;" onclick="return addComment.moveForm( &quot;div-comment-6226&quot;, &quot;6226&quot;, &quot;respond&quot;, &quot;7368&quot; )" aria-label="回复给jason">回复</a></div></div></li><!-- #comment-## -->
<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-5168"><span class="comt-f">#5</span><div class="comt-avatar"><img alt="" data-src="http://0.gravatar.com/avatar/fdf4ed5c2111d32e51e537b6d1395c7c?s=50&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g" srcset="http://0.gravatar.com/avatar/fdf4ed5c2111d32e51e537b6d1395c7c?s=100&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g 2x" class="avatar avatar-50 photo" height="50" width="50" src="./em-algorithm-and-its-generalization_files/fdf4ed5c2111d32e51e537b6d1395c7c" style="display: block;"></div><div class="comt-main" id="div-comment-5168"><p>在“M步：估算下一个迭代的新的模型估算值：”中对π概率的解释出现笔误，应该是通过出现B概率的期望来反映A出现正面的概率。</p>
<div class="comt-meta"><span class="comt-author">canwaals</span>2个月前 (04-19)<a rel="nofollow" class="comment-reply-link" href="javascript:;" onclick="return addComment.moveForm( &quot;div-comment-5168&quot;, &quot;5168&quot;, &quot;respond&quot;, &quot;7368&quot; )" aria-label="回复给canwaals">回复</a></div></div></li><!-- #comment-## -->
<li class="comment even thread-even depth-1" id="comment-4549"><span class="comt-f">#4</span><div class="comt-avatar"><img alt="" data-src="http://1.gravatar.com/avatar/?s=50&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g" srcset="http://2.gravatar.com/avatar/?s=100&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g 2x" class="avatar avatar-50 photo avatar-default" height="50" width="50" src="./em-algorithm-and-its-generalization_files/avatar-default.png"></div><div class="comt-main" id="div-comment-4549"><p>关于公式L(θ)-L(θ(i))的推导，感觉应当先进行两个log的合并，再使用Jense不等式变换，这样更容易看懂，明白</p>
<div class="comt-meta"><span class="comt-author"><a href="http://weibo.com/3616895903" rel="external nofollow" class="url" target="_blank">YSCRAZY</a></span>4个月前 (03-06)<a rel="nofollow" class="comment-reply-link" href="javascript:;" onclick="return addComment.moveForm( &quot;div-comment-4549&quot;, &quot;4549&quot;, &quot;respond&quot;, &quot;7368&quot; )" aria-label="回复给YSCRAZY">回复</a></div></div></li><!-- #comment-## -->
<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-4470"><span class="comt-f">#3</span><div class="comt-avatar"><img alt="" data-src="http://2.gravatar.com/avatar/?s=50&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g" srcset="http://0.gravatar.com/avatar/?s=100&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g 2x" class="avatar avatar-50 photo avatar-default" height="50" width="50" src="./em-algorithm-and-its-generalization_files/saved_resource(1)" style="display: block;"></div><div class="comt-main" id="div-comment-4470"><p> <img src="./em-algorithm-and-its-generalization_files/horse2_org.gif"> 厉害厉害，还是非计算机专业的</p>
<div class="comt-meta"><span class="comt-author"><a href="http://t.qq.com/c52199999" rel="external nofollow" class="url" target="_blank">啊呀</a></span>6个月前 (01-08)<a rel="nofollow" class="comment-reply-link" href="javascript:;" onclick="return addComment.moveForm( &quot;div-comment-4470&quot;, &quot;4470&quot;, &quot;respond&quot;, &quot;7368&quot; )" aria-label="回复给啊呀">回复</a></div></div></li><!-- #comment-## -->
<li class="comment even thread-even depth-1" id="comment-4192"><span class="comt-f">#2</span><div class="comt-avatar"><img alt="" data-src="http://1.gravatar.com/avatar/?s=50&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g" srcset="http://0.gravatar.com/avatar/?s=100&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g 2x" class="avatar avatar-50 photo avatar-default" height="50" width="50" src="./em-algorithm-and-its-generalization_files/avatar-default.png"></div><div class="comt-main" id="div-comment-4192"><p>先转！！</p>
<div class="comt-meta"><span class="comt-author"><a href="http://weibo.com/1965636213" rel="external nofollow" class="url" target="_blank">ClaireTan</a></span>1年前 (2016-05-31)<a rel="nofollow" class="comment-reply-link" href="javascript:;" onclick="return addComment.moveForm( &quot;div-comment-4192&quot;, &quot;4192&quot;, &quot;respond&quot;, &quot;7368&quot; )" aria-label="回复给ClaireTan">回复</a></div></div></li><!-- #comment-## -->
<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-4191"><span class="comt-f">#1</span><div class="comt-avatar"><img alt="" data-src="http://1.gravatar.com/avatar/7b23cbc7b6414c091334cde88a917dc9?s=50&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g" srcset="http://1.gravatar.com/avatar/7b23cbc7b6414c091334cde88a917dc9?s=100&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g 2x" class="avatar avatar-50 photo" height="50" width="50" src="./em-algorithm-and-its-generalization_files/avatar-default.png"></div><div class="comt-main" id="div-comment-4191"><p>调整初始值，结果差异很大啊，虽然都是0.52和0.8，但是倒了个个呢</p>
<div class="comt-meta"><span class="comt-author">易文</span>1年前 (2016-05-31)<a rel="nofollow" class="comment-reply-link" href="javascript:;" onclick="return addComment.moveForm( &quot;div-comment-4191&quot;, &quot;4191&quot;, &quot;respond&quot;, &quot;7368&quot; )" aria-label="回复给易文">回复</a></div></div><ul class="children">
<li class="comment byuser comment-author-hankcs bypostauthor even depth-2" id="comment-4193"><div class="comt-avatar"><img alt="" data-src="http://1.gravatar.com/avatar/de961732ee897fa88c707396fb1d55a4?s=50&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g" srcset="http://1.gravatar.com/avatar/de961732ee897fa88c707396fb1d55a4?s=100&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g 2x" class="avatar avatar-50 photo" height="50" width="50" src="./em-algorithm-and-its-generalization_files/avatar-default.png"></div><div class="comt-main" id="div-comment-4193"><p>因为在b中，名称AB是完全对称的。唯一的不对称就是赋的初值，求出来结果只能说是“两枚硬币小的那枚是0.52，大的那枚是0.8”</p>
<div class="comt-meta"><span class="comt-author"><a href="http://www.hankcs.com/" rel="external nofollow" class="url" target="_blank">hankcs</a></span>1年前 (2016-05-31)<a rel="nofollow" class="comment-reply-link" href="javascript:;" onclick="return addComment.moveForm( &quot;div-comment-4193&quot;, &quot;4193&quot;, &quot;respond&quot;, &quot;7368&quot; )" aria-label="回复给hankcs">回复</a></div></div></li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	</ol>
	<div class="pagenav">
			</div>
</div>
	</div>
	</div>
	<aside class="sidebar">
<div class="widget widget_categories affix-top" style="top: 0px;"><h3>栏目分类</h3><label class="screen-reader-text" for="cat">栏目分类</label><select name="cat" id="cat" class="postform">
	<option value="-1">选择分类目录</option>
	<option class="level-0" value="18">ACG&nbsp;&nbsp;(7)</option>
	<option class="level-1" value="117">&nbsp;&nbsp;&nbsp;游戏&nbsp;&nbsp;(5)</option>
	<option class="level-0" value="7">Web开发&nbsp;&nbsp;(80)</option>
	<option class="level-1" value="64">&nbsp;&nbsp;&nbsp;BAE&nbsp;&nbsp;(13)</option>
	<option class="level-1" value="11">&nbsp;&nbsp;&nbsp;Linux相关&nbsp;&nbsp;(9)</option>
	<option class="level-1" value="54">&nbsp;&nbsp;&nbsp;Mac OS&nbsp;&nbsp;(1)</option>
	<option class="level-1" value="27">&nbsp;&nbsp;&nbsp;WordPress&nbsp;&nbsp;(8)</option>
	<option class="level-1" value="65">&nbsp;&nbsp;&nbsp;Yii&nbsp;&nbsp;(17)</option>
	<option class="level-1" value="2">&nbsp;&nbsp;&nbsp;主机域名&nbsp;&nbsp;(26)</option>
	<option class="level-1" value="66">&nbsp;&nbsp;&nbsp;数据库&nbsp;&nbsp;(4)</option>
	<option class="level-0" value="140">信息安全&nbsp;&nbsp;(3)</option>
	<option class="level-0" value="1">其他类别&nbsp;&nbsp;(184)</option>
	<option class="level-1" value="78">&nbsp;&nbsp;&nbsp;心情&nbsp;&nbsp;(1)</option>
	<option class="level-1" value="15">&nbsp;&nbsp;&nbsp;旧的博文&nbsp;&nbsp;(170)</option>
	<option class="level-0" value="87">操作系统&nbsp;&nbsp;(3)</option>
	<option class="level-1" value="88">&nbsp;&nbsp;&nbsp;Windows&nbsp;&nbsp;(2)</option>
	<option class="level-0" value="81">数学基礎&nbsp;&nbsp;(3)</option>
	<option class="level-0" value="4">日语教程&nbsp;&nbsp;(120)</option>
	<option class="level-1" value="96">&nbsp;&nbsp;&nbsp;口译&nbsp;&nbsp;(1)</option>
	<option class="level-1" value="59">&nbsp;&nbsp;&nbsp;新编日语商务贸易会话&nbsp;&nbsp;(14)</option>
	<option class="level-1" value="19">&nbsp;&nbsp;&nbsp;新编日语阅读文选&nbsp;&nbsp;(34)</option>
	<option class="level-2" value="44">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第一册&nbsp;&nbsp;(20)</option>
	<option class="level-2" value="61">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第三册&nbsp;&nbsp;(2)</option>
	<option class="level-2" value="20">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第二册&nbsp;&nbsp;(10)</option>
	<option class="level-1" value="46">&nbsp;&nbsp;&nbsp;日语入门&nbsp;&nbsp;(2)</option>
	<option class="level-1" value="62">&nbsp;&nbsp;&nbsp;日语听力&nbsp;&nbsp;(2)</option>
	<option class="level-1" value="5">&nbsp;&nbsp;&nbsp;日语综合教程&nbsp;&nbsp;(64)</option>
	<option class="level-2" value="120">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第七册&nbsp;&nbsp;(14)</option>
	<option class="level-2" value="50">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第三册&nbsp;&nbsp;(7)</option>
	<option class="level-2" value="73">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第五册&nbsp;&nbsp;(12)</option>
	<option class="level-2" value="98">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第六册&nbsp;&nbsp;(18)</option>
	<option class="level-2" value="6">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第四册&nbsp;&nbsp;(12)</option>
	<option class="level-1" value="86">&nbsp;&nbsp;&nbsp;月の珊瑚&nbsp;&nbsp;(3)</option>
	<option class="level-0" value="131">机器学习&nbsp;&nbsp;(57)</option>
	<option class="level-0" value="16">经济人文&nbsp;&nbsp;(19)</option>
	<option class="level-1" value="17">&nbsp;&nbsp;&nbsp;国际贸易理论与政策&nbsp;&nbsp;(9)</option>
	<option class="level-1" value="30">&nbsp;&nbsp;&nbsp;当代世界经济与政治&nbsp;&nbsp;(3)</option>
	<option class="level-0" value="9">编程开发&nbsp;&nbsp;(556)</option>
	<option class="level-1" value="8">&nbsp;&nbsp;&nbsp;Android&nbsp;&nbsp;(30)</option>
	<option class="level-1" value="13">&nbsp;&nbsp;&nbsp;C++&nbsp;&nbsp;(237)</option>
	<option class="level-1" value="25">&nbsp;&nbsp;&nbsp;Drupal&nbsp;&nbsp;(23)</option>
	<option class="level-1" value="10">&nbsp;&nbsp;&nbsp;Java&nbsp;&nbsp;(69)</option>
	<option class="level-1" value="123">&nbsp;&nbsp;&nbsp;Javascript&nbsp;&nbsp;(1)</option>
	<option class="level-1" value="24">&nbsp;&nbsp;&nbsp;PHP&nbsp;&nbsp;(57)</option>
	<option class="level-1" value="94">&nbsp;&nbsp;&nbsp;Python&nbsp;&nbsp;(8)</option>
	<option class="level-1" value="14">&nbsp;&nbsp;&nbsp;汇编逆向&nbsp;&nbsp;(12)</option>
	<option class="level-1" value="70">&nbsp;&nbsp;&nbsp;算法&nbsp;&nbsp;(235)</option>
	<option class="level-1" value="121">&nbsp;&nbsp;&nbsp;网络&nbsp;&nbsp;(6)</option>
	<option class="level-0" value="104">自然语言处理&nbsp;&nbsp;(71)</option>
	<option class="level-1" value="109">&nbsp;&nbsp;&nbsp;中文分词&nbsp;&nbsp;(10)</option>
	<option class="level-1" value="128">&nbsp;&nbsp;&nbsp;句法分析&nbsp;&nbsp;(6)</option>
	<option class="level-1" value="127">&nbsp;&nbsp;&nbsp;命名实体识别&nbsp;&nbsp;(6)</option>
	<option class="level-1" value="105">&nbsp;&nbsp;&nbsp;语料库&nbsp;&nbsp;(4)</option>
	<option class="level-0" value="12">软件发布&nbsp;&nbsp;(9)</option>
</select>

<script type="text/javascript">
/* <![CDATA[ */
(function() {
	var dropdown = document.getElementById( "cat" );
	function onCatChange() {
		if ( dropdown.options[ dropdown.selectedIndex ].value > 0 ) {
			location.href = "http://www.hankcs.com/?cat=" + dropdown.options[ dropdown.selectedIndex ].value;
		}
	}
	dropdown.onchange = onCatChange;
})();
/* ]]> */
</script>

</div><div class="widget widget_archive" style="top: 0px;"><h3>文章归档</h3>		<label class="screen-reader-text" for="archives-dropdown-5">文章归档</label>
		<select id="archives-dropdown-5" name="archive-dropdown" onchange="document.location.href=this.options[this.selectedIndex].value;">
			
			<option value="">选择月份</option>
				<option value="http://www.hankcs.com/2017/06/"> 2017年六月 &nbsp;(23)</option>
	<option value="http://www.hankcs.com/2017/05/"> 2017年五月 &nbsp;(8)</option>
	<option value="http://www.hankcs.com/2017/03/"> 2017年三月 &nbsp;(12)</option>
	<option value="http://www.hankcs.com/2017/02/"> 2017年二月 &nbsp;(13)</option>
	<option value="http://www.hankcs.com/2017/01/"> 2017年一月 &nbsp;(22)</option>
	<option value="http://www.hankcs.com/2016/12/"> 2016年十二月 &nbsp;(2)</option>
	<option value="http://www.hankcs.com/2016/11/"> 2016年十一月 &nbsp;(15)</option>
	<option value="http://www.hankcs.com/2016/10/"> 2016年十月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2016/09/"> 2016年九月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2016/08/"> 2016年八月 &nbsp;(7)</option>
	<option value="http://www.hankcs.com/2016/07/"> 2016年七月 &nbsp;(1)</option>
	<option value="http://www.hankcs.com/2016/06/"> 2016年六月 &nbsp;(1)</option>
	<option value="http://www.hankcs.com/2016/05/"> 2016年五月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2016/04/"> 2016年四月 &nbsp;(2)</option>
	<option value="http://www.hankcs.com/2016/03/"> 2016年三月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2016/02/"> 2016年二月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2015/12/"> 2015年十二月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2015/11/"> 2015年十一月 &nbsp;(6)</option>
	<option value="http://www.hankcs.com/2015/10/"> 2015年十月 &nbsp;(4)</option>
	<option value="http://www.hankcs.com/2015/09/"> 2015年九月 &nbsp;(4)</option>
	<option value="http://www.hankcs.com/2015/08/"> 2015年八月 &nbsp;(2)</option>
	<option value="http://www.hankcs.com/2015/07/"> 2015年七月 &nbsp;(6)</option>
	<option value="http://www.hankcs.com/2015/05/"> 2015年五月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2015/04/"> 2015年四月 &nbsp;(5)</option>
	<option value="http://www.hankcs.com/2015/03/"> 2015年三月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2015/02/"> 2015年二月 &nbsp;(22)</option>
	<option value="http://www.hankcs.com/2015/01/"> 2015年一月 &nbsp;(14)</option>
	<option value="http://www.hankcs.com/2014/12/"> 2014年十二月 &nbsp;(10)</option>
	<option value="http://www.hankcs.com/2014/11/"> 2014年十一月 &nbsp;(21)</option>
	<option value="http://www.hankcs.com/2014/10/"> 2014年十月 &nbsp;(14)</option>
	<option value="http://www.hankcs.com/2014/09/"> 2014年九月 &nbsp;(16)</option>
	<option value="http://www.hankcs.com/2014/08/"> 2014年八月 &nbsp;(11)</option>
	<option value="http://www.hankcs.com/2014/07/"> 2014年七月 &nbsp;(6)</option>
	<option value="http://www.hankcs.com/2014/06/"> 2014年六月 &nbsp;(13)</option>
	<option value="http://www.hankcs.com/2014/05/"> 2014年五月 &nbsp;(28)</option>
	<option value="http://www.hankcs.com/2014/04/"> 2014年四月 &nbsp;(41)</option>
	<option value="http://www.hankcs.com/2014/03/"> 2014年三月 &nbsp;(26)</option>
	<option value="http://www.hankcs.com/2014/02/"> 2014年二月 &nbsp;(52)</option>
	<option value="http://www.hankcs.com/2014/01/"> 2014年一月 &nbsp;(28)</option>
	<option value="http://www.hankcs.com/2013/12/"> 2013年十二月 &nbsp;(29)</option>
	<option value="http://www.hankcs.com/2013/11/"> 2013年十一月 &nbsp;(21)</option>
	<option value="http://www.hankcs.com/2013/10/"> 2013年十月 &nbsp;(11)</option>
	<option value="http://www.hankcs.com/2013/09/"> 2013年九月 &nbsp;(19)</option>
	<option value="http://www.hankcs.com/2013/08/"> 2013年八月 &nbsp;(22)</option>
	<option value="http://www.hankcs.com/2013/07/"> 2013年七月 &nbsp;(36)</option>
	<option value="http://www.hankcs.com/2013/06/"> 2013年六月 &nbsp;(24)</option>
	<option value="http://www.hankcs.com/2013/05/"> 2013年五月 &nbsp;(36)</option>
	<option value="http://www.hankcs.com/2013/04/"> 2013年四月 &nbsp;(29)</option>
	<option value="http://www.hankcs.com/2013/03/"> 2013年三月 &nbsp;(46)</option>
	<option value="http://www.hankcs.com/2013/02/"> 2013年二月 &nbsp;(5)</option>
	<option value="http://www.hankcs.com/2012/05/"> 2012年五月 &nbsp;(2)</option>
	<option value="http://www.hankcs.com/2012/04/"> 2012年四月 &nbsp;(6)</option>
	<option value="http://www.hankcs.com/2010/12/"> 2010年十二月 &nbsp;(5)</option>
	<option value="http://www.hankcs.com/2010/11/"> 2010年十一月 &nbsp;(10)</option>
	<option value="http://www.hankcs.com/2010/10/"> 2010年十月 &nbsp;(13)</option>
	<option value="http://www.hankcs.com/2010/09/"> 2010年九月 &nbsp;(6)</option>
	<option value="http://www.hankcs.com/2010/08/"> 2010年八月 &nbsp;(5)</option>
	<option value="http://www.hankcs.com/2010/07/"> 2010年七月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2010/06/"> 2010年六月 &nbsp;(12)</option>
	<option value="http://www.hankcs.com/2010/05/"> 2010年五月 &nbsp;(14)</option>
	<option value="http://www.hankcs.com/2010/04/"> 2010年四月 &nbsp;(8)</option>
	<option value="http://www.hankcs.com/2010/03/"> 2010年三月 &nbsp;(16)</option>
	<option value="http://www.hankcs.com/2010/01/"> 2010年一月 &nbsp;(16)</option>
	<option value="http://www.hankcs.com/2009/12/"> 2009年十二月 &nbsp;(33)</option>
	<option value="http://www.hankcs.com/2009/11/"> 2009年十一月 &nbsp;(26)</option>
	<option value="http://www.hankcs.com/2009/09/"> 2009年九月 &nbsp;(2)</option>

		</select>
		</div><div class="widget widget_ui_posts"><h3>热门文章</h3><ul>		<li><a target="_blank" href="http://www.hankcs.com/ml/machine-learning-entry-list.html"><span class="thumbnail"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1ew7s3qoi2uj20h30meaco.jpg" class="thumb" alt="机器学习入门书单" title="机器学习入门书单"></span><span class="text">机器学习入门书单</span><span class="muted">2015-02-04</span><span class="muted">评论(26)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/ml/back-propagation-neural-network.html"><span class="thumbnail"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1exsm4yho09j208c044t8o.jpg" class="thumb" alt="反向传播神经网络极简入门" title="反向传播神经网络极简入门"></span><span class="text">反向传播神经网络极简入门</span><span class="muted">2015-11-08</span><span class="muted">评论(25)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/ml/k-nearest-neighbor-method.html"><span class="thumbnail"><img src="./em-algorithm-and-its-generalization_files/6cbb8645jw1eoxj45stqqg20m80godki.gif" class="thumb" alt="k近邻法" title="k近邻法"></span><span class="text">k近邻法</span><span class="muted">2015-02-06</span><span class="muted">评论(11)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/ml/understanding-the-convolution-in-deep-learning.html"><span class="thumbnail"><img src="./em-algorithm-and-its-generalization_files/006Fmjmcly1fdwjpji6qtj30dw05d0t8.jpg" class="thumb" alt="理解深度学习中的卷积" title="理解深度学习中的卷积"></span><span class="text">理解深度学习中的卷积</span><span class="muted">2017-03-24</span><span class="muted">评论(8)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/ml/naive-bayesian-method.html"><span class="thumbnail"><img src="./em-algorithm-and-its-generalization_files/6cbb8645jw1eozn0y3spcj20mn0h3q3a.jpg" class="thumb" alt="朴素贝叶斯法" title="朴素贝叶斯法"></span><span class="text">朴素贝叶斯法</span><span class="muted">2015-02-09</span><span class="muted">评论(8)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/ml/crf-code-analysis.html"><span class="thumbnail"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f72dgz2npkj21hc0uhwrp.jpg" class="thumb" alt="CRF++代码分析" title="CRF++代码分析"></span><span class="text">CRF++代码分析</span><span class="muted">2016-08-22</span><span class="muted">评论(8)</span></a></li>
</ul></div><div class="widget widget_ui_posts" style="top: 0px;"><h3>最新文章</h3><ul>		<li><a target="_blank" href="http://www.hankcs.com/ml/compile-and-install-tensorflow-from-source.html"><span class="thumbnail"><img src="./em-algorithm-and-its-generalization_files/6cbb8645gw1f9ty3e8d82j20ju0g6jsn.jpg" class="thumb" alt="从源码编译安装TensorFlow" title="从源码编译安装TensorFlow"></span><span class="text">从源码编译安装TensorFlow</span><span class="muted">2017-06-26</span><span class="muted">评论(0)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/ml/hinton-recent-applications-of-deep-neural-nets.html"><span class="thumbnail"><img src="./em-algorithm-and-its-generalization_files/006Fmjmcly1fga3c5iit4j30n40hg0tw.jpg" class="thumb" alt="Hinton神经网络公开课16 Recent applications of deep neural nets" title="Hinton神经网络公开课16 Recent applications of deep neural nets"></span><span class="text">Hinton神经网络公开课16 Recent applications of deep neural nets</span><span class="muted">2017-06-05</span><span class="muted">评论(0)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/ml/hinton-modeling-hierarchical-structure-with-neural-nets.html"><span class="thumbnail"><img src="./em-algorithm-and-its-generalization_files/006Fmjmcly1fg9g1g542jj30z60n07t8.jpg" class="thumb" alt="Hinton神经网络公开课15 Modeling hierarchical structure with neural nets" title="Hinton神经网络公开课15 Modeling hierarchical structure with neural nets"></span><span class="text">Hinton神经网络公开课15 Modeling hierarchical structure with neural nets</span><span class="muted">2017-06-04</span><span class="muted">评论(0)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/ml/nnml-rbm.html"><span class="thumbnail"><img src="./em-algorithm-and-its-generalization_files/006Fmjmcly1fg8ao6kthsj31kw11x48q.jpg" class="thumb" alt="Hinton神经网络公开课编程练习4 Restricted Boltzmann Machines" title="Hinton神经网络公开课编程练习4 Restricted Boltzmann Machines"></span><span class="text">Hinton神经网络公开课编程练习4 Restricted Boltzmann Machines</span><span class="muted">2017-06-03</span><span class="muted">评论(0)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/ml/hinton-deep-neural-nets-with-generative-pre-training.html"><span class="thumbnail"><img src="./em-algorithm-and-its-generalization_files/006Fmjmcly1fg61rho89qj30p00e6gsm.jpg" class="thumb" alt="Hinton神经网络公开课14 Deep neural nets with generative pre-training" title="Hinton神经网络公开课14 Deep neural nets with generative pre-training"></span><span class="text">Hinton神经网络公开课14 Deep neural nets with generative pre-training</span><span class="muted">2017-06-02</span><span class="muted">评论(0)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/ml/hinton-stacking-rbms-to-make-deep-belief-nets.html"><span class="thumbnail"><img src="./em-algorithm-and-its-generalization_files/006Fmjmcly1fg4sosou7jj30zk0aqac0.jpg" class="thumb" alt="Hinton神经网络公开课13 Stacking RBMs to make Deep Belief Nets" title="Hinton神经网络公开课13 Stacking RBMs to make Deep Belief Nets"></span><span class="text">Hinton神经网络公开课13 Stacking RBMs to make Deep Belief Nets</span><span class="muted">2017-05-31</span><span class="muted">评论(0)</span></a></li>
</ul></div><div class="widget widget_text"><h3>订阅关注</h3>			<div class="textwidget"><iframe width="100%" height="400" class="share_self" frameborder="0" scrolling="no" src="./em-algorithm-and-its-generalization_files/index.html"></iframe></div>
		</div><div class="widget widget_ui_tags" style="top: 0px;"><h3>热门标签</h3><div class="d_tags"><a href="http://www.hankcs.com/tag/%e3%80%8a%e6%8c%91%e6%88%98%e7%a8%8b%e5%ba%8f%e8%ae%be%e8%ae%a1%e7%ab%9e%e8%b5%9b%e7%ac%ac2%e7%89%88%e3%80%8b/">《挑战程序设计竞赛(第2版)》 (184)</a><a href="http://www.hankcs.com/tag/%e3%80%8a%e6%97%a5%e8%af%ad%e7%bb%bc%e5%90%88%e6%95%99%e7%a8%8b%e3%80%8b/">《日语综合教程》 (57)</a><a href="http://www.hankcs.com/tag/%e3%80%8a%e6%96%b0%e7%bc%96%e6%97%a5%e8%af%ad%e9%98%85%e8%af%bb%e6%96%87%e9%80%89%e3%80%8b/">《新编日语阅读文选》 (34)</a><a href="http://www.hankcs.com/tag/%e3%80%8a%e6%99%ba%e8%83%bdweb%e7%ae%97%e6%b3%95%e3%80%8b/">《智能Web算法》 (20)</a><a href="http://www.hankcs.com/tag/neural-networks-for-machine-learning/">Neural Networks for Machine Learning (19)</a><a href="http://www.hankcs.com/tag/%e4%b8%ad%e6%96%87%e5%88%86%e8%af%8d/">中文分词 (18)</a><a href="http://www.hankcs.com/tag/wordpress/">WordPress (17)</a><a href="http://www.hankcs.com/tag/cs224n/">CS224n (17)</a><a href="http://www.hankcs.com/tag/%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0/">深度学习 (16)</a><a href="http://www.hankcs.com/tag/lucene/">Lucene (15)</a><a href="http://www.hankcs.com/tag/%e7%bb%b4%e7%89%b9%e6%af%94%e7%ae%97%e6%b3%95/">维特比算法 (15)</a><a href="http://www.hankcs.com/tag/%e6%96%b0%e7%bc%96%e6%97%a5%e8%af%ad%e5%95%86%e5%8a%a1%e8%b4%b8%e6%98%93%e4%bc%9a%e8%af%9d/">新编日语商务贸易会话 (14)</a><a href="http://www.hankcs.com/tag/intellij-idea/">IntelliJ IDEA (13)</a><a href="http://www.hankcs.com/tag/%e3%80%8a%e7%bb%9f%e8%ae%a1%e5%ad%a6%e4%b9%a0%e6%96%b9%e6%b3%95%e3%80%8b/">《统计学习方法》 (12)</a><a href="http://www.hankcs.com/tag/uva/">UVa (11)</a><a href="http://www.hankcs.com/tag/drupal7%e4%b8%93%e4%b8%9a%e5%bc%80%e5%8f%91%e6%8c%87%e5%8d%97-%e7%ac%ac%e4%b8%89%e7%89%88/">Drupal7专业开发指南 第三版 (10)</a><a href="http://www.hankcs.com/tag/%e3%80%8a%e6%8c%91%e6%88%98%e7%bc%96%e7%a8%8b-%e7%a8%8b%e5%ba%8f%e8%ae%be%e8%ae%a1%e7%ab%9e%e8%b5%9b%e8%ae%ad%e7%bb%83%e6%89%8b%e5%86%8c%e3%80%8b/">《挑战编程-程序设计竞赛训练手册》 (10)</a><a href="http://www.hankcs.com/tag/hmm/">HMM (10)</a><a href="http://www.hankcs.com/tag/matlab/">matlab (9)</a><a href="http://www.hankcs.com/tag/cs229/">CS229 (8)</a><a href="http://www.hankcs.com/tag/word2vec/">word2vec (8)</a><a href="http://www.hankcs.com/tag/google-code-jam/">Google code jam (7)</a><a href="http://www.hankcs.com/tag/%e3%80%8ac%e6%a0%87%e5%87%86%e7%a8%8b%e5%ba%8f%e5%ba%93-%e8%87%aa%e4%bf%ae%e6%95%99%e7%a8%8b%e4%b8%8e%e5%8f%82%e8%80%83%e6%89%8b%e5%86%8c%e3%80%8b/">《C++标准程序库—自修教程与参考手册》 (7)</a><a href="http://www.hankcs.com/tag/crf/">CRF (7)</a><a href="http://www.hankcs.com/tag/tensorflow/">TensorFlow (7)</a><a href="http://www.hankcs.com/tag/yii/">Yii (6)</a><a href="http://www.hankcs.com/tag/webrtc/">WebRTC (5)</a><a href="http://www.hankcs.com/tag/cocos2d-x/">Cocos2d-x (5)</a><a href="http://www.hankcs.com/tag/cnn/">CNN (5)</a><a href="http://www.hankcs.com/tag/android/">Android (4)</a></div></div></aside></section>

<div class="branding branding-black">
	<div class="container">
		<h2>我的开源项目</h2>
		<a target="blank" class="btn btn-lg" href="https://github.com/hankcs/HanLP">HanLP自然语言处理包</a><a target="blank" class="btn btn-lg" href="https://github.com/hankcs/AhoCorasickDoubleArrayTrie">基于DoubleArrayTrie的Aho Corasick自动机</a>	</div>
</div>
<footer class="footer">
	<div class="container">
		<div class="fcode">
					</div>
		<p>© 2017 <a href="http://www.hankcs.com/">码农场</a> &nbsp; <a href="http://www.hankcs.com/sitemap.xml">网站地图</a> &nbsp; <a href="http://www.miitbeian.gov.cn/" target="_blank">沪ICP备14002007号-1</a></p>
		<div style="display:none">
<script language="javascript" type="text/javascript" src="./em-algorithm-and-its-generalization_files/trace.js.下载"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-47205472-1', 'auto');
  ga('send', 'pageview');

</script>
<script language="javascript" type="text/javascript" src="./em-algorithm-and-its-generalization_files/15590612.js.下载"></script><a href="http://www.51.la/?15590612" target="_blank" title="51.La 网站流量统计系统"><img alt="51.La 网站流量统计系统" src="./em-algorithm-and-its-generalization_files/icon_2.gif" style="border:none"></a>

<noscript>&lt;a href="//www.51.la/?15590612" target="_blank"&gt;&lt;img alt="&amp;#x6211;&amp;#x8981;&amp;#x5566;&amp;#x514D;&amp;#x8D39;&amp;#x7EDF;&amp;#x8BA1;" src="//img.users.51.la/15590612.asp" style="border:none" /&gt;&lt;/a&gt;</noscript>
</div>	</div>
</footer>

<script>
window.jsui={
    www: 'http://www.hankcs.com',
    uri: 'http://www.hankcs.com/wp-content/themes/dux',
    ver: '1.3',
	roll: ["1","2","6","4"],
    ajaxpager: '500',
    url_rp: 'http://www.hankcs.com/about/'
};
</script>
<script type="text/javascript" src="./em-algorithm-and-its-generalization_files/form.js.下载"></script>
<script type="text/javascript" src="./em-algorithm-and-its-generalization_files/bootstrap.min.js.下载"></script>
<script type="text/javascript" src="./em-algorithm-and-its-generalization_files/loader.js.下载"></script>
<script type="text/javascript" src="./em-algorithm-and-its-generalization_files/wp-embed.min.js.下载"></script>

    <div class="m-mask"></div>    <div class="rollbar" style="display: none;"><ul><li><a href="javascript:(scrollTo());"><i class="fa fa-angle-up"></i></a><h6>去顶部<i></i></h6></li><li><a href="javascript:(on_click_toc_button());"><i class="fa fa-list post_open_icon"></i></a><h6 id="toc_label">打开目录</h6></li><li><a href="javascript:(scrollTo(&#39;#comments&#39;,-15));"><i class="fa fa-comments"></i></a><h6>去评论<i></i></h6></li></ul></div><ul class="m-navbar">
			<li id="menu-item-1834" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1834"><a href="http://www.hankcs.com/program/cpp/">C++</a></li>
<li id="menu-item-1835" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1835"><a href="http://www.hankcs.com/program/java/">Java</a></li>
<li id="menu-item-5754" class="menu-item menu-item-type-taxonomy menu-item-object-category current-post-ancestor current-menu-parent current-post-parent menu-item-5754"><a href="http://www.hankcs.com/ml/">机器学习</a></li>
<li id="menu-item-2954" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-2954"><a href="http://www.hankcs.com/nlp/">NLP</a>
<ul class="sub-menu">
	<li id="menu-item-4344" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-4344"><a href="http://www.hankcs.com/nlp/corpus/">语料库</a></li>
	<li id="menu-item-4342" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-4342"><a href="http://www.hankcs.com/nlp/segment/">中文分词</a></li>
	<li id="menu-item-4343" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-4343"><a href="http://www.hankcs.com/nlp/ner/">命名实体识别</a></li>
	<li id="menu-item-4479" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-4479"><a href="http://www.hankcs.com/nlp/parsing/">句法分析</a></li>
</ul>
</li>
<li id="menu-item-1837" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1837"><a href="http://www.hankcs.com/program/algorithm/">算法</a></li>
<li id="menu-item-1839" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1839"><a href="http://www.hankcs.com/software/">软件</a></li>
<li id="menu-item-1838" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-1838"><a href="http://www.hankcs.com/nihongonote/">日语</a>
<ul class="sub-menu">
	<li id="menu-item-1860" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1860"><a href="http://www.hankcs.com/nihongonote/riyurimen/">日语入门</a></li>
	<li id="menu-item-1861" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1861"><a href="http://www.hankcs.com/nihongonote/listening/">日语听力</a></li>
	<li id="menu-item-1863" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-1863"><a href="http://www.hankcs.com/nihongonote/tekusuto/">日语综合教程</a>
	<ul class="sub-menu">
		<li id="menu-item-2190" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2190"><a href="http://www.hankcs.com/nihongonote/tekusuto/disance/">第三册</a></li>
		<li id="menu-item-2192" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2192"><a href="http://www.hankcs.com/nihongonote/tekusuto/daiyonnsatu/">第四册</a></li>
		<li id="menu-item-2191" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2191"><a href="http://www.hankcs.com/nihongonote/tekusuto/5/">第五册</a></li>
		<li id="menu-item-2702" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2702"><a href="http://www.hankcs.com/nihongonote/tekusuto/%e7%ac%ac%e5%85%ad%e5%86%8c/">第六册</a></li>
		<li id="menu-item-3604" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3604"><a href="http://www.hankcs.com/nihongonote/tekusuto/%e7%ac%ac%e4%b8%83%e5%86%8c/">第七册</a></li>
	</ul>
</li>
	<li id="menu-item-1859" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-1859"><a href="http://www.hankcs.com/nihongonote/fd2/">新编日语阅读文选</a>
	<ul class="sub-menu">
		<li id="menu-item-2187" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2187"><a href="http://www.hankcs.com/nihongonote/fd2/c1/">第一册</a></li>
		<li id="menu-item-2189" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2189"><a href="http://www.hankcs.com/nihongonote/fd2/c2/">第二册</a></li>
		<li id="menu-item-2188" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2188"><a href="http://www.hankcs.com/nihongonote/fd2/c3/">第三册</a></li>
	</ul>
</li>
	<li id="menu-item-1858" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1858"><a href="http://www.hankcs.com/nihongonote/jpkaiwa/">日语商务贸易会话</a></li>
</ul>
</li>
<li id="menu-item-1843" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1843"><a href="http://www.hankcs.com/about/">关于</a></li>
							<li class="navto-search"><a href="javascript:;" class="search-show active"><i class="fa fa-search"></i></a></li>
					</ul>			<div class="sign">			    <div class="sign-mask"></div>			    <div class="container">			        <a href="http://www.hankcs.com/ml/em-algorithm-and-its-generalization.html#" class="close-link signclose-loader"><i class="fa fa-close"></i></a>			        <div class="sign-tips"></div>			        <form id="sign-in">  			            <h3><small class="signup-loader">切换注册</small>登录</h3>			            <h6>			                <label for="inputEmail">用户名或邮箱</label>			                <input type="text" name="username" class="form-control" id="inputEmail" placeholder="用户名或邮箱">			            </h6>			            <h6>			                <label for="inputPassword">密码</label>			                <input type="password" name="password" class="form-control" id="inputPassword" placeholder="登录密码">			            </h6>			            <div class="sign-submit">			                <input type="button" class="btn btn-primary signsubmit-loader" name="submit" value="登录">  			                <input type="hidden" name="action" value="signin">			                <label><input type="checkbox" checked="checked" name="remember" value="forever">记住我</label>			            </div><div class="sign-info"><a href="http://www.hankcs.com/about/">找回密码？</a></div></form>			        <form id="sign-up"> 			            <h3><small class="signin-loader">切换登录</small>注册</h3>			            <h6>			                <label for="inputName">昵称</label>			                <input type="text" name="name" class="form-control" id="inputName" placeholder="设置昵称">			            </h6>			            <h6>			                <label for="inputEmail">邮箱</label>			                <input type="email" name="email" class="form-control" id="inputEmail" placeholder="邮箱">			            </h6>			            <div class="sign-submit">			                <input type="button" class="btn btn-primary btn-block signsubmit-loader" name="submit" value="快速注册">  			                <input type="hidden" name="action" value="signup">  			            </div>			        </form>			    </div>			</div>		</body></html>