<!DOCTYPE html>
<!-- saved from url=(0039)http://www.hankcs.com/nlp/word2vec.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<link rel="dns-prefetch" href="http://apps.bdimg.com/">
<meta http-equiv="X-UA-Compatible" content="IE=11,IE=10,IE=9,IE=8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=0, minimum-scale=1.0, maximum-scale=1.0">
<meta name="apple-mobile-web-app-title" content="码农场">
<meta http-equiv="Cache-Control" content="no-siteapp">
<title>word2vec原理推导与代码分析-码农场</title>
<link rel="dns-prefetch" href="http://apps.bdimg.com/">
<link rel="dns-prefetch" href="http://s.w.org/">
		<script src="./word2vec原理推导与代码分析-码农场_files/ca-pub-1152644711996772.js.下载"></script><script async="" src="./word2vec原理推导与代码分析-码农场_files/analytics.js.下载"></script><script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/2.3\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/2.3\/svg\/","svgExt":".svg","source":{"concatemoji":"http:\/\/www.hankcs.com\/wp-includes\/js\/wp-emoji-release.min.js?ver=4.8.1"}};
			!function(a,b,c){function d(a){var b,c,d,e,f=String.fromCharCode;if(!k||!k.fillText)return!1;switch(k.clearRect(0,0,j.width,j.height),k.textBaseline="top",k.font="600 32px Arial",a){case"flag":return k.fillText(f(55356,56826,55356,56819),0,0),b=j.toDataURL(),k.clearRect(0,0,j.width,j.height),k.fillText(f(55356,56826,8203,55356,56819),0,0),c=j.toDataURL(),b===c&&(k.clearRect(0,0,j.width,j.height),k.fillText(f(55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447),0,0),b=j.toDataURL(),k.clearRect(0,0,j.width,j.height),k.fillText(f(55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447),0,0),c=j.toDataURL(),b!==c);case"emoji4":return k.fillText(f(55358,56794,8205,9794,65039),0,0),d=j.toDataURL(),k.clearRect(0,0,j.width,j.height),k.fillText(f(55358,56794,8203,9794,65039),0,0),e=j.toDataURL(),d!==e}return!1}function e(a){var c=b.createElement("script");c.src=a,c.defer=c.type="text/javascript",b.getElementsByTagName("head")[0].appendChild(c)}var f,g,h,i,j=b.createElement("canvas"),k=j.getContext&&j.getContext("2d");for(i=Array("flag","emoji4"),c.supports={everything:!0,everythingExceptFlag:!0},h=0;h<i.length;h++)c.supports[i[h]]=d(i[h]),c.supports.everything=c.supports.everything&&c.supports[i[h]],"flag"!==i[h]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[i[h]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(g=function(){c.readyCallback()},b.addEventListener?(b.addEventListener("DOMContentLoaded",g,!1),a.addEventListener("load",g,!1)):(a.attachEvent("onload",g),b.attachEvent("onreadystatechange",function(){"complete"===b.readyState&&c.readyCallback()})),f=c.source||{},f.concatemoji?e(f.concatemoji):f.wpemoji&&f.twemoji&&(e(f.twemoji),e(f.wpemoji)))}(window,document,window._wpemojiSettings);
		</script><script src="./word2vec原理推导与代码分析-码农场_files/wp-emoji-release.min.js.下载" type="text/javascript" defer=""></script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
<link rel="stylesheet" id="_bootstrap-css" href="./word2vec原理推导与代码分析-码农场_files/bootstrap.min.css" type="text/css" media="all">
<link rel="stylesheet" id="_fontawesome-css" href="./word2vec原理推导与代码分析-码农场_files/font-awesome.min.css" type="text/css" media="all">
<link rel="stylesheet" id="_main-css" href="./word2vec原理推导与代码分析-码农场_files/main.css" type="text/css" media="all">
<script type="text/javascript" src="./word2vec原理推导与代码分析-码农场_files/jquery.min.js.下载"></script>
<link rel="https://api.w.org/" href="http://www.hankcs.com/wp-json/">
<link rel="prev" title="基于信息熵和互信息的新词识别" href="http://www.hankcs.com/nlp/new-word-discovery.html">
<link rel="next" title="隐马尔可夫模型" href="http://www.hankcs.com/ml/hidden-markov-model.html">
<link rel="canonical" href="http://www.hankcs.com/nlp/word2vec.html">
<link rel="shortlink" href="http://www.hankcs.com/?p=7502">
<link rel="alternate" type="application/json+oembed" href="http://www.hankcs.com/wp-json/oembed/1.0/embed?url=http%3A%2F%2Fwww.hankcs.com%2Fnlp%2Fword2vec.html">
<link rel="alternate" type="text/xml+oembed" href="http://www.hankcs.com/wp-json/oembed/1.0/embed?url=http%3A%2F%2Fwww.hankcs.com%2Fnlp%2Fword2vec.html&amp;format=xml">
<meta name="keywords" content="自然语言处理">
<meta name="description" content="本文摘录整编了一些理论介绍，推导了word2vec中的数学原理；并考察了一些常见的word2vec实现，评测其准确率等性能，最后分析了word2vec原版C代码；针对没有好用的Java实现的现状，移植了原版C程序到Java。时间和水平有限，本文没有就其发展历史展开多谈，只记录了必要的知识点，并着重关注工程实践。虽然我的Java方案速度比原版C程序高出1倍，在">
<link rel="icon" href="http://www.hankcs.com/wp-content/uploads/2017/04/cropped-Hankcs_512-32x32.png" sizes="32x32">
<link rel="icon" href="http://www.hankcs.com/wp-content/uploads/2017/04/cropped-Hankcs_512-192x192.png" sizes="192x192">
<link rel="apple-touch-icon-precomposed" href="http://www.hankcs.com/wp-content/uploads/2017/04/cropped-Hankcs_512-180x180.png">
<meta name="msapplication-TileImage" content="http://www.hankcs.com/wp-content/uploads/2017/04/cropped-Hankcs_512-270x270.png">
<link rel="shortcut icon" href="http://www.hankcs.com/favicon.ico">
<!--[if lt IE 9]><script src="http://www.hankcs.com/wp-content/themes/dux/js/libs/html5.min.js"></script><![endif]-->
<!--
	generated 5862 seconds ago
	generated in 0.247 seconds
	served from batcache in 0.003 seconds
	expires in 80538 seconds
-->
<script async="" data-requirecontext="_" data-requiremodule="main" src="./word2vec原理推导与代码分析-码农场_files/main.js.下载"></script><script src="./word2vec原理推导与代码分析-码农场_files/share.js.下载"></script><script async="" data-requirecontext="_" data-requiremodule="lazyload" src="./word2vec原理推导与代码分析-码农场_files/lazyload.min.js.下载"></script><script async="" data-requirecontext="_" data-requiremodule="prettyprint" src="./word2vec原理推导与代码分析-码农场_files/prettyprint.js.下载"></script><script async="" data-requirecontext="_" data-requiremodule="signpop" src="./word2vec原理推导与代码分析-码农场_files/signpop.js.下载"></script><script async="" data-requirecontext="_" data-requiremodule="comment" src="./word2vec原理推导与代码分析-码农场_files/comment.js.下载"></script><link href="./word2vec原理推导与代码分析-码农场_files/share.css" rel="styleSheet" type="text/css"></head>
<body class="post-template-default single single-post postid-7502 single-format-standard comment-open site-layout-2">
<header class="header">
	<div class="container">
		<div class="logo"><a href="http://www.hankcs.com/" title="码农场-自然语言处理、机器学习算法"><img src="./word2vec原理推导与代码分析-码农场_files/logo.png">码农场</a></div>		<a href="http://www.hankcs.com/" title="码农场-自然语言处理、机器学习算法" class="brand">放牧代码和思想
<br>专注自然语言处理、机器学习算法</a>		<ul class="site-nav site-navbar">
			<li id="menu-item-1834" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1834"><a href="http://www.hankcs.com/program/cpp/">C++</a></li>
<li id="menu-item-1835" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1835"><a href="http://www.hankcs.com/program/java/">Java</a></li>
<li id="menu-item-5754" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-5754"><a href="http://www.hankcs.com/ml/">机器学习</a></li>
<li id="menu-item-2954" class="menu-item menu-item-type-taxonomy menu-item-object-category current-post-ancestor current-menu-parent current-post-parent menu-item-has-children menu-item-2954"><a href="http://www.hankcs.com/nlp/">NLP</a>
<ul class="sub-menu">
	<li id="menu-item-4344" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-4344"><a href="http://www.hankcs.com/nlp/corpus/">语料库</a></li>
	<li id="menu-item-4342" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-4342"><a href="http://www.hankcs.com/nlp/segment/">中文分词</a></li>
	<li id="menu-item-4343" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-4343"><a href="http://www.hankcs.com/nlp/ner/">命名实体识别</a></li>
	<li id="menu-item-4479" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-4479"><a href="http://www.hankcs.com/nlp/parsing/">句法分析</a></li>
</ul>
</li>
<li id="menu-item-1837" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1837"><a href="http://www.hankcs.com/program/algorithm/">算法</a></li>
<li id="menu-item-1839" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1839"><a href="http://www.hankcs.com/software/">软件</a></li>
<li id="menu-item-1838" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-1838"><a href="http://www.hankcs.com/nihongonote/">日语</a>
<ul class="sub-menu">
	<li id="menu-item-1860" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1860"><a href="http://www.hankcs.com/nihongonote/riyurimen/">日语入门</a></li>
	<li id="menu-item-1861" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1861"><a href="http://www.hankcs.com/nihongonote/listening/">日语听力</a></li>
	<li id="menu-item-1863" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-1863"><a href="http://www.hankcs.com/nihongonote/tekusuto/">日语综合教程</a>
	<ul class="sub-menu">
		<li id="menu-item-2190" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2190"><a href="http://www.hankcs.com/nihongonote/tekusuto/disance/">第三册</a></li>
		<li id="menu-item-2192" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2192"><a href="http://www.hankcs.com/nihongonote/tekusuto/daiyonnsatu/">第四册</a></li>
		<li id="menu-item-2191" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2191"><a href="http://www.hankcs.com/nihongonote/tekusuto/5/">第五册</a></li>
		<li id="menu-item-2702" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2702"><a href="http://www.hankcs.com/nihongonote/tekusuto/%e7%ac%ac%e5%85%ad%e5%86%8c/">第六册</a></li>
		<li id="menu-item-3604" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3604"><a href="http://www.hankcs.com/nihongonote/tekusuto/%e7%ac%ac%e4%b8%83%e5%86%8c/">第七册</a></li>
	</ul>
</li>
	<li id="menu-item-1859" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-1859"><a href="http://www.hankcs.com/nihongonote/fd2/">新编日语阅读文选</a>
	<ul class="sub-menu">
		<li id="menu-item-2187" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2187"><a href="http://www.hankcs.com/nihongonote/fd2/c1/">第一册</a></li>
		<li id="menu-item-2189" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2189"><a href="http://www.hankcs.com/nihongonote/fd2/c2/">第二册</a></li>
		<li id="menu-item-2188" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2188"><a href="http://www.hankcs.com/nihongonote/fd2/c3/">第三册</a></li>
	</ul>
</li>
	<li id="menu-item-1858" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1858"><a href="http://www.hankcs.com/nihongonote/jpkaiwa/">日语商务贸易会话</a></li>
</ul>
</li>
<li id="menu-item-1843" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1843"><a href="http://www.hankcs.com/about/">关于</a></li>
							<li class="navto-search"><a href="javascript:;" class="search-show active"><i class="fa fa-search"></i></a></li>
					</ul>
		<div class="topbar">
			<ul class="site-nav topmenu">
				<li id="menu-item-5755" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-5755"><a href="http://www.hankcs.com/about/#comments"><i class="fa fa-comment"></i> 留言板</a></li>
				<li><a target="_blank" rel="external nofollow" href="https://github.com/hankcs"><i class="fa fa-github-alt"></i> GitHub</a></li>                                <li><a target="_blank" rel="external nofollow" href="http://weibo.com/hankcs"><i class="fa fa-weibo"></i> 微博</a></li>                                <li><a target="_blank" rel="external nofollow" href="https://twitter.com/hankcs"><i class="fa fa-twitter"></i> Twitter</a></li>                                <li><a target="_blank" href="http://www.hankcs.com/feed"><i class="fa fa-rss"></i> RSS订阅</a></li>			</ul>
							&nbsp; &nbsp; <i class="fa fa-bullhorn url"></i> <a href="http://www.hankcs.com/about/" target="_blank">我是一个浪人，这里是我的个人博客。我没有师门，都是瞎写的，不用太认真，也不要过于期待。</a><a href="http://www.hankcs.com/about/#comments" target="_blank" textvalue="">留言板</a>。					</div>
		<i class="fa fa-bars m-icon-nav"></i>
	</div>
</header>
<div class="site-search">
	<div class="container">
		<form method="get" class="site-search-form" action="http://www.hankcs.com/"><input class="search-input" name="s" type="text" placeholder="输入关键字" value=""><button class="search-btn" type="submit"><i class="fa fa-search"></i></button></form>	</div>
</div><section class="container">
	<div class="content-wrap">
	<div class="content">
				<header class="article-header">
			<h1 class="article-title"><a href="http://www.hankcs.com/nlp/word2vec.html">word2vec原理推导与代码分析</a></h1>
			<div class="article-meta">
				<span class="item">
					<a href="http://www.hankcs.com/">码农场</a> <small>&gt;</small> <a href="http://www.hankcs.com/nlp/">自然语言处理</a><span class="muted"></span>				</span>
				<span class="item">2016-07-21</span>
																<span class="item post-views">阅读(3904)</span>				<span class="item"><a class="pc" href="http://www.hankcs.com/nlp/word2vec.html#respond">评论(8)</a></span>				<span class="item"></span>
			</div>
		</header>
		<article class="article-content">
			<div class="asb asb-post asb-post-01"><script async="" src="./word2vec原理推导与代码分析-码农场_files/adsbygoogle.js.下载"></script>
<!-- 文章页 - 页面标题下 728 90 -->
<ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-1152644711996772" data-ad-slot="5413029241" data-adsbygoogle-status="done"><ins id="aswift_0_expand" style="display:inline-table;border:none;height:90px;margin:0;padding:0;position:relative;visibility:visible;width:728px;background-color:transparent"><ins id="aswift_0_anchor" style="display:block;border:none;height:90px;margin:0;padding:0;position:relative;visibility:visible;width:728px;background-color:transparent"><iframe width="728" height="90" frameborder="0" marginwidth="0" marginheight="0" vspace="0" hspace="0" allowtransparency="true" scrolling="no" allowfullscreen="true" onload="var i=this.id,s=window.google_iframe_oncopy,H=s&amp;&amp;s.handlers,h=H&amp;&amp;H[i],w=this.contentWindow,d;try{d=w.document}catch(e){}if(h&amp;&amp;d&amp;&amp;(!d.body||!d.body.firstChild)){if(h.call){setTimeout(h,0)}else if(h.match){try{h=s.upd(h,i)}catch(e){}w.location.replace(h)}}" id="aswift_0" name="aswift_0" style="left:0;position:absolute;top:0;width:728px;height:90px;" src="./word2vec原理推导与代码分析-码农场_files/saved_resource.html"></iframe></ins></ins></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></div>			<div class="post_nav" style="width: 0px;"><div class="post_nav_side" style="height: 100%;"><div class="post_nav_top"><p>目录</p></div><div class="post_nav_bottom"></div><span class="post_nav_close icon-remove" title="关闭目录" style="opacity: 0; display: none;"><i class="fa fa-times"></i></span></div><ul class="post_nav_content"><li class="h2_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h2-0">背景</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-1">语言模型</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-2">word2vec</a><i class="post_nav_dot"></i></li>
<li class="h2_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h2-3">Hierarchical Softmax</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-4">模型共同点</a><i class="post_nav_dot"></i></li>
<li class="h3_nav active"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-5">CBOW</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-6">Skip-gram</a><i class="post_nav_dot"></i></li>
<li class="h2_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h2-7">Negative Sampling</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-8">CBOW</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-9">Skip-gram</a><i class="post_nav_dot"></i></li>
<li class="h2_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h2-10">更多细节</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-11">Huffman树</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-12">负采样算法</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-13">sigmoid函数</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-14">多线程</a><i class="post_nav_dot"></i></li>
<li class="h2_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h2-15">一些开源实现</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-16">C</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-17">C++</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-18">Java</a><i class="post_nav_dot"></i></li>
<li class="h2_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h2-19">我的Java方案</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-20">参数</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-21">训练速度</a><i class="post_nav_dot"></i></li>
<li class="h3_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h3-22">准确率</a><i class="post_nav_dot"></i></li>
<li class="h2_nav"><a href="http://www.hankcs.com/nlp/word2vec.html#h2-23">Reference</a><i class="post_nav_dot"></i></li>
</ul></div><p style="text-indent: 2em;">本文摘录整编了一些理论介绍，推导了word2vec中的数学原理；并考察了<span style="text-indent: 32px;">一些常见的word2vec实现，评测其准确率等性能，最后</span>分析了word2vec原版C代码；针对没有好用的Java实现的现状，移植了原版C程序到Java。时间和水平有限，本文没有就其发展历史展开多谈，只记录了必要的知识点，并着重关注工程实践。</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5tns7711ej20j90dkdjx.jpg" title="word2vec_diagram.png" alt="word2vec_diagram.png" data-tag="bdshare"></p>
<p style="text-indent: 2em;">虽然我的<span style="text-indent: 32px;">Java方案</span>速度比原版C程序高出1倍，在算法代码与原版C程序一致的情况下准确率仍然略低于原版C程序（不过依然是目前准确率最高的Java实现），并非完美，还有待改进。</p>
<p style="text-indent: 2em;">本文的理论部分大量参考《word2vec中的数学原理详解》，按照我这种初学者方便理解的顺序重新编排、重新叙述。题图来自<span style="text-indent: 32px;">siegfang的博客。我提出的Java方案基于<a href="https://github.com/kojisekig/word2vec-lucene" _src="https://github.com/kojisekig/word2vec-lucene" target="_blank" rel="external nofollow" style="text-indent: 32px; white-space: normal;">kojisekig</a>，我们还在跟进准确率的问题。</span></p>
<h2 id="h2-0">背景<br></h2>
<h3 id="h3-1">语言模型</h3>
<p style="text-indent: 2em;">在统计自然语言处理中，语言模型指的是计算一个句子的概率模型。</p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">传统的语言模型中词的表示是原始的、面向字符串的。两个语义相似的词的字符串可能完全不同，比如“番茄”和“西红柿”。这给所有NLP任务都带来了挑战——字符串本身无法储存语义信息。该挑战突出表现在模型的平滑问题上：标注语料是有限的，而语言整体是无限的，传统模型无法借力未标注的海量语料，只能靠人工设计平滑算法，而这些算法往往效果甚微。</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">神经概率语言模型（Neural Probabilistic Language Model）中词的表示是向量形式、面向语义的。两个语义相似的词对应的向量也是相似的，具体反映在夹角或距离上。甚至一些语义相似的二元词组中的词语对应的向量做线性减法之后得到的向量依然是相似的。词的向量表示可以显著提高传统NLP任务的性能，例如《</span><a href="http://www.hankcs.com/nlp/parsing/neural-network-based-dependency-parser.html"><span style="text-indent: 2em;">基于神经网络的高性能依存句法分析器</span></a><span style="text-indent: 2em;">》中介绍的词、词性、依存关系的向量化对正确率的提升等。</span></p>
<p style="text-indent: 2em;">从向量的角度来看，字符串形式的词语其实是更高维、更稀疏的向量。若词汇表大小为N，每个字符串形式的词语字典序为i，则其被表示为一个N维向量，该向量的第i维为1，其他维都为0。汉语的词汇量大约在十万这个量级，十万维的向量对计算来讲绝对是个维度灾难。而word2vec得到的词的向量形式（下文简称“词向量”，更学术化的翻译是“词嵌入”）则可以自由控制维度，一般是100左右。</p>
<h3 id="h3-2"><span style="text-indent: 2em;">word2vec</span></h3>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">word2vec作为神经概率语言模型的输入，其本身其实是神经概率模型的副产品，是为了通过神经网络学习<strong>某个语言模型</strong>而产生的中间结果。具体来说，“某个语言模型”指的是“CBOW”和“Skip-gram”。具体学习过程会用到两个降低复杂度的近似方法——Hierarchical Softmax或Negative Sampling。两个模型乘以两种方法，一共有四种实现。这些内容就是本文理论部分要详细阐明的全部了。</span></p>
<h2 id="h2-3"><span style="text-indent: 2em;"><span style="text-indent: 32px;">Hierarchical Softmax</span></span></h2>
<h3 id="h3-4">模型共同点</h3>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">无论是哪种模型，其基本网络结构都是在下图的基础上，省略掉hidden layer：</span></p>
<p style="text-align:center"><span style="text-indent: 2em;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5to0uwydsj216i0ikdi3.jpg" title="屏幕快照 2016-07-14 下午7.30.23.png" alt="屏幕快照 2016-07-14 下午7.30.23.png" width="512" height="224" border="0" vspace="0" style="width: 512px; height: 224px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">为什么要去掉这一层呢？据说是因为word2vec的作者嫌从hidden layer到output layer的矩阵运算太多了。于是两种模型的网络结构是：</span></p>
<p style="text-align:center"><span style="text-indent: 2em;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5to6e5d9lj216c0qkwhk.jpg" title="屏幕快照 2016-07-14 下午7.27.35.png" alt="屏幕快照 2016-07-14 下午7.27.35.png" width="512" height="321" border="0" vspace="0" style="width: 512px; height: 321px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">其中w(t)代表当前词语位于句子的位置t，同理定义其他记号。在窗口内（上图为窗口大小为5），除了当前词语之外的其他词语共同构成上下文。</span></p>
<h3 id="h3-5"><span style="text-indent: 2em;">CBOW</span></h3>
<h4 style="text-indent: 2em;">原理</h4>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">CBOW 是 Continuous Bag-of-Words Model 的缩写，是一种根据上下文的词语预测当前词语的出现概率的模型。其图示如上图左。</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">CBOW是已知上下文，估算当前词语的语言模型。其学习目标是最大化对数似然函数：</span></p>
<p style="text-align:center"><span style="text-indent: 2em;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5tocs4lykj20fa03aaa8.jpg" title="屏幕快照 2016-07-14 下午7.45.11.png" alt="屏幕快照 2016-07-14 下午7.45.11.png" width="233" height="50" border="0" vspace="0" style="width: 233px; height: 50px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">其中，w表示语料库C中任意一个词。从上图可以看出，对于CBOW，</span></p>
<p style="text-indent: 2em;"><strong><span style="text-indent: 2em;">输入层</span></strong><span style="text-indent: 2em;">是上下文的词语的词向量（什么！我们不是在训练词向量吗？不不不，我们是在训练CBOW模型，词向量只是个副产品，确切来说，是CBOW模型的一个参数。<span style="text-indent: 32px;">训练开始的时候，词向量是个随机值，随着训练的进行不断被更新）。</span></span></p>
<p style="text-indent: 2em;"><strong><span style="text-indent: 2em;">投影层</span></strong><span style="text-indent: 2em;">对其求和，所谓求和，就是简单的向量加法。</span></p>
<p style="text-indent: 2em;"><strong><span style="text-indent: 2em;">输出层</span></strong><span style="text-indent: 2em;">输出最可能的w。</span><span style="text-indent: 2em;">由于语料库中词汇量是固定的|C|个，所以上述过程其实可以看做一个多分类问题。给定特征，从|C|个分类中挑一个。</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">对于神经网络模型多分类，最朴素的做法是softmax回归：</span></p>
<p style="text-align:center"><span style="text-indent: 2em;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1exxdsuugv1j20cl033jrj.jpg" title="神经网络依存句法分析29.png" alt="神经网络依存句法分析29.png" style="line-height: 16px; text-align: center; text-indent: 32px; white-space: normal;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;">softmax回归需要对语料库中每个词语（类）都计算一遍输出概率并进行归一化，在几十万词汇量的语料上无疑是令人头疼的。</p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">不用softmax怎么样？比如SVM中的多分类，我们都知道其多分类是由二分类组合而来的：</span></p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wmvf9tbrg20bf08mq30.gif" title="svm_多分类.gif" alt="svm_多分类.gif" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">这是一种二叉树结构，应用到word2vec中被作者称为Hierarchical Softmax：</span></p>
<p style="text-align:center"><span style="text-indent: 2em;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wmy4jdnwj214w12a42v.jpg" title="屏幕快照 2016-07-17 上午9.13.40.png" alt="屏幕快照 2016-07-17 上午9.13.40.png" width="512" height="479" border="0" vspace="0" style="width: 512px; height: 479px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">上图输出层的树形结构即为<span style="text-indent: 32px;">Hierarchical Softmax。</span></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;"><span style="text-indent: 32px;">非叶子节点相当于一个神经元（感知机，我认为逻辑斯谛回归就是感知机的输出代入f(x)=1/(1+e^x)），二分类决策输出1或0，分别代表向下左转或向下右转；<span style="text-indent: 32px;">每个叶子节点代表语料库中的一个词语，于是每个词语都可以被01唯一地编码，并且其编码序列对应一个事件序列，于是我们可以计算条件概率<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wofvax07j208u0283yg.jpg" title="屏幕快照 2016-07-17 上午10.05.33.png" alt="屏幕快照 2016-07-17 上午10.05.33.png" width="87" height="22" border="0" vspace="0" style="width: 87px; height: 22px;" data-tag="bdshare">。</span></span></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;"><span style="text-indent: 32px;"><span style="text-indent: 32px;">在开始计算之前，还是得引入一些符号：</span></span></span></p>
<ol class=" list-paddingleft-2" style="list-style-type: decimal;">
<li>
<p><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wo9rldvej201o01kt8h.jpg" title="屏幕快照 2016-07-17 上午9.59.45.png" alt="屏幕快照 2016-07-17 上午9.59.45.png" width="23" height="22" border="0" vspace="0" style="width: 23px; height: 22px;" data-tag="bdshare">从根结点出发到达w对应叶子结点的路径.</p>
</li>
<li>
<p><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5woa6hrx9j201c01ojr5.jpg" title="屏幕快照 2016-07-17 上午10.00.06.png" alt="屏幕快照 2016-07-17 上午10.00.06.png" width="18" height="22" border="0" vspace="0" style="white-space: normal; width: 18px; height: 22px;" data-tag="bdshare">路径中包含结点的个数</p>
</li>
<li>
<p><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wobigm5sj207m01wmx3.jpg" title="屏幕快照 2016-07-17 上午10.01.17.png" alt="屏幕快照 2016-07-17 上午10.01.17.png" width="89" height="22" border="0" vspace="0" style="width: 89px; height: 22px;" data-tag="bdshare">路径<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wo9rldvej201o01kt8h.jpg" title="屏幕快照 2016-07-17 上午9.59.45.png" alt="屏幕快照 2016-07-17 上午9.59.45.png" width="23" height="22" border="0" vspace="0" style="white-space: normal; width: 23px; height: 22px;" data-tag="bdshare">中的各个节点</p>
</li>
<li>
<p><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5woco1brlj20c001ywei.jpg" title="屏幕快照 2016-07-17 上午10.02.33.png" alt="屏幕快照 2016-07-17 上午10.02.33.png" width="136" height="22" border="0" vspace="0" style="width: 136px; height: 22px;" data-tag="bdshare">词w的编码，<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wodgv934j201q020742.jpg" title="屏幕快照 2016-07-17 上午10.03.27.png" alt="屏幕快照 2016-07-17 上午10.03.27.png" width="19" height="22" border="0" vspace="0" style="width: 19px; height: 22px;" data-tag="bdshare">表示路径<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wo9rldvej201o01kt8h.jpg" title="屏幕快照 2016-07-17 上午9.59.45.png" alt="屏幕快照 2016-07-17 上午9.59.45.png" width="23" height="22" border="0" vspace="0" style="white-space: normal; width: 23px; height: 22px;" data-tag="bdshare">第j个节点对应的编码（根节点无编码）</p>
</li>
<li>
<p><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5woefv8p6j20bo01udfv.jpg" title="屏幕快照 2016-07-17 上午10.04.18.png" alt="屏幕快照 2016-07-17 上午10.04.18.png" width="140" height="22" border="0" vspace="0" style="width: 140px; height: 22px;" data-tag="bdshare">路径<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wo9rldvej201o01kt8h.jpg" title="屏幕快照 2016-07-17 上午9.59.45.png" alt="屏幕快照 2016-07-17 上午9.59.45.png" width="23" height="22" border="0" vspace="0" style="white-space: normal; width: 23px; height: 22px;" data-tag="bdshare">中非叶节点对应的参数向量</p>
<p>于是可以给出w的条件概率：</p>
<p></p>
</li>
</ol>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wohk3pi7j20ka042t91.jpg" title="屏幕快照 2016-07-17 上午10.07.18.png" alt="屏幕快照 2016-07-17 上午10.07.18.png" width="275" height="55" border="0" vspace="0" style="width: 275px; height: 55px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">这是个简单明了的式子，从根节点到叶节点经过了<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5woa6hrx9j201c01ojr5.jpg" title="屏幕快照 2016-07-17 上午10.00.06.png" alt="屏幕快照 2016-07-17 上午10.00.06.png" width="18" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 18px; height: 22px;" data-tag="bdshare">-1个节点，编码从下标2开始（根节点无编码），对应的参数向量下标从1开始（根节点为1）。</p>
<p style="text-indent: 2em;">其中，每一项是一个逻辑斯谛回归：</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5woq5oeojj20pm05yt9a.jpg" title="屏幕快照 2016-07-17 上午10.15.37.png" alt="屏幕快照 2016-07-17 上午10.15.37.png" width="331" height="77" border="0" vspace="0" style="width: 331px; height: 77px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">考虑到d只有0和1两种取值，我们可以用指数形式方便地将其写到一起：</p>
<p style="text-align:center"><span style="text-indent: 2em;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wowc2oi2j20qm02mjrs.jpg" title="屏幕快照 2016-07-17 上午10.21.31.png" alt="屏幕快照 2016-07-17 上午10.21.31.png" width="337" height="33" border="0" vspace="0" style="width: 337px; height: 33px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">我们的目标函数取对数似然：<br></span></p>
<p style="text-align:center"><span style="text-indent: 2em;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5woyikyp0j20fc03kgls.jpg" title="屏幕快照 2016-07-17 上午10.23.25.png" alt="屏幕快照 2016-07-17 上午10.23.25.png" width="190" height="44" border="0" vspace="0" style="width: 190px; height: 44px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">将<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wofvax07j208u0283yg.jpg" title="屏幕快照 2016-07-17 上午10.05.33.png" alt="屏幕快照 2016-07-17 上午10.05.33.png" width="131" height="33" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 131px; height: 33px;" data-tag="bdshare">代入上式，有</span></p>
<p style="text-align:center"><span style="text-indent: 2em;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wp0mws5gj20zi086gn9.jpg" title="屏幕快照 2016-07-17 上午10.25.37.png" alt="屏幕快照 2016-07-17 上午10.25.37.png" width="383" height="88" border="0" vspace="0" style="width: 383px; height: 88px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;">这也很直白，连乘的对数换成求和。不过还是有点长，我们把每一项简记为：</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wp2ahoblj20ug02adge.jpg" title="屏幕快照 2016-07-17 上午10.27.15.png" alt="屏幕快照 2016-07-17 上午10.27.15.png" width="441" height="33" border="0" vspace="0" style="width: 441px; height: 33px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">怎么最大化对数似然函数呢？分别最大化每一项即可（这应该是一种近似，最大化某一项不一定使整体增大，具体收敛的证明还不清楚）。怎么最大化每一项呢？先求函数对每个变量的偏导数，对每一个样本，代入偏导数表达式得到函数在该维度的增长梯度，然后让对应参数加上这个梯度，函数在这个维度上就增长了。这种白话描述的算法在学术上叫随机梯度上升法，详见<a href="http://www.hankcs.com/ml/the-logistic-regression-and-the-maximum-entropy-model.html#h3-6" target="_blank">更规范的描述</a>。</p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">每一项有两个参数，一个是每个节点的参数向量<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wpyg370hj202i022t8i.jpg" title="屏幕快照 2016-07-17 上午10.58.10.png" alt="屏幕快照 2016-07-17 上午10.58.10.png" width="34" height="28" border="0" vspace="0" style="width: 34px; height: 28px;" data-tag="bdshare">，另一个是输出层的输入<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wps67xq7j201m01kmwx.jpg" title="屏幕快照 2016-07-17 上午10.52.10.png" alt="屏幕快照 2016-07-17 上午10.52.10.png" width="23" height="22" border="0" vspace="0" style="width: 23px; height: 22px;" data-tag="bdshare">，我们分别对其求偏导数：</span></p>
<p style="text-align:center"><span style="text-indent: 2em;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wpt4xg8tj212603q756.jpg" title="屏幕快照 2016-07-17 上午10.52.59.png" alt="屏幕快照 2016-07-17 上午10.52.59.png" width="451" height="44" border="0" vspace="0" style="width: 451px; height: 44px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;">因为sigmoid函数的导数有个很棒的形式：</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wpus333qj20bi02gmx5.jpg" title="屏幕快照 2016-07-17 上午10.54.30.png" alt="屏幕快照 2016-07-17 上午10.54.30.png" width="155" height="33" border="0" vspace="0" style="width: 155px; height: 33px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">于是代入上上式得到：</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wpwixaknj20ne02kt93.jpg" title="屏幕快照 2016-07-17 上午10.56.15.png" alt="屏幕快照 2016-07-17 上午10.56.15.png" width="302" height="33" border="0" vspace="0" style="width: 302px; height: 33px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">合并同类项得到：<br></span></p>
<p style="text-align:center"><span style="text-indent: 2em;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wpxj61wjj20co02k0ss.jpg" title="屏幕快照 2016-07-17 上午10.57.17.png" alt="屏幕快照 2016-07-17 上午10.57.17.png" width="164" height="33" border="0" vspace="0" style="width: 164px; height: 33px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">于是<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wpyg370hj202i022t8i.jpg" title="屏幕快照 2016-07-17 上午10.58.10.png" alt="屏幕快照 2016-07-17 上午10.58.10.png" width="34" height="28" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 34px; height: 28px;" data-tag="bdshare">的更新表达式就得到了：</span></p>
<p style="text-align:center"><span style="text-indent: 2em;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wpzj0m0zj20l2026t90.jpg" title="屏幕快照 2016-07-17 上午10.59.08.png" alt="屏幕快照 2016-07-17 上午10.59.08.png" width="321" height="33" border="0" vspace="0" style="width: 321px; height: 33px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">其中，<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wq02oflgj201e01k741.jpg" title="屏幕快照 2016-07-17 上午10.59.48.png" alt="屏幕快照 2016-07-17 上午10.59.48.png" width="20" height="22" border="0" vspace="0" style="width: 20px; height: 22px;" data-tag="bdshare">是机器学习的老相好——学习率，通常取0-1之间的一个值。学习率越大训练速度越快，但目标函数容易在局部区域来回抖动。</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">再来<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wps67xq7j201m01kmwx.jpg" title="屏幕快照 2016-07-17 上午10.52.10.png" alt="屏幕快照 2016-07-17 上午10.52.10.png" width="23" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 23px; height: 22px;" data-tag="bdshare">的偏导数，注意到<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wp2ahoblj20ug02adge.jpg" title="屏幕快照 2016-07-17 上午10.27.15.png" alt="屏幕快照 2016-07-17 上午10.27.15.png" width="441" height="33" border="0" vspace="0" style="text-align: center; white-space: normal; width: 441px; height: 33px;" data-tag="bdshare">中<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wps67xq7j201m01kmwx.jpg" title="屏幕快照 2016-07-17 上午10.52.10.png" alt="屏幕快照 2016-07-17 上午10.52.10.png" width="23" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 23px; height: 22px;" data-tag="bdshare">和<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wpyg370hj202i022t8i.jpg" title="屏幕快照 2016-07-17 上午10.58.10.png" alt="屏幕快照 2016-07-17 上午10.58.10.png" width="34" height="28" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 34px; height: 28px;" data-tag="bdshare">是对称的，所有直接将<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wpyg370hj202i022t8i.jpg" title="屏幕快照 2016-07-17 上午10.58.10.png" alt="屏幕快照 2016-07-17 上午10.58.10.png" width="34" height="28" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 34px; height: 28px;" data-tag="bdshare">的偏导数中的<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wpyg370hj202i022t8i.jpg" title="屏幕快照 2016-07-17 上午10.58.10.png" alt="屏幕快照 2016-07-17 上午10.58.10.png" width="34" height="28" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 34px; height: 28px;" data-tag="bdshare">替换为<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wps67xq7j201m01kmwx.jpg" title="屏幕快照 2016-07-17 上午10.52.10.png" alt="屏幕快照 2016-07-17 上午10.52.10.png" width="23" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 23px; height: 22px;" data-tag="bdshare">，得到关于<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wps67xq7j201m01kmwx.jpg" title="屏幕快照 2016-07-17 上午10.52.10.png" alt="屏幕快照 2016-07-17 上午10.52.10.png" width="23" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 23px; height: 22px;" data-tag="bdshare">的偏导数：</span></p>
<p style="text-align:center"><span style="text-indent: 2em;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wq5cfqknj20je03qt92.jpg" title="屏幕快照 2016-07-17 上午11.04.49.png" alt="屏幕快照 2016-07-17 上午11.04.49.png" width="229" height="44" border="0" vspace="0" style="width: 229px; height: 44px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">于是<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wps67xq7j201m01kmwx.jpg" title="屏幕快照 2016-07-17 上午10.52.10.png" alt="屏幕快照 2016-07-17 上午10.52.10.png" width="23" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 23px; height: 22px;" data-tag="bdshare">的更新表达式也得到了。</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">不过<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wps67xq7j201m01kmwx.jpg" title="屏幕快照 2016-07-17 上午10.52.10.png" alt="屏幕快照 2016-07-17 上午10.52.10.png" width="23" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 23px; height: 22px;" data-tag="bdshare">是上下文的词向量的和，不是上下文单个词的词向量。怎么把这个更新量应用到单个词的词向量上去呢？word2vec采取的是直接将<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wps67xq7j201m01kmwx.jpg" title="屏幕快照 2016-07-17 上午10.52.10.png" alt="屏幕快照 2016-07-17 上午10.52.10.png" width="23" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 23px; height: 22px;" data-tag="bdshare">的更新量整个应用到每个单词的词向量上去：</span></p>
<p style="text-align:center"><span style="text-indent: 2em;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wqcddww7j20q6042wf4.jpg" title="屏幕快照 2016-07-17 上午11.11.33.png" alt="屏幕快照 2016-07-17 上午11.11.33.png" width="355" height="55" border="0" vspace="0" style="width: 355px; height: 55px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">其中，<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wqcuc7mvj202q01yjr7.jpg" title="屏幕快照 2016-07-17 上午11.11.46.png" alt="屏幕快照 2016-07-17 上午11.11.46.png" width="36" height="25" border="0" vspace="0" style="width: 36px; height: 25px;" data-tag="bdshare">代表上下文中某一个单词的词向量。我认为应该也可以将其平均后更新到每个词向量上去，无非是学习率的不同，欢迎指正。</span></p>
<h4 style="text-indent: 2em;"><span style="text-indent: 2em;">代码分析</span></h4>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">于是就可以得到两个参数更新的伪码：</span></p>
<p style="text-align:center"><span style="text-indent: 2em;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wqgz0elqj20pm0qaq5a.jpg" title="屏幕快照 2016-07-17 上午11.15.50.png" alt="屏幕快照 2016-07-17 上午11.15.50.png" width="333" height="341" border="0" vspace="0" style="width: 333px; height: 341px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">在原版C代码中的对应关系是：</span></p>
<pre class="prettyprint lang-cpp linenums"><ol class="linenums"><li class="L0"><span class="pln">f&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">;</span></li><li class="L1"><span class="com">//&nbsp;Propagate&nbsp;hidden&nbsp;-&gt;&nbsp;output</span></li><li class="L2"><span class="kwd">for</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">c&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">;</span><span class="pln">&nbsp;c&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;layer1_size</span><span class="pun">;</span><span class="pln">&nbsp;c</span><span class="pun">++)</span></li><li class="L3"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;f&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;neu1</span><span class="pun">[</span><span class="pln">c</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;syn1</span><span class="pun">[</span><span class="pln">c&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;l2</span><span class="pun">];</span></li></ol></pre>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">f对应q，neu1对应<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wps67xq7j201m01kmwx.jpg" title="屏幕快照 2016-07-17 上午10.52.10.png" alt="屏幕快照 2016-07-17 上午10.52.10.png" width="23" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 23px; height: 22px;" data-tag="bdshare">，syn1对应<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wpyg370hj202i022t8i.jpg" title="屏幕快照 2016-07-17 上午10.58.10.png" alt="屏幕快照 2016-07-17 上午10.58.10.png" width="34" height="28" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 34px; height: 28px;" data-tag="bdshare">。</span></p>
<pre class="prettyprint lang-cpp linenums"><ol class="linenums"><li class="L0"><span class="com">//&nbsp;'g'&nbsp;is&nbsp;the&nbsp;gradient&nbsp;multiplied&nbsp;by&nbsp;the&nbsp;learning&nbsp;rate</span></li><li class="L1"><span class="pln">g&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="lit">1</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">&nbsp;vocab</span><span class="pun">[</span><span class="pln">word</span><span class="pun">].</span><span class="pln">code</span><span class="pun">[</span><span class="pln">d</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">&nbsp;f</span><span class="pun">)</span><span class="pln">&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;alpha</span><span class="pun">;</span></li></ol></pre>
<p style="text-indent: 2em;"><span style="text-indent: 2em;"></span>对应伪码中的g。</p>
<pre class="prettyprint lang-cpp linenums"><ol class="linenums"><li class="L0"><span class="com">//&nbsp;Propagate&nbsp;errors&nbsp;output&nbsp;-&gt;&nbsp;hidden</span></li><li class="L1"><span class="kwd">for</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">c&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">;</span><span class="pln">&nbsp;c&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;layer1_size</span><span class="pun">;</span><span class="pln">&nbsp;c</span><span class="pun">++)</span></li><li class="L2"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;neu1e</span><span class="pun">[</span><span class="pln">c</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;g&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;syn1</span><span class="pun">[</span><span class="pln">c&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;l2</span><span class="pun">];</span></li></ol></pre>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">对应伪码中的e。</span></p>
<pre class="prettyprint lang-cpp linenums"><ol class="linenums"><li class="L0"><span class="com">//&nbsp;Learn&nbsp;weights&nbsp;hidden&nbsp;-&gt;&nbsp;output</span></li><li class="L1"><span class="kwd">for</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">c&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">;</span><span class="pln">&nbsp;c&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;layer1_size</span><span class="pun">;</span><span class="pln">&nbsp;c</span><span class="pun">++)</span></li><li class="L2"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;syn1</span><span class="pun">[</span><span class="pln">c&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;l2</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;g&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;neu1</span><span class="pun">[</span><span class="pln">c</span><span class="pun">];</span></li></ol></pre>
<p style="text-indent: 2em;">对应伪码中的<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wpyg370hj202i022t8i.jpg" title="屏幕快照 2016-07-17 上午10.58.10.png" alt="屏幕快照 2016-07-17 上午10.58.10.png" width="34" height="28" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 34px; height: 28px;" data-tag="bdshare">。<span style="text-indent: 2em;"></span></p>
<h3 id="h3-6">Skip-gram<br></h3>
<p style="text-indent: 2em;">原理</p>
<p style="text-indent: 2em;">Skip-gram只是逆转了CBOW的因果关系而已，即已知当前词语，预测上下文。</p>
<p style="text-indent: 2em;">其网络结构如下图所示：</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wqzg68u0j214a120wij.jpg" title="屏幕快照 2016-07-17 上午11.33.31.png" alt="屏幕快照 2016-07-17 上午11.33.31.png" width="512" height="483" border="0" vspace="0" style="width: 512px; height: 483px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">上图与CBOW的两个不同在于</p>
<ol class=" list-paddingleft-2" style="list-style-type: decimal;">
<li>
<p style="text-indent: 2em;">输入层不再是多个词向量，而是一个词向量</p>
</li>
<li>
<p style="text-indent: 2em;">投影层其实什么事情都没干，直接将输入层的词向量传递给输出层</p>
</li>
</ol>
<p style="text-indent: 2em;">在对其推导之前需要引入一个新的记号：</p>
<p style="text-indent: 2em;">u：表示w的上下文中的一个词语。</p>
<p style="text-indent: 2em;">于是语言模型的概率函数可以写作：</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wr8gixuxj20ji03kq37.jpg" title="屏幕快照 2016-07-17 上午11.42.19.png" alt="屏幕快照 2016-07-17 上午11.42.19.png" width="241" height="44" border="0" vspace="0" style="width: 241px; height: 44px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">注意这是一个词袋模型，所以每个u是无序的，或者说，互相独立的。</p>
<p style="text-indent: 2em;">在<span style="text-indent: 32px;">Hierarchical Softmax思想下，每个u都可以编码为一条01路径：</span></p>
<p style="text-align:center"><span style="text-indent: 32px;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wrc0q0qbj20f80483yp.jpg" title="屏幕快照 2016-07-17 上午11.45.43.png" alt="屏幕快照 2016-07-17 上午11.45.43.png" width="159" height="44" border="0" vspace="0" style="width: 159px; height: 44px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">类似地，每一项都是如下简写：<br></span></p>
<p style="text-align:center"><span style="text-indent: 32px;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wrdn000lj20v602st97.jpg" title="屏幕快照 2016-07-17 上午11.47.23.png" alt="屏幕快照 2016-07-17 上午11.47.23.png" width="371" height="33" border="0" vspace="0" style="width: 371px; height: 33px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">把它们写到一起，得到目标函数：</span></p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wula1s3qj217g08q40h.jpg" title="屏幕快照 2016-07-17 下午1.38.22.png" alt="屏幕快照 2016-07-17 下午1.38.22.png" width="493" height="99" border="0" vspace="0" style="width: 493px; height: 99px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"></span>类似CBOW的做法，将每一项简记为：</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wungph30j20ze024wf2.jpg" title="屏幕快照 2016-07-17 下午1.40.34.png" alt="屏幕快照 2016-07-17 下午1.40.34.png" width="453" height="27" border="0" vspace="0" style="width: 453px; height: 27px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">虽然上式对比CBOW多了一个u，但给定训练实例（一个词w和它的上下文{u}），u也是固定的。所以上式其实依然只有两个变量<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wps67xq7j201m01kmwx.jpg" title="屏幕快照 2016-07-17 上午10.52.10.png" alt="屏幕快照 2016-07-17 上午10.52.10.png" width="23" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 23px; height: 22px;" data-tag="bdshare">和<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wpyg370hj202i022t8i.jpg" title="屏幕快照 2016-07-17 上午10.58.10.png" alt="屏幕快照 2016-07-17 上午10.58.10.png" width="34" height="28" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 34px; height: 28px;" data-tag="bdshare">，对其求偏导数：</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"></span></p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wuuqjclej206s03waa1.jpg" title="屏幕快照 2016-07-17 下午1.47.40.png" alt="屏幕快照 2016-07-17 下午1.47.40.png" width="88" height="50" border="0" vspace="0" style="width: 88px; height: 50px;" data-tag="bdshare"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wuufd3hcj20h601w0su.jpg" title="屏幕快照 2016-07-17 下午1.47.16.png" alt="屏幕快照 2016-07-17 下午1.47.16.png" width="255" height="28" border="0" vspace="0" style="text-indent: 32px; width: 255px; height: 28px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">具体求导过程类似CBOW，略过。</p>
<p style="text-indent: 2em;">于是得到<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wpyg370hj202i022t8i.jpg" title="屏幕快照 2016-07-17 上午10.58.10.png" alt="屏幕快照 2016-07-17 上午10.58.10.png" width="34" height="28" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 34px; height: 28px;" data-tag="bdshare">的更新表达式：</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wuwiun2hj20nq02a3yr.jpg" title="屏幕快照 2016-07-17 下午1.49.16.png" alt="屏幕快照 2016-07-17 下午1.49.16.png" width="344" height="33" border="0" vspace="0" style="width: 344px; height: 33px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">同理利用对称性得到对<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wps67xq7j201m01kmwx.jpg" title="屏幕快照 2016-07-17 上午10.52.10.png" alt="屏幕快照 2016-07-17 上午10.52.10.png" width="23" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 23px; height: 22px;" data-tag="bdshare">的偏导数：</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wuxki2icj20me03cdg7.jpg" title="屏幕快照 2016-07-17 下午1.50.19.png" alt="屏幕快照 2016-07-17 下午1.50.19.png" width="296" height="44" border="0" vspace="0" style="width: 296px; height: 44px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">于是得到<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wps67xq7j201m01kmwx.jpg" title="屏幕快照 2016-07-17 上午10.52.10.png" alt="屏幕快照 2016-07-17 上午10.52.10.png" width="23" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 23px; height: 22px;" data-tag="bdshare">的更新表达式：</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wuym3dfsj20ms04mgm3.jpg" title="屏幕快照 2016-07-17 下午1.51.20.png" alt="屏幕快照 2016-07-17 下午1.51.20.png" width="271" height="55" border="0" vspace="0" style="width: 271px; height: 55px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">训练伪码如下：</span></p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wv0ifddej20ok0ncgni.jpg" title="屏幕快照 2016-07-17 下午1.53.06.png" alt="屏幕快照 2016-07-17 下午1.53.06.png" width="333" height="317" border="0" vspace="0" style="width: 333px; height: 317px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">word2vec源码中并没有等<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wpyg370hj202i022t8i.jpg" title="屏幕快照 2016-07-17 上午10.58.10.png" alt="屏幕快照 2016-07-17 上午10.58.10.png" width="34" height="28" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 34px; height: 28px;" data-tag="bdshare">更新完再更新<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wps67xq7j201m01kmwx.jpg" title="屏幕快照 2016-07-17 上午10.52.10.png" alt="屏幕快照 2016-07-17 上午10.52.10.png" width="23" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 23px; height: 22px;" data-tag="bdshare">，而是即时地更新：</span></p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wv2jzxnfj20oe0ncdhp.jpg" title="屏幕快照 2016-07-17 下午1.55.05.png" alt="屏幕快照 2016-07-17 下午1.55.05.png" width="333" height="319" border="0" vspace="0" style="width: 333px; height: 319px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"></span>具体对应源码中的</p>
<pre class="prettyprint lang-cpp linenums"><ol class="linenums"><li class="L0"><span class="com">//&nbsp;Propagate&nbsp;hidden&nbsp;-&gt;&nbsp;output</span></li><li class="L1"><span class="kwd">for</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">c&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">;</span><span class="pln">&nbsp;c&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;layer1_size</span><span class="pun">;</span><span class="pln">&nbsp;c</span><span class="pun">++)</span></li><li class="L2"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;f&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;syn0</span><span class="pun">[</span><span class="pln">c&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;l1</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;syn1</span><span class="pun">[</span><span class="pln">c&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;l2</span><span class="pun">];</span></li><li class="L3"><span class="com">//&nbsp;'g'&nbsp;is&nbsp;the&nbsp;gradient&nbsp;multiplied&nbsp;by&nbsp;the&nbsp;learning&nbsp;rate</span></li><li class="L4"><span class="pln">g&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="lit">1</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">&nbsp;vocab</span><span class="pun">[</span><span class="pln">word</span><span class="pun">].</span><span class="pln">code</span><span class="pun">[</span><span class="pln">d</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">&nbsp;f</span><span class="pun">)</span><span class="pln">&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;alpha</span><span class="pun">;</span></li><li class="L5"><span class="com">//&nbsp;Propagate&nbsp;errors&nbsp;output&nbsp;-&gt;&nbsp;hidden</span></li><li class="L6"><span class="kwd">for</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">c&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">;</span><span class="pln">&nbsp;c&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;layer1_size</span><span class="pun">;</span><span class="pln">&nbsp;c</span><span class="pun">++)</span></li><li class="L7"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;neu1e</span><span class="pun">[</span><span class="pln">c</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;g&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;syn1</span><span class="pun">[</span><span class="pln">c&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;l2</span><span class="pun">];</span></li><li class="L8"><span class="com">//&nbsp;Learn&nbsp;weights&nbsp;hidden&nbsp;-&gt;&nbsp;output</span></li><li class="L9"><span class="kwd">for</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">c&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">;</span><span class="pln">&nbsp;c&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;layer1_size</span><span class="pun">;</span><span class="pln">&nbsp;c</span><span class="pun">++)</span></li><li class="L0"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;syn1</span><span class="pun">[</span><span class="pln">c&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;l2</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;g&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;syn0</span><span class="pun">[</span><span class="pln">c&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;l1</span><span class="pun">];</span></li></ol></pre>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"><span style="text-indent: 32px;">f对应q，syn0对应v</span><span style="text-indent: 32px;">，syn1对应</span><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wpyg370hj202i022t8i.jpg" title="屏幕快照 2016-07-17 上午10.58.10.png" alt="屏幕快照 2016-07-17 上午10.58.10.png" width="34" height="28" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 34px; height: 28px;" data-tag="bdshare">，neu1e对应e<span style="text-indent: 32px;">。</span></span></p>
<h2 id="h2-7"><span style="text-indent: 32px;">Negative Sampling</span></h2>
<p style="text-indent: 2em;">通过上一章的学习，我们知道无论是CBOW还是<span style="text-indent: 32px;">Skip-gram模型，其实都是分类模型。对于机器学习中的分类任务，在训练的时候不但要给正例，还要给负例。对于<span style="text-indent: 32px;">Hierarchical Softmax，负例放在二叉树的根节点上。对于Negative Sampling，负例是随机挑选出来的。据说Negative Sampling能提高速度、改进模型质量。</span></span></p>
<h3 id="h3-8"><span style="text-indent: 32px;"><span style="text-indent: 32px;">CBOW<br></span></span></h3>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"><span style="text-indent: 32px;">给定训练样本，即一个词w和它的上下文Context(w)，<span style="text-indent: 32px;">Context(w)是输入，w是输出。那么w就是正例，词汇表中其他的词语的就是负例。假设我们通过某种采样方法获得了负例子集NEG(w)。对于正负样本，分别定义一个标签：</span></span></span></p>
<p style="text-align:center"><span style="text-indent: 32px;"><span style="text-indent: 32px;"><span style="text-indent: 32px;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wvqrrxrkj20du04uaa6.jpg" title="屏幕快照 2016-07-17 下午2.18.20.png" alt="屏幕快照 2016-07-17 下午2.18.20.png" width="190" height="66" border="0" vspace="0" style="width: 190px; height: 66px;" data-tag="bdshare"></span></span></span></p>
<p style="text-indent: 2em;">也即正样本为1，负样本为0。</p>
<p style="text-indent: 2em;">对于给定正样本<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wvstbibtj208k022mx4.jpg" title="屏幕快照 2016-07-17 下午2.20.18.png" alt="屏幕快照 2016-07-17 下午2.20.18.png" width="116" height="28" border="0" vspace="0" style="width: 116px; height: 28px;" data-tag="bdshare">，我们希望最大化：</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wvu0zlm8j20ja03s74k.jpg" title="屏幕快照 2016-07-17 下午2.21.21.png" alt="屏幕快照 2016-07-17 下午2.21.21.png" width="281" height="55" border="0" vspace="0" style="width: 281px; height: 55px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">其中，</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wvvi5wd1j20tk03caak.jpg" title="屏幕快照 2016-07-17 下午2.22.46.png" alt="屏幕快照 2016-07-17 下午2.22.46.png" width="390" height="44" border="0" vspace="0" style="width: 390px; height: 44px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">也就是说，当u是正例时，<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wvyjh18ij204e022mx0.jpg" title="屏幕快照 2016-07-17 下午2.25.48.png" alt="屏幕快照 2016-07-17 下午2.25.48.png" width="71" height="33" border="0" vspace="0" style="width: 71px; height: 33px;" data-tag="bdshare">越大越好，当u是负例时，<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wvz1yo3mj204e022mx0.jpg" title="屏幕快照 2016-07-17 下午2.25.48.png" alt="屏幕快照 2016-07-17 下午2.25.48.png" width="70" height="33" border="0" vspace="0" style="width: 70px; height: 33px;" data-tag="bdshare">越小越好。因为<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wvyjh18ij204e022mx0.jpg" title="屏幕快照 2016-07-17 下午2.25.48.png" alt="屏幕快照 2016-07-17 下午2.25.48.png" width="71" height="33" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 71px; height: 33px;" data-tag="bdshare">等于模型预测样本为正例的概率，当答案就是正的时候，我们希望这个概率越大越好，当答案是负的时候，我们希望它越小越好，这样才能说明该模型是个明辨是非的好同志。</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">每个词都是如此，语料库有多个词，我们将g累积得到优化目标。因为对数方便计算，我们对其取对数得到目标函数：<br></span></p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5ww343093j202w01qjr5.jpg" title="屏幕快照 2016-07-17 下午2.30.13.png" alt="屏幕快照 2016-07-17 下午2.30.13.png" width="56" height="33" border="0" vspace="0" style="text-align: center; text-indent: 32px; white-space: normal; width: 56px; height: 33px;" data-tag="bdshare"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5ww51ivztj20f0036t8v.jpg" title="屏幕快照 2016-07-17 下午2.30.29.png" alt="屏幕快照 2016-07-17 下午2.30.29.png" width="208" height="44" border="0" vspace="0" style="text-indent: 2em; width: 208px; height: 44px;" data-tag="bdshare"></p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5ww6ewrf6j214c06u75z.jpg" title="屏幕快照 2016-07-17 下午2.30.41.png" alt="屏幕快照 2016-07-17 下午2.30.41.png" width="519" height="88" border="0" vspace="0" style="width: 519px; height: 88px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"></span>记双重求和中的每一项为：</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5ww86shjmj20ww02adgb.jpg" title="屏幕快照 2016-07-17 下午2.35.00.png" alt="屏幕快照 2016-07-17 下午2.35.00.png" width="476" height="33" border="0" vspace="0" style="width: 476px; height: 33px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">求梯度：</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5ww8moi79j206w03qmx3.jpg" title="屏幕快照 2016-07-17 下午2.35.20.png" alt="屏幕快照 2016-07-17 下午2.35.20.png" width="81" height="44" border="0" vspace="0" style="width: 81px; height: 44px;" data-tag="bdshare"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5ww9fhthaj20bi02cjre.jpg" title="屏幕快照 2016-07-17 下午2.36.01.png" alt="屏幕快照 2016-07-17 下午2.36.01.png" width="178" height="36" border="0" vspace="0" style="text-indent: 2em; width: 178px; height: 36px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">于是<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwa421k2j201a01mdfl.jpg" title="屏幕快照 2016-07-17 下午2.37.02.png" alt="屏幕快照 2016-07-17 下午2.37.02.png" width="22" height="28" border="0" vspace="0" style="width: 22px; height: 28px;" data-tag="bdshare">的更新方法为：<br></span></p>
<p style="text-align:center"><span style="text-indent: 32px;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwbbbx5ij20hy022jri.jpg" title="屏幕快照 2016-07-17 下午2.37.34.png" alt="屏幕快照 2016-07-17 下午2.37.34.png" width="288" height="33" border="0" vspace="0" style="width: 288px; height: 33px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">利用对称性得到关于<img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wps67xq7j201m01kmwx.jpg" title="屏幕快照 2016-07-17 上午10.52.10.png" alt="屏幕快照 2016-07-17 上午10.52.10.png" width="23" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 23px; height: 22px;" data-tag="bdshare">的梯度：</span></p>
<p style="text-align:center"><span style="text-indent: 32px;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwbh2e7gj20hg03kmxe.jpg" title="屏幕快照 2016-07-17 下午2.38.12.png" alt="屏幕快照 2016-07-17 下午2.38.12.png" width="216" height="44" border="0" vspace="0" style="width: 216px; height: 44px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">将该更新应用到每个词向量上去：<br></span></p>
<p style="text-align:center"><span style="text-indent: 32px;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwdsvi40j20uk0463z4.jpg" title="屏幕快照 2016-07-17 下午2.40.01.png" alt="屏幕快照 2016-07-17 下午2.40.01.png" width="323" height="44" border="0" vspace="0" style="width: 323px; height: 44px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">训练伪码为：<br></span></p>
<p style="text-align:center"><span style="text-indent: 32px;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwegdnryj20oi0q00v3.jpg" title="屏幕快照 2016-07-17 下午2.40.41.png" alt="屏幕快照 2016-07-17 下午2.40.41.png" width="333" height="353" border="0" vspace="0" style="width: 333px; height: 353px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">对应原版C代码的片段：</span></p>
<pre class="prettyprint lang-cpp linenums"><ol class="linenums"><li class="L0"><span class="pln">f&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">;</span></li><li class="L1"><span class="kwd">for</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">c&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">;</span><span class="pln">&nbsp;c&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;layer1_size</span><span class="pun">;</span><span class="pln">&nbsp;c</span><span class="pun">++)</span></li><li class="L2"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;f&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;neu1</span><span class="pun">[</span><span class="pln">c</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;syn1neg</span><span class="pun">[</span><span class="pln">c&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;l2</span><span class="pun">];</span></li><li class="L3"><span class="kwd">if</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">f&nbsp;</span><span class="pun">&gt;</span><span class="pln">&nbsp;MAX_EXP</span><span class="pun">)</span></li><li class="L4"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;g&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">label&nbsp;</span><span class="pun">-</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">)</span><span class="pln">&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;alpha</span><span class="pun">;</span></li><li class="L5"><span class="kwd">else</span><span class="pln">&nbsp;</span><span class="kwd">if</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">f&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">MAX_EXP</span><span class="pun">)</span></li><li class="L6"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;g&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">label&nbsp;</span><span class="pun">-</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">)</span><span class="pln">&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;alpha</span><span class="pun">;</span></li><li class="L7"><span class="kwd">else</span></li><li class="L8"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;g&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">label&nbsp;</span><span class="pun">-</span><span class="pln">&nbsp;expTable</span><span class="pun">[(</span><span class="typ">int</span><span class="pun">)</span><span class="pln">&nbsp;</span><span class="pun">((</span><span class="pln">f&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;MAX_EXP</span><span class="pun">)</span><span class="pln">&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">EXP_TABLE_SIZE&nbsp;</span><span class="pun">/</span><span class="pln">&nbsp;MAX_EXP&nbsp;</span><span class="pun">/</span><span class="pln">&nbsp;</span><span class="lit">2</span><span class="pun">))])</span><span class="pln">&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;alpha</span><span class="pun">;</span></li><li class="L9"><span class="kwd">for</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">c&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">;</span><span class="pln">&nbsp;c&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;layer1_size</span><span class="pun">;</span><span class="pln">&nbsp;c</span><span class="pun">++)</span></li><li class="L0"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;neu1e</span><span class="pun">[</span><span class="pln">c</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;g&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;syn1neg</span><span class="pun">[</span><span class="pln">c&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;l2</span><span class="pun">];</span></li><li class="L1"><span class="kwd">for</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">c&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">;</span><span class="pln">&nbsp;c&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;layer1_size</span><span class="pun">;</span><span class="pln">&nbsp;c</span><span class="pun">++)</span></li><li class="L2"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;syn1neg</span><span class="pun">[</span><span class="pln">c&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;l2</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;g&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;neu1</span><span class="pun">[</span><span class="pln">c</span><span class="pun">];</span></li></ol></pre>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"></span></p>
<h3 id="h3-9">Skip-gram<br></h3>
<p style="text-indent: 2em;">有了前三次的经验，这次轻车熟路地给出结论吧。<span style="text-indent: 2em;">颠倒样本的x和y部分，也即对</span><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwmf09odj208e01udfs.jpg" title="屏幕快照 2016-07-17 下午2.48.48.png" alt="屏幕快照 2016-07-17 下午2.48.48.png" width="101" height="22" border="0" vspace="0" style="text-indent: 2em; width: 101px; height: 22px;" data-tag="bdshare"><span style="text-indent: 2em;">，我们希望最大化：</span></p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwn80xmpj20kw03qaae.jpg" title="屏幕快照 2016-07-17 下午2.49.32.png" alt="屏幕快照 2016-07-17 下午2.49.32.png" width="269" height="48" border="0" vspace="0" style="width: 269px; height: 48px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">其中，</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwnsb8gwj20rs02q74p.jpg" title="屏幕快照 2016-07-17 下午2.50.05.png" alt="屏幕快照 2016-07-17 下午2.50.05.png" width="408" height="40" border="0" vspace="0" style="width: 408px; height: 40px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">最终目标函数为：<br></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"></span></p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwpygiykj203c01ujr5.jpg" title="屏幕快照 2016-07-17 下午2.52.14.png" alt="屏幕快照 2016-07-17 下午2.52.14.png" width="60" height="33" border="0" vspace="0" style="width: 60px; height: 33px;" data-tag="bdshare"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwq6wiqgj20gc03iq35.jpg" title="屏幕快照 2016-07-17 下午2.52.27.png" alt="屏幕快照 2016-07-17 下午2.52.27.png" width="205" height="44" border="0" vspace="0" style="text-indent: 32px; width: 205px; height: 44px;" data-tag="bdshare"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwqfdz9dj205q02aglh.jpg" title="屏幕快照 2016-07-17 下午2.52.39.png" alt="屏幕快照 2016-07-17 下午2.52.39.png" width="111" height="44" border="0" vspace="0" style="text-indent: 32px; width: 111px; height: 44px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">其中，</span></p>
<p style="text-align:center"><span style="text-indent: 32px;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwrfbv20j212a028q3k.jpg" title="屏幕快照 2016-07-17 下午2.53.36.png" alt="屏幕快照 2016-07-17 下午2.53.36.png" width="620" height="36" border="0" vspace="0" style="width: 620px; height: 36px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">分别求出梯度：</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"></span></p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwssk44nj2070036dfs.jpg" title="屏幕快照 2016-07-17 下午2.54.58.png" alt="屏幕快照 2016-07-17 下午2.54.58.png" width="97" height="44" border="0" vspace="0" style="width: 97px; height: 44px;" data-tag="bdshare"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwt3b6slj20gc026dfy.jpg" title="屏幕快照 2016-07-17 下午2.55.09.png" alt="屏幕快照 2016-07-17 下午2.55.09.png" width="249" height="33" border="0" vspace="0" style="text-indent: 32px; width: 249px; height: 33px;" data-tag="bdshare"></p>
<p style="text-align:center"><span style="text-indent: 32px;"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwvo04hhj20kc03u0t4.jpg" title="屏幕快照 2016-07-17 下午2.57.39.png" alt="屏幕快照 2016-07-17 下午2.57.39.png" width="291" height="55" border="0" vspace="0" style="width: 291px; height: 55px;" data-tag="bdshare"></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">得到两者的更新方法：</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"></span></p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwybgglbj201k01odfl.jpg" title="屏幕快照 2016-07-17 下午3.00.14.png" alt="屏幕快照 2016-07-17 下午3.00.14.png" width="31" height="33" border="0" vspace="0" style="width: 31px; height: 33px;" data-tag="bdshare"><span style="text-indent: 32px;">+=</span><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwx8u1fdj20fa02k0sv.jpg" title="屏幕快照 2016-07-17 下午2.58.34.png" alt="屏幕快照 2016-07-17 下午2.58.34.png" width="197" height="33" border="0" vspace="0" style="text-indent: 32px; width: 197px; height: 33px;" data-tag="bdshare"></p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwzexewnj20hi0440sx.jpg" title="屏幕快照 2016-07-17 下午3.01.01.png" alt="屏幕快照 2016-07-17 下午3.01.01.png" width="187" height="44" border="0" vspace="0" style="width: 187px; height: 44px;" data-tag="bdshare"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwzp1b9nj20d002oaa4.jpg" title="屏幕快照 2016-07-17 下午3.01.34.png" alt="屏幕快照 2016-07-17 下午3.01.34.png" width="161" height="33" border="0" vspace="0" style="width: 161px; height: 33px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">训练伪码为：</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wx0r6vbsj20oo0ngabz.jpg" title="屏幕快照 2016-07-17 下午3.02.35.png" alt="屏幕快照 2016-07-17 下午3.02.35.png" width="333" height="317" border="0" vspace="0" style="width: 333px; height: 317px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">对应原版C代码片段：</span></p>
<pre class="prettyprint lang-cpp linenums"><ol class="linenums"><li class="L0"><span class="pln">f&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">;</span></li><li class="L1"><span class="kwd">for</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">c&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">;</span><span class="pln">&nbsp;c&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;layer1_size</span><span class="pun">;</span><span class="pln">&nbsp;c</span><span class="pun">++)</span></li><li class="L2"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;f&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;syn0</span><span class="pun">[</span><span class="pln">c&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;l1</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;syn1neg</span><span class="pun">[</span><span class="pln">c&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;l2</span><span class="pun">];</span></li><li class="L3"><span class="kwd">if</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">f&nbsp;</span><span class="pun">&gt;</span><span class="pln">&nbsp;MAX_EXP</span><span class="pun">)</span></li><li class="L4"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;g&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">label&nbsp;</span><span class="pun">-</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">)</span><span class="pln">&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;alpha</span><span class="pun">;</span></li><li class="L5"><span class="kwd">else</span><span class="pln">&nbsp;</span><span class="kwd">if</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">f&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">MAX_EXP</span><span class="pun">)</span></li><li class="L6"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;g&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">label&nbsp;</span><span class="pun">-</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">)</span><span class="pln">&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;alpha</span><span class="pun">;</span></li><li class="L7"><span class="kwd">else</span></li><li class="L8"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;g&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">label&nbsp;</span><span class="pun">-</span><span class="pln">&nbsp;expTable</span><span class="pun">[(</span><span class="typ">int</span><span class="pun">)</span><span class="pln">&nbsp;</span><span class="pun">((</span><span class="pln">f&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;MAX_EXP</span><span class="pun">)</span><span class="pln">&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">EXP_TABLE_SIZE&nbsp;</span><span class="pun">/</span><span class="pln">&nbsp;MAX_EXP&nbsp;</span><span class="pun">/</span><span class="pln">&nbsp;</span><span class="lit">2</span><span class="pun">))])</span><span class="pln">&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;alpha</span><span class="pun">;</span></li><li class="L9"><span class="kwd">for</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">c&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">;</span><span class="pln">&nbsp;c&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;layer1_size</span><span class="pun">;</span><span class="pln">&nbsp;c</span><span class="pun">++)</span></li><li class="L0"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;neu1e</span><span class="pun">[</span><span class="pln">c</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;g&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;syn1neg</span><span class="pun">[</span><span class="pln">c&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;l2</span><span class="pun">];</span></li><li class="L1"><span class="kwd">for</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">c&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">;</span><span class="pln">&nbsp;c&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;layer1_size</span><span class="pun">;</span><span class="pln">&nbsp;c</span><span class="pun">++)</span></li><li class="L2"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;syn1neg</span><span class="pun">[</span><span class="pln">c&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;l2</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+=</span><span class="pln">&nbsp;g&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;syn0</span><span class="pun">[</span><span class="pln">c&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;l1</span><span class="pun">];</span></li></ol></pre>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"></span><span style="text-indent: 32px;">syn0对应</span><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wps67xq7j201m01kmwx.jpg" title="屏幕快照 2016-07-17 上午10.52.10.png" alt="屏幕快照 2016-07-17 上午10.52.10.png" width="23" height="22" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 23px; height: 22px;" data-tag="bdshare"><span style="text-indent: 32px;"></span><span style="text-indent: 32px;">，syn1neg对应</span><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wwa421k2j201a01mdfl.jpg" title="屏幕快照 2016-07-17 下午2.37.02.png" alt="屏幕快照 2016-07-17 下午2.37.02.png" width="22" height="28" border="0" vspace="0" style="text-indent: 32px; white-space: normal; width: 22px; height: 28px;" data-tag="bdshare"><span style="text-indent: 32px;">，f运算后得到q，代码中有优化（后文分解），neu1e对应e。</span></p>
<h2 id="h2-10">更多细节</h2>
<h3 id="h3-11">Huffman树</h3>
<p style="text-indent: 2em;">上文一直在用二叉树描述<span style="text-indent: 32px;">Hierarchical Softmax，这是因为我不想仿照大部分tutorial那样一下子拿出Huffman这么具体的细节。初期对word2vec的大框架还没把握住的时候突然看到这些细节的话，人会抓不住重点，造成学习成本无谓的上升。我当时看到有些tutorial第一节就在讲Huffman编码，还以为实现word2vec一定要用Huffman树呢。</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">其实根本不是的，任何二叉树都可以。Huffman树只是二叉树中具体的一种，特别适合word2vec的训练。</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">word2vec训练的时候按照词频将每个词语Huffman编码，由于Huffman编码中词频越高的词语对应的编码越短。所以越高频的词语在<span style="text-indent: 32px;">Hierarchical Softmax过程中经过的二分类节点就越少，整体计算量就更少了。</span></span></p>
<h3 id="h3-12"><span style="text-indent: 32px;"><span style="text-indent: 32px;">负采样算法<br></span></span></h3>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"><span style="text-indent: 32px;">任何采样算法都应该保证频次越高的样本越容易被采样出来。基本的思路是对于长度为1的线段，根据词语的词频将其公平地分配给每个词语：</span></span></p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wxfljwsnj20cs04ajrn.jpg" title="屏幕快照 2016-07-17 下午3.16.37.png" alt="屏幕快照 2016-07-17 下午3.16.37.png" width="197" height="66" border="0" vspace="0" style="width: 197px; height: 66px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"><span style="text-indent: 32px;"></span></span>counter就是w的词频。</p>
<p style="text-indent: 2em;">于是我们将该线段公平地分配了：</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wxhgjcnkj20xo03mwep.jpg" title="屏幕快照 2016-07-17 下午3.18.09.png" alt="屏幕快照 2016-07-17 下午3.18.09.png" width="411" height="44" border="0" vspace="0" style="width: 411px; height: 44px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;">接下来我们只要生成一个0-1之间的随机数，看看落到哪个区间，就能采样到该区间对应的单词了，很公平。</p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"><span style="text-indent: 32px;">但怎么根据小数找区间呢？速度慢可不行。</span></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"><span style="text-indent: 32px;">word2vec用的是一种查表的方式，</span></span>将上述线段标上M个“刻度”，刻度之间的间隔是相等的，即1/M：</p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wxly3lgkj20yo0c0aba.jpg" title="屏幕快照 2016-07-17 下午3.22.12.png" alt="屏幕快照 2016-07-17 下午3.22.12.png" width="411" height="142" border="0" vspace="0" style="width: 411px; height: 142px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"><span style="text-indent: 32px;">接着我们就不生成0-1之间的随机数了，我们生成0-M之间的整数，去这个刻度尺上一查就能抽中一个单词了。</span></span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"><span style="text-indent: 32px;">在word2vec中，该“刻度尺”对应着table数组。具体实现时，对词频取了0.75次幂：</span></span></p>
<p style="text-align:center"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1f5wyr5o2p6j20ew04o74n.jpg" title="屏幕快照 2016-07-17 下午4.02.32.png" alt="屏幕快照 2016-07-17 下午4.02.32.png" width="175" height="55" border="0" vspace="0" style="width: 175px; height: 55px;" data-tag="bdshare"></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;"><span style="text-indent: 32px;"></span></span>这个幂实际上是一种“平滑”策略，能够让低频词多一些出场机会，高频词贡献一些出场机会，劫富济贫。</p>
<h3 id="h3-13">sigmoid函数</h3>
<p style="text-indent: 2em;">类似的查表方法还有sigmoid函数的计算，因为该函数使用太频繁，而其值仅仅在靠近0的时候才会剧烈变化，远离0的方向很快趋近0和1。所以源码中也采用了“刻度查表”的方法，先算出了很多个刻度对应的函数值，运算中直接查表。这部分对应:</p>
<pre class="prettyprint lang-cpp linenums"><ol class="linenums"><li class="L0"><span class="pln">expTable&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">real&nbsp;</span><span class="pun">*)</span><span class="pln">&nbsp;malloc</span><span class="pun">((</span><span class="pln">EXP_TABLE_SIZE&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">)</span><span class="pln">&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;</span><span class="kwd">sizeof</span><span class="pun">(</span><span class="pln">real</span><span class="pun">));</span></li><li class="L1"><span class="kwd">for</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">i&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;</span><span class="lit">0</span><span class="pun">;</span><span class="pln">&nbsp;i&nbsp;</span><span class="pun">&lt;</span><span class="pln">&nbsp;EXP_TABLE_SIZE</span><span class="pun">;</span><span class="pln">&nbsp;i</span><span class="pun">++)</span></li><li class="L2"><span class="pun">{</span></li><li class="L3"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;expTable</span><span class="pun">[</span><span class="pln">i</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;exp</span><span class="pun">((</span><span class="pln">i&nbsp;</span><span class="pun">/</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">real</span><span class="pun">)</span><span class="pln">&nbsp;EXP_TABLE_SIZE&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;</span><span class="lit">2</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">)</span><span class="pln">&nbsp;</span><span class="pun">*</span><span class="pln">&nbsp;MAX_EXP</span><span class="pun">);</span><span class="pln">&nbsp;</span><span class="com">//&nbsp;Precompute&nbsp;the&nbsp;exp()&nbsp;table</span></li><li class="L4"><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;expTable</span><span class="pun">[</span><span class="pln">i</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">=</span><span class="pln">&nbsp;expTable</span><span class="pun">[</span><span class="pln">i</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">/</span><span class="pln">&nbsp;</span><span class="pun">(</span><span class="pln">expTable</span><span class="pun">[</span><span class="pln">i</span><span class="pun">]</span><span class="pln">&nbsp;</span><span class="pun">+</span><span class="pln">&nbsp;</span><span class="lit">1</span><span class="pun">);</span><span class="pln">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="com">//&nbsp;Precompute&nbsp;f(x)&nbsp;=&nbsp;x&nbsp;/&nbsp;(x&nbsp;+&nbsp;1)</span></li><li class="L5"><span class="pun">}</span></li></ol></pre>
<h3 id="h3-14">多线程<br></h3>
<p style="text-indent: 2em;">关于如何多线程并行训练的问题，我没看代码之前也想过。大致就是将语料按照线程数均分，大家分头算，更新参数的过程中做好线程同步的工作。</p>
<p style="text-indent: 2em;">后来看了原版C代码，原来作者压根就没做线程同步，一个全局的数组，大家都往里面写，万一下标冲突了怎么办？那就让它冲突呗……数组那么大（在text8语料上是一千万），线程那么少，冲突的概率不大吧。</p>
<h2 id="h2-15">一些开源实现</h2>
<h3 id="h3-16">C</h3>
<p style="text-indent: 2em;"><a href="https://github.com/dav/word2vec" _src="https://github.com/dav/word2vec" target="_blank" rel="external nofollow">https://github.com/dav/word2vec</a> </p>
<p style="text-indent: 2em;">在原版的基础上打了一些社区的patch，可以在macos上make编译</p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;"><a href="https://github.com/bpiwowar/word2vec" _src="https://github.com/bpiwowar/word2vec" target="_blank" rel="external nofollow">https://github.com/bpiwowar/word2vec</a> </span></p>
<p style="text-indent: 2em;">原版的CMake迁移，可以在macos下编译</p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;"><a href="https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/word2vec.py" _src="https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/word2vec.py" target="_blank" rel="external nofollow">https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/word2vec.py</a> </span></p>
<p style="text-indent: 2em;">大名鼎鼎的gensim，适合Python用户。</p>
<p style="text-indent: 2em;"><a href="https://github.com/h10r/word2vec-macosx-maverics" _src="https://github.com/h10r/word2vec-macosx-maverics" target="_blank" rel="external nofollow">https://github.com/h10r/word2vec-macosx-maverics</a> </p>
<p style="text-indent: 2em;">改了几个文件头，可以在macos上make编译。</p>
<h3 id="h3-17">C++</h3>
<p style="text-indent: 2em;"><a href="https://github.com/eske/multivec" _src="https://github.com/eske/multivec" target="_blank" rel="external nofollow">https://github.com/eske/multivec</a> </p>
<p style="text-indent: 2em;">C++实现的各种各样的XXvector，包括paragraph vector等，其word2vec只是对原版C代码的包装，没有多少改进。</p>
<p style="white-space: normal; text-indent: 2em;">*<a href="https://github.com/jdeng/word2vec" _src="https://github.com/jdeng/word2vec" target="_blank" rel="external nofollow">https://github.com/jdeng/word2vec</a></p>
<p style="white-space: normal; text-indent: 2em;">又一份C++11的实现，虽然星星很多，但<a href="https://github.com/jdeng/word2vec/issues/4" target="_blank" rel="external nofollow">据说准确率惨不忍睹</a>，并且作者没有解释。在较早的一份<a href="https://github.com/jdeng/word2vec/issues/2" target="_blank" rel="external nofollow">issue</a>（就是由一份Java版的作者siegfang提出的）中，作者表示“I am not sure if my implementation is accurate”。另外<a href="https://groups.google.com/forum/#!topic/word2vec-toolkit/lVZ96A-gOj0" target="_blank" rel="external nofollow">Google论坛</a>上有人表示该C++11实现只有原版C实现速度的一半。所以我认为这两个版本都应该谨慎使用。</p>
<h3 id="h3-18">Java</h3>
<p style="text-indent: 2em;"><a href="https://github.com/medallia" _src="https://github.com/medallia" target="_blank" rel="external nofollow">https://github.com/medallia</a></p>
<p style="text-indent: 2em;">一份Java实现，使用了很多Google的库，校正了一些原版的错误，阉割掉了k-means，从代码质量上讲总体是一份不错的实现。其输出的bin模型与原版C程序直接兼容，然而并不支持宽字符（需要改改，有个pull request做了，但作者一直没merge）。我测试了其准确率，比原版低20%左右。从这一点来讲，该实现没有多大价值。</p>
<p style="text-indent: 2em;"><a href="https://github.com/kojisekig/word2vec-lucene" _src="https://github.com/kojisekig/word2vec-lucene" target="_blank" rel="external nofollow">https://github.com/kojisekig/word2vec-lucene</a> </p>
<p style="text-indent: 2em;">一份Java实现，是我见过最忠于原版的Java实现。卖点是不但可以用文本文件训练，还可以直接用Lucene的index训练。对于文本，由于Java没有“读取下一个String”的IO接口，作者实现了一个TextFileCorpus.nextWord。该方法读取一行并且拆分成字符串数组，然而text8整个文件也就一行，所以会频繁地多次读取（多个线程），然后OOM。作者提供一个切割程序，将text8切成多行，这样才能训练text8。作者并没有做准确率评测，我移植了谷歌的评测程序，并提交给了作者。我还将评测结果做了对比，比原版低10%左右，也报告给了作者，有志于开源项目的朋友可以<a href="https://github.com/kojisekig/word2vec-lucene/issues/21" target="_blank" rel="external nofollow">持续参与讨论</a>。事实上，这份实现的价值是最高的，因为它的准确率是Java中最高的。</p>
<p style="text-indent: 2em;">*<a href="https://github.com/siegfang/word2vec" _src="https://github.com/siegfang/word2vec" target="_blank" rel="external nofollow">https://github.com/siegfang/word2vec</a> </p>
<p style="text-indent: 2em;">一份Java实现，卖点是并行化（其实上所有开源的都支持并行化）；内存占用较大（Java的通病），据作者<span style="text-indent: 32px;">siegfang讲参考了上述C++11实现。然而上梁不正，下梁能好到哪去</span>。既不支持negative sampling，又不能保证准确率，毫无亮点。</p>
<p style="text-indent: 2em;">其他不在此列表中的方案要么没被我看到，要么不值得一试。</p>
<p style="text-indent: 2em;">事实上，上述实现都没入这位日本友人的<a href="http://aial.shiroyagi.co.jp/2015/12/word2vec/" target="_blank" rel="external nofollow">评测单</a>，他建议或者原版，或者gensim。</p>
<h2 id="h2-19">我的Java方案</h2>
<p style="text-indent: 2em;">在C和Python界，我们分别有原版C程序和gensim可以用；在Java界，没有足够好用的开源实现。鉴于此，我决定在<a href="https://github.com/kojisekig/word2vec-lucene" _src="https://github.com/kojisekig/word2vec-lucene" target="_blank" rel="external nofollow" style="text-indent: 32px; white-space: normal;">kojisekig</a>的基础上优化一下，目前效果如下——</p>
<h3 id="h3-20">参数</h3>
<p style="text-indent: 2em;">使用相同的参数</p>
<pre class="prettyprint lang-plain linenums"><ol class="linenums"><li class="L0"><span class="pln">word2vec&nbsp;</span><span class="pun">-</span><span class="pln">train&nbsp;text8&nbsp;</span><span class="pun">-</span><span class="pln">output&nbsp;vectors</span><span class="pun">.</span><span class="pln">bin&nbsp;</span><span class="pun">-</span><span class="pln">cbow&nbsp;</span><span class="lit">1</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">size&nbsp;</span><span class="lit">200</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">window&nbsp;</span><span class="lit">8</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">negative&nbsp;</span><span class="lit">25</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">hs&nbsp;</span><span class="lit">0</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">sample&nbsp;</span><span class="lit">1e-4</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">threads&nbsp;</span><span class="lit">8</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">binary&nbsp;</span><span class="lit">1</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">iter&nbsp;</span><span class="lit">15</span></li><li class="L1"><span class="pln">com</span><span class="pun">.</span><span class="pln">hankcs</span><span class="pun">.</span><span class="pln">word2vec</span><span class="pun">.</span><span class="typ">Train</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">input&nbsp;text8&nbsp;</span><span class="pun">-</span><span class="pln">output&nbsp;vectors</span><span class="pun">.</span><span class="pln">txt&nbsp;</span><span class="pun">-</span><span class="pln">cbow&nbsp;</span><span class="lit">1</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">size&nbsp;</span><span class="lit">200</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">window&nbsp;</span><span class="lit">8</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">negative&nbsp;</span><span class="lit">25</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">hs&nbsp;</span><span class="lit">0</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">sample&nbsp;</span><span class="lit">1e-4</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">threads&nbsp;</span><span class="lit">8</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">binary&nbsp;</span><span class="lit">1</span><span class="pln">&nbsp;</span><span class="pun">-</span><span class="pln">iter&nbsp;</span><span class="lit">15</span></li></ol></pre>
<h3 id="h3-21">训练速度</h3>
<p style="text-indent: 2em;">训练过程中的对比——</p>
<p style="text-indent: 2em;"><span style="text-indent: 2em;">原版C代码</span></p>
<pre class="prettyprint lang-plain linenums"><ol class="linenums"><li class="L0"><span class="typ">Alpha</span><span class="pun">:</span><span class="pln">&nbsp;</span><span class="lit">0.048220</span><span class="pln">&nbsp;&nbsp;</span><span class="typ">Progress</span><span class="pun">:</span><span class="pln">&nbsp;</span><span class="lit">3.56</span><span class="pun">%</span><span class="pln">&nbsp;&nbsp;</span><span class="typ">Words</span><span class="pun">/</span><span class="pln">thread</span><span class="pun">/</span><span class="pln">sec</span><span class="pun">:</span><span class="pln">&nbsp;</span><span class="lit">78.33k</span></li></ol></pre>
<p style="text-indent: 2em;">我的Java移植</p>
<pre class="prettyprint lang-plain linenums"><ol class="linenums"><li class="L0"><span class="typ">Alpha</span><span class="pun">:</span><span class="pln">&nbsp;</span><span class="lit">0.048824</span><span class="pln">&nbsp;&nbsp;</span><span class="typ">Progress</span><span class="pun">:</span><span class="pln">&nbsp;</span><span class="lit">2.39</span><span class="pun">%</span><span class="pln">&nbsp;&nbsp;</span><span class="typ">Words</span><span class="pun">/</span><span class="pln">thread</span><span class="pun">/</span><span class="pln">sec</span><span class="pun">:</span><span class="pln">&nbsp;</span><span class="lit">182.56k</span></li></ol></pre>
<p style="text-indent: 2em;">每个线程每秒训练的词语稳定在180-190K，比原版C程序要快2.5倍左右；训练速度比C程序要快的原因是，原版C程序读取单词后需要去char数组里遍历查找id；而我的Java实现直接读取缓存文件中的id，当然开始训练前要先进行词-&gt;id的转换并输出到缓存文件，这个过程大约多花一两分钟时间，相较于训练时间，无疑是值得的。这样改进之后还可以直接读取类似text8那样的变态语料，一举多得。</p>
<h3 id="h3-22">准确率</h3>
<p style="text-indent: 2em;">由于并没有在算法层找出问题所在，所以准确率依然和<a href="https://github.com/kojisekig/word2vec-lucene" _src="https://github.com/kojisekig/word2vec-lucene" target="_blank" rel="external nofollow" style="text-indent: 32px; white-space: normal;">kojisekig</a>的一样，<a href="https://github.com/kojisekig/word2vec-lucene/issues/21" target="_blank" rel="external nofollow">欢迎围观</a>。</p>
<h2 id="h2-23">Reference</h2>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">《word2vec中的数学原理详解》</span></p>
<p style="text-indent: 2em;"><span style="text-indent: 32px;">《Deep Learning 实战之 word2vec》<br></span></p>
<p style="text-indent: 2em;"></p>
<p class="post-copyright"><a href="http://www.hankcs.com/license/" target="_blank"><img alt="知识共享许可协议" style="border-width: 0px;margin: 0 !important;" src="./word2vec原理推导与代码分析-码农场_files/CC-BY-NC-SA-icon-88x31.png" width="88" height="31" border="0" vspace="0" title="知识共享许可协议" data-tag="bdshare"></a>&nbsp;<a href="http://www.hankcs.com/license/" target="_blank" textvalue="知识共享署名-非商业性使用-相同方式共享">知识共享署名-非商业性使用-相同方式共享</a>：<a href="http://www.hankcs.com/">码农场</a> » <a href="http://www.hankcs.com/nlp/word2vec.html">word2vec原理推导与代码分析</a></p>		</article>
								<div class="action-share bdsharebuttonbox bdshare-button-style0-24" data-bd-bind="1502189424376">
			<span>分享到：</span><a class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a><a class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a><a class="bds_weixin" data-cmd="weixin" title="分享到微信"></a><a class="bds_tqq" data-cmd="tqq" title="分享到腾讯微博"></a><a class="bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a><a class="bds_bdhome" data-cmd="bdhome" title="分享到百度新首页"></a><a class="bds_tqf" data-cmd="tqf" title="分享到腾讯朋友"></a><a class="bds_renren" data-cmd="renren" title="分享到人人网"></a><a class="bds_diandian" data-cmd="diandian" title="分享到点点网"></a><a class="bds_youdao" data-cmd="youdao" title="分享到有道云笔记"></a><a class="bds_ty" data-cmd="ty" title="分享到天涯社区"></a><a class="bds_kaixin001" data-cmd="kaixin001" title="分享到开心网"></a><a class="bds_taobao" data-cmd="taobao"></a><a class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a><a class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a><a class="bds_twi" data-cmd="twi" title="分享到Twitter"></a><a class="bds_mail" data-cmd="mail" title="分享到邮件分享"></a><a class="bds_copy" data-cmd="copy" title="分享到复制网址"></a><a class="bds_more" data-cmd="more">更多</a> <span>(</span><a class="bds_count" data-cmd="count" title="累计分享16次">16</a><span>)</span>		</div>
		<div class="article-tags">继续浏览有关 <a href="http://www.hankcs.com/nlp/"><i class="fa fa-folder-open"></i> 自然语言处理</a> 的文章</div>		<div class="asb asb-post asb-post-02"><script async="" src="./word2vec原理推导与代码分析-码农场_files/adsbygoogle.js.下载"></script>
<!-- 文章页正文下 页首横幅 -->
<ins class="adsbygoogle" style="display: inline-block; width: 728px; height: 0px;" data-ad-client="ca-pub-1152644711996772" data-ad-slot="2657945648" data-adsbygoogle-status="done"><ins id="aswift_1_expand" style="display: inline-table; border: none; height: 0px; margin: 0px; padding: 0px; position: relative; visibility: visible; width: 728px; background-color: transparent;"><ins id="aswift_1_anchor" style="display: block; border: none; height: 0px; margin: 0px; padding: 0px; position: relative; visibility: visible; width: 728px; background-color: transparent; overflow: hidden; opacity: 0;"><iframe width="728" height="90" frameborder="0" marginwidth="0" marginheight="0" vspace="0" hspace="0" allowtransparency="true" scrolling="no" allowfullscreen="true" onload="var i=this.id,s=window.google_iframe_oncopy,H=s&amp;&amp;s.handlers,h=H&amp;&amp;H[i],w=this.contentWindow,d;try{d=w.document}catch(e){}if(h&amp;&amp;d&amp;&amp;(!d.body||!d.body.firstChild)){if(h.call){setTimeout(h,0)}else if(h.match){try{h=s.upd(h,i)}catch(e){}w.location.replace(h)}}" id="aswift_1" name="aswift_1" style="left:0;position:absolute;top:0;width:728px;height:90px;" src="./word2vec原理推导与代码分析-码农场_files/saved_resource(1).html"></iframe></ins></ins></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></div>		<nav class="article-nav">
			<span class="article-nav-prev">上一篇 <a href="http://www.hankcs.com/nlp/new-word-discovery.html" rel="prev">基于信息熵和互信息的新词识别</a></span>
			<span class="article-nav-next"><a href="http://www.hankcs.com/nlp/simplified-traditional-chinese-conversion.html" rel="next">HanLP极致简繁转换</a> 下一篇</span>
		</nav>
				<div class="asb asb-post asb-post-03"><script async="" src="./word2vec原理推导与代码分析-码农场_files/adsbygoogle.js.下载"></script>
<!-- 匹配内容 -->
<ins class="adsbygoogle" style="display: block; height: 466px;" data-ad-client="ca-pub-1152644711996772" data-ad-slot="7343699642" data-ad-format="autorelaxed" data-adsbygoogle-status="done"><ins id="aswift_2_expand" style="display:inline-table;border:none;height:466px;margin:0;padding:0;position:relative;visibility:visible;width:778px;background-color:transparent"><ins id="aswift_2_anchor" style="display:block;border:none;height:466px;margin:0;padding:0;position:relative;visibility:visible;width:778px;background-color:transparent"><iframe width="778" height="466" frameborder="0" marginwidth="0" marginheight="0" vspace="0" hspace="0" allowtransparency="true" scrolling="no" allowfullscreen="true" onload="var i=this.id,s=window.google_iframe_oncopy,H=s&amp;&amp;s.handlers,h=H&amp;&amp;H[i],w=this.contentWindow,d;try{d=w.document}catch(e){}if(h&amp;&amp;d&amp;&amp;(!d.body||!d.body.firstChild)){if(h.call){setTimeout(h,0)}else if(h.match){try{h=s.upd(h,i)}catch(e){}w.location.replace(h)}}" id="aswift_2" name="aswift_2" style="left:0;position:absolute;top:0;width:778px;height:466px;" src="./word2vec原理推导与代码分析-码农场_files/saved_resource(2).html"></iframe></ins></ins></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></div>		<div class="title" id="comments">
	<h3>评论 <b>8</b></h3>
</div>
<div id="respond" class="no_webshot">
		
	<form action="http://www.hankcs.com/wp-comments-post.php" method="post" id="commentform">
		<div class="comt">
			<div class="comt-title">
				<img alt="" data-src="http://0.gravatar.com/avatar/?s=50&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g" srcset="http://0.gravatar.com/avatar/?s=100&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g 2x" class="avatar avatar-50 photo avatar-default" height="50" width="50" src="./word2vec原理推导与代码分析-码农场_files/avatar-default.png">				<p><a id="cancel-comment-reply-link" href="javascript:;">取消</a></p>
			</div>
			<div class="comt-box">
				<textarea placeholder="此处不受理任何开源项目问题，请在GitHub上发issue ，大家一起讨论，谢谢。" class="input-block-level comt-area" name="comment" id="comment" cols="100%" rows="3" tabindex="1" onkeydown="if(event.ctrlKey&amp;&amp;event.keyCode==13){document.getElementById(&#39;submit&#39;).click();return false};"></textarea>
				<div class="comt-ctrl">
					<div class="comt-tips"><input type="hidden" name="comment_post_ID" value="7502" id="comment_post_ID">
<input type="hidden" name="comment_parent" id="comment_parent" value="0">
<p style="display: none;"><input type="hidden" id="akismet_comment_nonce" name="akismet_comment_nonce" value="6df7465bad"></p><label for="comment_mail_notify" class="checkbox inline hide" style="padding-top:0"><input type="checkbox" name="comment_mail_notify" id="comment_mail_notify" value="comment_mail_notify" checked="checked">有人回复时邮件通知我</label><p style="display: none;"></p><div class="comt-tip comt-loading" style="display: none;">评论提交中...</div><div class="comt-tip comt-error" style="display: none;">#</div></div>
					<button type="submit" name="submit" id="submit" tabindex="5">提交评论</button>
					<!-- <span data-type="comment-insert-smilie" class="muted comt-smilie"><i class="icon-thumbs-up icon12"></i> 表情</span> -->
				</div>
			</div>

												<div class="comt-comterinfo" id="comment-author-info">
						<ul>
							<li class="form-inline"><label class="hide" for="author">昵称</label><input class="ipt" type="text" name="author" id="author" value="" tabindex="2" placeholder="昵称"><span class="text-muted">昵称 (必填)</span></li>
							<li class="form-inline"><label class="hide" for="email">邮箱</label><input class="ipt" type="text" name="email" id="email" value="" tabindex="3" placeholder="邮箱"><span class="text-muted">邮箱 (必填)</span></li>
							<li class="form-inline"><label class="hide" for="url">网址</label><input class="ipt" type="text" name="url" id="url" value="" tabindex="4" placeholder="网址"><span class="text-muted">网址</span></li>
						</ul>
					</div>
									</div>

	<input type="hidden" id="ak_js" name="ak_js" value="1502189423629"></form>
	</div>
<div id="postcomments">
	<ol class="commentlist">
		<li class="comment even thread-even depth-1" id="comment-5945"><span class="comt-f">#5</span><div class="comt-avatar"><img alt="" data-src="http://2.gravatar.com/avatar/e0b8c692a631c6f43035bdb1d66dd27b?s=50&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g" srcset="http://2.gravatar.com/avatar/e0b8c692a631c6f43035bdb1d66dd27b?s=100&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g 2x" class="avatar avatar-50 photo" height="50" width="50" src="./word2vec原理推导与代码分析-码农场_files/avatar-default.png"></div><div class="comt-main" id="div-comment-5945"><p>无门槛理解词嵌入体系的知识，for fish.<br>
<a href="http://blog.csdn.net/scotfield_msn/article/details/69075227" rel="nofollow">http://blog.csdn.net/scotfield_msn/article/details/69075227</a></p>
<div class="comt-meta"><span class="comt-author">Scofield</span>2个月前 (06-04)<a rel="nofollow" class="comment-reply-link" href="javascript:;" onclick="return addComment.moveForm( &quot;div-comment-5945&quot;, &quot;5945&quot;, &quot;respond&quot;, &quot;7502&quot; )" aria-label="回复给Scofield">回复</a></div></div></li><!-- #comment-## -->
<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-4387"><span class="comt-f">#4</span><div class="comt-avatar"><img alt="" data-src="http://0.gravatar.com/avatar/?s=50&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g" srcset="http://2.gravatar.com/avatar/?s=100&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g 2x" class="avatar avatar-50 photo avatar-default" height="50" width="50" src="./word2vec原理推导与代码分析-码农场_files/avatar-default.png"></div><div class="comt-main" id="div-comment-4387"><p>ansj也写了个版本，ansj分词还是蛮好用的，不知word2vec如何</p>
<div class="comt-meta"><span class="comt-author"><a href="http://weibo.com/2192516241" rel="external nofollow" class="url" target="_blank">陈裕通Derrick</a></span>10个月前 (10-11)<a rel="nofollow" class="comment-reply-link" href="javascript:;" onclick="return addComment.moveForm( &quot;div-comment-4387&quot;, &quot;4387&quot;, &quot;respond&quot;, &quot;7502&quot; )" aria-label="回复给陈裕通Derrick">回复</a></div></div></li><!-- #comment-## -->
<li class="comment even thread-even depth-1" id="comment-4335"><span class="comt-f">#3</span><div class="comt-avatar"><img alt="" data-src="http://0.gravatar.com/avatar/?s=50&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g" srcset="http://1.gravatar.com/avatar/?s=100&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g 2x" class="avatar avatar-50 photo avatar-default" height="50" width="50" src="./word2vec原理推导与代码分析-码农场_files/avatar-default.png"></div><div class="comt-main" id="div-comment-4335"><p>你好，有空比较一下Spark里的Word2Vec，看看准确度如何。Java代码我用的就是Spark的Word2Vector。性能方面也不比google的代码低。<br>
另外，你的准确度是怎么测量的？</p>
<div class="comt-meta"><span class="comt-author">张华</span>11个月前 (08-30)<a rel="nofollow" class="comment-reply-link" href="javascript:;" onclick="return addComment.moveForm( &quot;div-comment-4335&quot;, &quot;4335&quot;, &quot;respond&quot;, &quot;7502&quot; )" aria-label="回复给张华">回复</a></div></div><ul class="children">
<li class="comment byuser comment-author-hankcs bypostauthor odd alt depth-2" id="comment-4336"><div class="comt-avatar"><img alt="" data-src="http://1.gravatar.com/avatar/de961732ee897fa88c707396fb1d55a4?s=50&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g" srcset="http://1.gravatar.com/avatar/de961732ee897fa88c707396fb1d55a4?s=100&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g 2x" class="avatar avatar-50 photo" height="50" width="50" src="./word2vec原理推导与代码分析-码农场_files/avatar-default.png"></div><div class="comt-main" id="div-comment-4336"><p>谢谢，spark太重量级了。<br>
谷歌原版附带了评测程序和语料</p>
<div class="comt-meta"><span class="comt-author"><a href="http://www.hankcs.com/" rel="external nofollow" class="url" target="_blank">hankcs</a></span>11个月前 (08-30)<a rel="nofollow" class="comment-reply-link" href="javascript:;" onclick="return addComment.moveForm( &quot;div-comment-4336&quot;, &quot;4336&quot;, &quot;respond&quot;, &quot;7502&quot; )" aria-label="回复给hankcs">回复</a></div></div></li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment even thread-odd thread-alt depth-1" id="comment-4323"><span class="comt-f">#2</span><div class="comt-avatar"><img alt="" data-src="http://1.gravatar.com/avatar/?s=50&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g" srcset="http://1.gravatar.com/avatar/?s=100&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g 2x" class="avatar avatar-50 photo avatar-default" height="50" width="50" src="./word2vec原理推导与代码分析-码农场_files/avatar-default.png"></div><div class="comt-main" id="div-comment-4323"><p>&gt;对于Hierarchical Softmax，负例放在二叉树的根节点上。<br>
这个怎么理解呢？</p>
<div class="comt-meta"><span class="comt-author"><a href="http://weibo.com/2358277823" rel="external nofollow" class="url" target="_blank">luckystar少爷</a></span>12个月前 (08-23)<a rel="nofollow" class="comment-reply-link" href="javascript:;" onclick="return addComment.moveForm( &quot;div-comment-4323&quot;, &quot;4323&quot;, &quot;respond&quot;, &quot;7502&quot; )" aria-label="回复给luckystar少爷">回复</a></div></div><ul class="children">
<li class="comment byuser comment-author-hankcs bypostauthor odd alt depth-2" id="comment-4324"><div class="comt-avatar"><img alt="" data-src="http://1.gravatar.com/avatar/de961732ee897fa88c707396fb1d55a4?s=50&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g" srcset="http://1.gravatar.com/avatar/de961732ee897fa88c707396fb1d55a4?s=100&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g 2x" class="avatar avatar-50 photo" height="50" width="50" src="./word2vec原理推导与代码分析-码农场_files/avatar-default.png"></div><div class="comt-main" id="div-comment-4324"><p>我说的不好，我想表达的意思是对于Hierarchical Softmax，除了路径抵达的根节点对应的词语，其他根节点上的词语都是负例。</p>
<div class="comt-meta"><span class="comt-author"><a href="http://www.hankcs.com/" rel="external nofollow" class="url" target="_blank">hankcs</a></span>12个月前 (08-23)<a rel="nofollow" class="comment-reply-link" href="javascript:;" onclick="return addComment.moveForm( &quot;div-comment-4324&quot;, &quot;4324&quot;, &quot;respond&quot;, &quot;7502&quot; )" aria-label="回复给hankcs">回复</a></div></div></li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment even thread-even depth-1" id="comment-4247"><span class="comt-f">#1</span><div class="comt-avatar"><img alt="" data-src="http://0.gravatar.com/avatar/?s=50&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g" srcset="http://2.gravatar.com/avatar/?s=100&amp;d=http%3A%2F%2Fwww.hankcs.com%2Fwp-content%2Fthemes%2Fdux%2Fimg%2Favatar-default.png&amp;r=g 2x" class="avatar avatar-50 photo avatar-default" height="50" width="50" src="./word2vec原理推导与代码分析-码农场_files/avatar-default.png"></div><div class="comt-main" id="div-comment-4247"><p>关注博主中，学习的榜样，最近正在看你的HanLp，也买了一本统计学习方法，学了很多东西。。。</p>
<div class="comt-meta"><span class="comt-author"><a href="http://t.qq.com/shijianjiqi_888" rel="external nofollow" class="url" target="_blank">hcy</a></span>1年前 (2016-07-25)<a rel="nofollow" class="comment-reply-link" href="javascript:;" onclick="return addComment.moveForm( &quot;div-comment-4247&quot;, &quot;4247&quot;, &quot;respond&quot;, &quot;7502&quot; )" aria-label="回复给hcy">回复</a></div></div></li><!-- #comment-## -->
	</ol>
	<div class="pagenav">
			</div>
</div>
	</div>
	</div>
	<aside class="sidebar">
<div class="widget widget_categories affix-top" style="top: 0px;"><h3>栏目分类</h3><label class="screen-reader-text" for="cat">栏目分类</label><select name="cat" id="cat" class="postform">
	<option value="-1">选择分类目录</option>
	<option class="level-0" value="18">ACG&nbsp;&nbsp;(7)</option>
	<option class="level-1" value="117">&nbsp;&nbsp;&nbsp;游戏&nbsp;&nbsp;(5)</option>
	<option class="level-0" value="7">Web开发&nbsp;&nbsp;(80)</option>
	<option class="level-1" value="64">&nbsp;&nbsp;&nbsp;BAE&nbsp;&nbsp;(13)</option>
	<option class="level-1" value="11">&nbsp;&nbsp;&nbsp;Linux相关&nbsp;&nbsp;(9)</option>
	<option class="level-1" value="54">&nbsp;&nbsp;&nbsp;Mac OS&nbsp;&nbsp;(1)</option>
	<option class="level-1" value="27">&nbsp;&nbsp;&nbsp;WordPress&nbsp;&nbsp;(8)</option>
	<option class="level-1" value="65">&nbsp;&nbsp;&nbsp;Yii&nbsp;&nbsp;(17)</option>
	<option class="level-1" value="2">&nbsp;&nbsp;&nbsp;主机域名&nbsp;&nbsp;(26)</option>
	<option class="level-1" value="66">&nbsp;&nbsp;&nbsp;数据库&nbsp;&nbsp;(4)</option>
	<option class="level-0" value="140">信息安全&nbsp;&nbsp;(3)</option>
	<option class="level-0" value="1">其他类别&nbsp;&nbsp;(184)</option>
	<option class="level-1" value="78">&nbsp;&nbsp;&nbsp;心情&nbsp;&nbsp;(1)</option>
	<option class="level-1" value="15">&nbsp;&nbsp;&nbsp;旧的博文&nbsp;&nbsp;(170)</option>
	<option class="level-0" value="87">操作系统&nbsp;&nbsp;(3)</option>
	<option class="level-1" value="88">&nbsp;&nbsp;&nbsp;Windows&nbsp;&nbsp;(2)</option>
	<option class="level-0" value="81">数学基礎&nbsp;&nbsp;(3)</option>
	<option class="level-0" value="4">日语教程&nbsp;&nbsp;(120)</option>
	<option class="level-1" value="96">&nbsp;&nbsp;&nbsp;口译&nbsp;&nbsp;(1)</option>
	<option class="level-1" value="59">&nbsp;&nbsp;&nbsp;新编日语商务贸易会话&nbsp;&nbsp;(14)</option>
	<option class="level-1" value="19">&nbsp;&nbsp;&nbsp;新编日语阅读文选&nbsp;&nbsp;(34)</option>
	<option class="level-2" value="44">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第一册&nbsp;&nbsp;(20)</option>
	<option class="level-2" value="61">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第三册&nbsp;&nbsp;(2)</option>
	<option class="level-2" value="20">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第二册&nbsp;&nbsp;(10)</option>
	<option class="level-1" value="46">&nbsp;&nbsp;&nbsp;日语入门&nbsp;&nbsp;(2)</option>
	<option class="level-1" value="62">&nbsp;&nbsp;&nbsp;日语听力&nbsp;&nbsp;(2)</option>
	<option class="level-1" value="5">&nbsp;&nbsp;&nbsp;日语综合教程&nbsp;&nbsp;(64)</option>
	<option class="level-2" value="120">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第七册&nbsp;&nbsp;(14)</option>
	<option class="level-2" value="50">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第三册&nbsp;&nbsp;(7)</option>
	<option class="level-2" value="73">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第五册&nbsp;&nbsp;(12)</option>
	<option class="level-2" value="98">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第六册&nbsp;&nbsp;(18)</option>
	<option class="level-2" value="6">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第四册&nbsp;&nbsp;(12)</option>
	<option class="level-1" value="86">&nbsp;&nbsp;&nbsp;月の珊瑚&nbsp;&nbsp;(3)</option>
	<option class="level-0" value="131">机器学习&nbsp;&nbsp;(57)</option>
	<option class="level-0" value="16">经济人文&nbsp;&nbsp;(19)</option>
	<option class="level-1" value="17">&nbsp;&nbsp;&nbsp;国际贸易理论与政策&nbsp;&nbsp;(9)</option>
	<option class="level-1" value="30">&nbsp;&nbsp;&nbsp;当代世界经济与政治&nbsp;&nbsp;(3)</option>
	<option class="level-0" value="9">编程开发&nbsp;&nbsp;(556)</option>
	<option class="level-1" value="8">&nbsp;&nbsp;&nbsp;Android&nbsp;&nbsp;(30)</option>
	<option class="level-1" value="13">&nbsp;&nbsp;&nbsp;C++&nbsp;&nbsp;(237)</option>
	<option class="level-1" value="25">&nbsp;&nbsp;&nbsp;Drupal&nbsp;&nbsp;(23)</option>
	<option class="level-1" value="10">&nbsp;&nbsp;&nbsp;Java&nbsp;&nbsp;(69)</option>
	<option class="level-1" value="123">&nbsp;&nbsp;&nbsp;Javascript&nbsp;&nbsp;(1)</option>
	<option class="level-1" value="24">&nbsp;&nbsp;&nbsp;PHP&nbsp;&nbsp;(57)</option>
	<option class="level-1" value="94">&nbsp;&nbsp;&nbsp;Python&nbsp;&nbsp;(8)</option>
	<option class="level-1" value="14">&nbsp;&nbsp;&nbsp;汇编逆向&nbsp;&nbsp;(12)</option>
	<option class="level-1" value="70">&nbsp;&nbsp;&nbsp;算法&nbsp;&nbsp;(235)</option>
	<option class="level-1" value="121">&nbsp;&nbsp;&nbsp;网络&nbsp;&nbsp;(6)</option>
	<option class="level-0" value="104">自然语言处理&nbsp;&nbsp;(90)</option>
	<option class="level-1" value="109">&nbsp;&nbsp;&nbsp;中文分词&nbsp;&nbsp;(10)</option>
	<option class="level-1" value="128">&nbsp;&nbsp;&nbsp;句法分析&nbsp;&nbsp;(6)</option>
	<option class="level-1" value="127">&nbsp;&nbsp;&nbsp;命名实体识别&nbsp;&nbsp;(7)</option>
	<option class="level-1" value="105">&nbsp;&nbsp;&nbsp;语料库&nbsp;&nbsp;(4)</option>
	<option class="level-0" value="12">软件发布&nbsp;&nbsp;(9)</option>
</select>

<script type="text/javascript">
/* <![CDATA[ */
(function() {
	var dropdown = document.getElementById( "cat" );
	function onCatChange() {
		if ( dropdown.options[ dropdown.selectedIndex ].value > 0 ) {
			location.href = "http://www.hankcs.com/?cat=" + dropdown.options[ dropdown.selectedIndex ].value;
		}
	}
	dropdown.onchange = onCatChange;
})();
/* ]]> */
</script>

</div><div class="widget widget_archive" style="top: 0px;"><h3>文章归档</h3>		<label class="screen-reader-text" for="archives-dropdown-5">文章归档</label>
		<select id="archives-dropdown-5" name="archive-dropdown" onchange="document.location.href=this.options[this.selectedIndex].value;">
			
			<option value="">选择月份</option>
				<option value="http://www.hankcs.com/2017/07/"> 2017年七月 &nbsp;(14)</option>
	<option value="http://www.hankcs.com/2017/06/"> 2017年六月 &nbsp;(28)</option>
	<option value="http://www.hankcs.com/2017/05/"> 2017年五月 &nbsp;(8)</option>
	<option value="http://www.hankcs.com/2017/03/"> 2017年三月 &nbsp;(12)</option>
	<option value="http://www.hankcs.com/2017/02/"> 2017年二月 &nbsp;(13)</option>
	<option value="http://www.hankcs.com/2017/01/"> 2017年一月 &nbsp;(22)</option>
	<option value="http://www.hankcs.com/2016/12/"> 2016年十二月 &nbsp;(2)</option>
	<option value="http://www.hankcs.com/2016/11/"> 2016年十一月 &nbsp;(15)</option>
	<option value="http://www.hankcs.com/2016/10/"> 2016年十月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2016/09/"> 2016年九月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2016/08/"> 2016年八月 &nbsp;(7)</option>
	<option value="http://www.hankcs.com/2016/07/"> 2016年七月 &nbsp;(1)</option>
	<option value="http://www.hankcs.com/2016/06/"> 2016年六月 &nbsp;(1)</option>
	<option value="http://www.hankcs.com/2016/05/"> 2016年五月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2016/04/"> 2016年四月 &nbsp;(2)</option>
	<option value="http://www.hankcs.com/2016/03/"> 2016年三月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2016/02/"> 2016年二月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2015/12/"> 2015年十二月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2015/11/"> 2015年十一月 &nbsp;(6)</option>
	<option value="http://www.hankcs.com/2015/10/"> 2015年十月 &nbsp;(4)</option>
	<option value="http://www.hankcs.com/2015/09/"> 2015年九月 &nbsp;(4)</option>
	<option value="http://www.hankcs.com/2015/08/"> 2015年八月 &nbsp;(2)</option>
	<option value="http://www.hankcs.com/2015/07/"> 2015年七月 &nbsp;(6)</option>
	<option value="http://www.hankcs.com/2015/05/"> 2015年五月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2015/04/"> 2015年四月 &nbsp;(5)</option>
	<option value="http://www.hankcs.com/2015/03/"> 2015年三月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2015/02/"> 2015年二月 &nbsp;(22)</option>
	<option value="http://www.hankcs.com/2015/01/"> 2015年一月 &nbsp;(14)</option>
	<option value="http://www.hankcs.com/2014/12/"> 2014年十二月 &nbsp;(10)</option>
	<option value="http://www.hankcs.com/2014/11/"> 2014年十一月 &nbsp;(21)</option>
	<option value="http://www.hankcs.com/2014/10/"> 2014年十月 &nbsp;(14)</option>
	<option value="http://www.hankcs.com/2014/09/"> 2014年九月 &nbsp;(16)</option>
	<option value="http://www.hankcs.com/2014/08/"> 2014年八月 &nbsp;(11)</option>
	<option value="http://www.hankcs.com/2014/07/"> 2014年七月 &nbsp;(6)</option>
	<option value="http://www.hankcs.com/2014/06/"> 2014年六月 &nbsp;(13)</option>
	<option value="http://www.hankcs.com/2014/05/"> 2014年五月 &nbsp;(28)</option>
	<option value="http://www.hankcs.com/2014/04/"> 2014年四月 &nbsp;(41)</option>
	<option value="http://www.hankcs.com/2014/03/"> 2014年三月 &nbsp;(26)</option>
	<option value="http://www.hankcs.com/2014/02/"> 2014年二月 &nbsp;(52)</option>
	<option value="http://www.hankcs.com/2014/01/"> 2014年一月 &nbsp;(28)</option>
	<option value="http://www.hankcs.com/2013/12/"> 2013年十二月 &nbsp;(29)</option>
	<option value="http://www.hankcs.com/2013/11/"> 2013年十一月 &nbsp;(21)</option>
	<option value="http://www.hankcs.com/2013/10/"> 2013年十月 &nbsp;(11)</option>
	<option value="http://www.hankcs.com/2013/09/"> 2013年九月 &nbsp;(19)</option>
	<option value="http://www.hankcs.com/2013/08/"> 2013年八月 &nbsp;(22)</option>
	<option value="http://www.hankcs.com/2013/07/"> 2013年七月 &nbsp;(36)</option>
	<option value="http://www.hankcs.com/2013/06/"> 2013年六月 &nbsp;(24)</option>
	<option value="http://www.hankcs.com/2013/05/"> 2013年五月 &nbsp;(36)</option>
	<option value="http://www.hankcs.com/2013/04/"> 2013年四月 &nbsp;(29)</option>
	<option value="http://www.hankcs.com/2013/03/"> 2013年三月 &nbsp;(46)</option>
	<option value="http://www.hankcs.com/2013/02/"> 2013年二月 &nbsp;(5)</option>
	<option value="http://www.hankcs.com/2012/05/"> 2012年五月 &nbsp;(2)</option>
	<option value="http://www.hankcs.com/2012/04/"> 2012年四月 &nbsp;(6)</option>
	<option value="http://www.hankcs.com/2010/12/"> 2010年十二月 &nbsp;(5)</option>
	<option value="http://www.hankcs.com/2010/11/"> 2010年十一月 &nbsp;(10)</option>
	<option value="http://www.hankcs.com/2010/10/"> 2010年十月 &nbsp;(13)</option>
	<option value="http://www.hankcs.com/2010/09/"> 2010年九月 &nbsp;(6)</option>
	<option value="http://www.hankcs.com/2010/08/"> 2010年八月 &nbsp;(5)</option>
	<option value="http://www.hankcs.com/2010/07/"> 2010年七月 &nbsp;(3)</option>
	<option value="http://www.hankcs.com/2010/06/"> 2010年六月 &nbsp;(12)</option>
	<option value="http://www.hankcs.com/2010/05/"> 2010年五月 &nbsp;(14)</option>
	<option value="http://www.hankcs.com/2010/04/"> 2010年四月 &nbsp;(8)</option>
	<option value="http://www.hankcs.com/2010/03/"> 2010年三月 &nbsp;(16)</option>
	<option value="http://www.hankcs.com/2010/01/"> 2010年一月 &nbsp;(16)</option>
	<option value="http://www.hankcs.com/2009/12/"> 2009年十二月 &nbsp;(33)</option>
	<option value="http://www.hankcs.com/2009/11/"> 2009年十一月 &nbsp;(26)</option>
	<option value="http://www.hankcs.com/2009/09/"> 2009年九月 &nbsp;(2)</option>

		</select>
		</div><div class="widget widget_ui_posts"><h3>热门文章</h3><ul>		<li><a target="_blank" href="http://www.hankcs.com/nlp/hanlp.html"><span class="thumbnail"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645jw1eqkariq2ijj20se0sik3a.jpg" class="thumb" alt="HanLP自然语言处理包开源" title="HanLP自然语言处理包开源"></span><span class="text">HanLP自然语言处理包开源</span><span class="muted">2015-03-27</span><span class="muted">评论(260)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/nlp/chinese-name-recognition-in-actual-hmm-viterbi-role-labeling.html"><span class="thumbnail"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645jw1emfhkq95r4j20iw0gogqc.jpg" class="thumb" alt="实战HMM-Viterbi角色标注中国人名识别" title="实战HMM-Viterbi角色标注中国人名识别"></span><span class="text">实战HMM-Viterbi角色标注中国人名识别</span><span class="muted">2014-09-11</span><span class="muted">评论(54)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/program/java/%e5%8f%8c%e6%95%b0%e7%bb%84trie%e6%a0%91doublearraytriejava%e5%ae%9e%e7%8e%b0.html"><span class="thumbnail"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1eej8x5w4r6j20m00at75g.jpg" class="thumb" alt="双数组Trie树(DoubleArrayTrie)Java实现" title="双数组Trie树(DoubleArrayTrie)Java实现"></span><span class="text">双数组Trie树(DoubleArrayTrie)Java实现</span><span class="muted">2014-03-18</span><span class="muted">评论(52)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/nlp/the-crf-model-format-description.html"><span class="thumbnail"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645jw1en3owz0tqkj20m709cab7.jpg" class="thumb" alt="CRF++模型格式说明" title="CRF++模型格式说明"></span><span class="text">CRF++模型格式说明</span><span class="muted">2014-12-09</span><span class="muted">评论(45)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/nlp/part-of-speech-tagging.html"><span class="thumbnail"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645jw1emgd7fyb3ij20k00f074u.jpg" class="thumb" alt="词性标注" title="词性标注"></span><span class="text">词性标注</span><span class="muted">2014-11-19</span><span class="muted">评论(39)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/nlp/chinese-sentences-svo-java-extraction.html"><span class="thumbnail"><img src="./word2vec原理推导与代码分析-码农场_files/6cbb8645gw1ek372ah95cj20eq0rcdgj.jpg" class="thumb" alt="提取中文句子主谓宾的Java实现" title="提取中文句子主谓宾的Java实现"></span><span class="text">提取中文句子主谓宾的Java实现</span><span class="muted">2014-09-07</span><span class="muted">评论(30)</span></a></li>
</ul></div><div class="widget widget_ui_posts" style="top: 0px;"><h3>最新文章</h3><ul>		<li><a target="_blank" href="http://www.hankcs.com/nlp/cs224n-tackling-the-limits-of-dl-for-nlp.html"><span class="thumbnail"><img src="./word2vec原理推导与代码分析-码农场_files/006Fmjmcly1fhjhnsrsxwj31bc0omqdk.jpg" class="thumb" alt="CS224n笔记18 挑战深度学习与自然语言处理的极限" title="CS224n笔记18 挑战深度学习与自然语言处理的极限"></span><span class="text">CS224n笔记18 挑战深度学习与自然语言处理的极限</span><span class="muted">2017-07-14</span><span class="muted">评论(0)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/nlp/cs224n-neural-turing-machines.html"><span class="thumbnail"><img src="./word2vec原理推导与代码分析-码农场_files/006Fmjmcly1fhjanz14ndj30uk0h6gng.jpg" class="thumb" alt="CS224n研究热点15 Neural Turing Machines" title="CS224n研究热点15 Neural Turing Machines"></span><span class="text">CS224n研究热点15 Neural Turing Machines</span><span class="muted">2017-07-14</span><span class="muted">评论(1)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/nlp/cs224n-nlp-issues-architectures.html"><span class="thumbnail"><img src="./word2vec原理推导与代码分析-码农场_files/006Fmjmcly1fhi3ny7njyj30ri0twwm7.jpg" class="thumb" alt="CS224n笔记17 NLP存在的问题与未来的架构" title="CS224n笔记17 NLP存在的问题与未来的架构"></span><span class="text">CS224n笔记17 NLP存在的问题与未来的架构</span><span class="muted">2017-07-13</span><span class="muted">评论(0)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/nlp/cs224n-compose-nn-for-qa.html"><span class="thumbnail"><img src="./word2vec原理推导与代码分析-码农场_files/006Fmjmcly1fhicdkacepj318a0v8jv4.jpg" class="thumb" alt="CS224n研究热点14 自动组合神经网络做问答系统" title="CS224n研究热点14 自动组合神经网络做问答系统"></span><span class="text">CS224n研究热点14 自动组合神经网络做问答系统</span><span class="muted">2017-07-13</span><span class="muted">评论(0)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/nlp/cs224n-dmn-question-answering.html"><span class="thumbnail"><img src="./word2vec原理推导与代码分析-码农场_files/006Fmjmcly1fhgwvmstwnj313d0fjn4i.jpg" class="thumb" alt="CS224n笔记16 DMN与问答系统" title="CS224n笔记16 DMN与问答系统"></span><span class="text">CS224n笔记16 DMN与问答系统</span><span class="muted">2017-07-12</span><span class="muted">评论(0)</span></a></li>
		<li><a target="_blank" href="http://www.hankcs.com/nlp/cs224n-program-embeddings.html"><span class="thumbnail"><img src="./word2vec原理推导与代码分析-码农场_files/006Fmjmcly1fhh4wad4q8j31bm0vagqi.jpg" class="thumb" alt="CS224n研究热点13 学习代码的语义" title="CS224n研究热点13 学习代码的语义"></span><span class="text">CS224n研究热点13 学习代码的语义</span><span class="muted">2017-07-12</span><span class="muted">评论(0)</span></a></li>
</ul></div><div class="widget widget_text"><h3>订阅关注</h3>			<div class="textwidget"><iframe width="100%" height="400" class="share_self" frameborder="0" scrolling="no" src="./word2vec原理推导与代码分析-码农场_files/index.html"></iframe></div>
		</div><div class="widget widget_ui_tags" style="top: 0px;"><h3>热门标签</h3><div class="d_tags"><a href="http://www.hankcs.com/tag/%e3%80%8a%e6%8c%91%e6%88%98%e7%a8%8b%e5%ba%8f%e8%ae%be%e8%ae%a1%e7%ab%9e%e8%b5%9b%e7%ac%ac2%e7%89%88%e3%80%8b/">《挑战程序设计竞赛(第2版)》 (184)</a><a href="http://www.hankcs.com/tag/%e3%80%8a%e6%97%a5%e8%af%ad%e7%bb%bc%e5%90%88%e6%95%99%e7%a8%8b%e3%80%8b/">《日语综合教程》 (57)</a><a href="http://www.hankcs.com/tag/cs224n/">CS224n (36)</a><a href="http://www.hankcs.com/tag/%e3%80%8a%e6%96%b0%e7%bc%96%e6%97%a5%e8%af%ad%e9%98%85%e8%af%bb%e6%96%87%e9%80%89%e3%80%8b/">《新编日语阅读文选》 (34)</a><a href="http://www.hankcs.com/tag/%e3%80%8a%e6%99%ba%e8%83%bdweb%e7%ae%97%e6%b3%95%e3%80%8b/">《智能Web算法》 (20)</a><a href="http://www.hankcs.com/tag/neural-networks-for-machine-learning/">Neural Networks for Machine Learning (19)</a><a href="http://www.hankcs.com/tag/%e4%b8%ad%e6%96%87%e5%88%86%e8%af%8d/">中文分词 (18)</a><a href="http://www.hankcs.com/tag/wordpress/">WordPress (17)</a><a href="http://www.hankcs.com/tag/%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0/">深度学习 (16)</a><a href="http://www.hankcs.com/tag/lucene/">Lucene (15)</a><a href="http://www.hankcs.com/tag/%e7%bb%b4%e7%89%b9%e6%af%94%e7%ae%97%e6%b3%95/">维特比算法 (15)</a><a href="http://www.hankcs.com/tag/%e6%96%b0%e7%bc%96%e6%97%a5%e8%af%ad%e5%95%86%e5%8a%a1%e8%b4%b8%e6%98%93%e4%bc%9a%e8%af%9d/">新编日语商务贸易会话 (14)</a><a href="http://www.hankcs.com/tag/intellij-idea/">IntelliJ IDEA (13)</a><a href="http://www.hankcs.com/tag/%e3%80%8a%e7%bb%9f%e8%ae%a1%e5%ad%a6%e4%b9%a0%e6%96%b9%e6%b3%95%e3%80%8b/">《统计学习方法》 (12)</a><a href="http://www.hankcs.com/tag/uva/">UVa (11)</a><a href="http://www.hankcs.com/tag/drupal7%e4%b8%93%e4%b8%9a%e5%bc%80%e5%8f%91%e6%8c%87%e5%8d%97-%e7%ac%ac%e4%b8%89%e7%89%88/">Drupal7专业开发指南 第三版 (10)</a><a href="http://www.hankcs.com/tag/%e3%80%8a%e6%8c%91%e6%88%98%e7%bc%96%e7%a8%8b-%e7%a8%8b%e5%ba%8f%e8%ae%be%e8%ae%a1%e7%ab%9e%e8%b5%9b%e8%ae%ad%e7%bb%83%e6%89%8b%e5%86%8c%e3%80%8b/">《挑战编程-程序设计竞赛训练手册》 (10)</a><a href="http://www.hankcs.com/tag/hmm/">HMM (10)</a><a href="http://www.hankcs.com/tag/matlab/">matlab (9)</a><a href="http://www.hankcs.com/tag/tensorflow/">TensorFlow (9)</a><a href="http://www.hankcs.com/tag/cs229/">CS229 (8)</a><a href="http://www.hankcs.com/tag/word2vec/">word2vec (8)</a><a href="http://www.hankcs.com/tag/google-code-jam/">Google code jam (7)</a><a href="http://www.hankcs.com/tag/%e3%80%8ac%e6%a0%87%e5%87%86%e7%a8%8b%e5%ba%8f%e5%ba%93-%e8%87%aa%e4%bf%ae%e6%95%99%e7%a8%8b%e4%b8%8e%e5%8f%82%e8%80%83%e6%89%8b%e5%86%8c%e3%80%8b/">《C++标准程序库—自修教程与参考手册》 (7)</a><a href="http://www.hankcs.com/tag/crf/">CRF (7)</a><a href="http://www.hankcs.com/tag/yii/">Yii (6)</a><a href="http://www.hankcs.com/tag/cnn/">CNN (6)</a><a href="http://www.hankcs.com/tag/webrtc/">WebRTC (5)</a><a href="http://www.hankcs.com/tag/cocos2d-x/">Cocos2d-x (5)</a><a href="http://www.hankcs.com/tag/rnn/">RNN (5)</a></div></div></aside></section>

<div class="branding branding-black">
	<div class="container">
		<h2>我的开源项目</h2>
		<a target="blank" class="btn btn-lg" href="https://github.com/hankcs/HanLP">HanLP自然语言处理包</a><a target="blank" class="btn btn-lg" href="https://github.com/hankcs/AhoCorasickDoubleArrayTrie">基于DoubleArrayTrie的Aho Corasick自动机</a>	</div>
</div>
<footer class="footer">
	<div class="container">
		<div class="fcode">
					</div>
		<p>© 2017 <a href="http://www.hankcs.com/">码农场</a> &nbsp; <a href="http://www.hankcs.com/sitemap.xml">网站地图</a> &nbsp; <a href="http://www.miitbeian.gov.cn/" target="_blank">沪ICP备14002007号-1</a></p>
		<div style="display:none">
<script language="javascript" type="text/javascript" src="./word2vec原理推导与代码分析-码农场_files/trace.js.下载"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-47205472-1', 'auto');
  ga('send', 'pageview');

</script>
<script language="javascript" type="text/javascript" src="./word2vec原理推导与代码分析-码农场_files/15590612.js.下载"></script><a href="http://www.51.la/?15590612" target="_blank" title="51.La 网站流量统计系统"><img alt="51.La 网站流量统计系统" src="./word2vec原理推导与代码分析-码农场_files/icon_2.gif" style="border:none"></a>

<noscript>&lt;a href="//www.51.la/?15590612" target="_blank"&gt;&lt;img alt="&amp;#x6211;&amp;#x8981;&amp;#x5566;&amp;#x514D;&amp;#x8D39;&amp;#x7EDF;&amp;#x8BA1;" src="//img.users.51.la/15590612.asp" style="border:none" /&gt;&lt;/a&gt;</noscript>
</div>	</div>
</footer>

<script>
window.jsui={
    www: 'http://www.hankcs.com',
    uri: 'http://www.hankcs.com/wp-content/themes/dux',
    ver: '1.3',
	roll: ["1","2","6","4"],
    ajaxpager: '500',
    url_rp: 'http://www.hankcs.com/about/'
};
</script>
<script type="text/javascript" src="./word2vec原理推导与代码分析-码农场_files/bootstrap.min.js.下载"></script>
<script type="text/javascript" src="./word2vec原理推导与代码分析-码农场_files/loader.js.下载"></script>
<script type="text/javascript" src="./word2vec原理推导与代码分析-码农场_files/wp-embed.min.js.下载"></script>
<script type="text/javascript" src="./word2vec原理推导与代码分析-码农场_files/form.js.下载"></script>

    <div class="m-mask"></div>    <div class="rollbar" style="display: block;"><ul><li><a href="javascript:(scrollTo());"><i class="fa fa-angle-up"></i></a><h6>去顶部<i></i></h6></li><li><a href="javascript:(on_click_toc_button());"><i class="fa fa-list post_open_icon"></i></a><h6 id="toc_label">打开目录<i></i></h6></li><li><a href="javascript:(scrollTo(&#39;#comments&#39;,-15));"><i class="fa fa-comments"></i></a><h6>去评论<i></i></h6></li></ul></div><ul class="m-navbar">
			<li id="menu-item-1834" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1834"><a href="http://www.hankcs.com/program/cpp/">C++</a></li>
<li id="menu-item-1835" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1835"><a href="http://www.hankcs.com/program/java/">Java</a></li>
<li id="menu-item-5754" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-5754"><a href="http://www.hankcs.com/ml/">机器学习</a></li>
<li id="menu-item-2954" class="menu-item menu-item-type-taxonomy menu-item-object-category current-post-ancestor current-menu-parent current-post-parent menu-item-has-children menu-item-2954"><a href="http://www.hankcs.com/nlp/">NLP</a>
<ul class="sub-menu">
	<li id="menu-item-4344" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-4344"><a href="http://www.hankcs.com/nlp/corpus/">语料库</a></li>
	<li id="menu-item-4342" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-4342"><a href="http://www.hankcs.com/nlp/segment/">中文分词</a></li>
	<li id="menu-item-4343" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-4343"><a href="http://www.hankcs.com/nlp/ner/">命名实体识别</a></li>
	<li id="menu-item-4479" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-4479"><a href="http://www.hankcs.com/nlp/parsing/">句法分析</a></li>
</ul>
</li>
<li id="menu-item-1837" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1837"><a href="http://www.hankcs.com/program/algorithm/">算法</a></li>
<li id="menu-item-1839" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1839"><a href="http://www.hankcs.com/software/">软件</a></li>
<li id="menu-item-1838" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-1838"><a href="http://www.hankcs.com/nihongonote/">日语</a>
<ul class="sub-menu">
	<li id="menu-item-1860" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1860"><a href="http://www.hankcs.com/nihongonote/riyurimen/">日语入门</a></li>
	<li id="menu-item-1861" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1861"><a href="http://www.hankcs.com/nihongonote/listening/">日语听力</a></li>
	<li id="menu-item-1863" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-1863"><a href="http://www.hankcs.com/nihongonote/tekusuto/">日语综合教程</a>
	<ul class="sub-menu">
		<li id="menu-item-2190" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2190"><a href="http://www.hankcs.com/nihongonote/tekusuto/disance/">第三册</a></li>
		<li id="menu-item-2192" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2192"><a href="http://www.hankcs.com/nihongonote/tekusuto/daiyonnsatu/">第四册</a></li>
		<li id="menu-item-2191" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2191"><a href="http://www.hankcs.com/nihongonote/tekusuto/5/">第五册</a></li>
		<li id="menu-item-2702" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2702"><a href="http://www.hankcs.com/nihongonote/tekusuto/%e7%ac%ac%e5%85%ad%e5%86%8c/">第六册</a></li>
		<li id="menu-item-3604" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3604"><a href="http://www.hankcs.com/nihongonote/tekusuto/%e7%ac%ac%e4%b8%83%e5%86%8c/">第七册</a></li>
	</ul>
</li>
	<li id="menu-item-1859" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-1859"><a href="http://www.hankcs.com/nihongonote/fd2/">新编日语阅读文选</a>
	<ul class="sub-menu">
		<li id="menu-item-2187" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2187"><a href="http://www.hankcs.com/nihongonote/fd2/c1/">第一册</a></li>
		<li id="menu-item-2189" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2189"><a href="http://www.hankcs.com/nihongonote/fd2/c2/">第二册</a></li>
		<li id="menu-item-2188" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-2188"><a href="http://www.hankcs.com/nihongonote/fd2/c3/">第三册</a></li>
	</ul>
</li>
	<li id="menu-item-1858" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-1858"><a href="http://www.hankcs.com/nihongonote/jpkaiwa/">日语商务贸易会话</a></li>
</ul>
</li>
<li id="menu-item-1843" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1843"><a href="http://www.hankcs.com/about/">关于</a></li>
							<li class="navto-search"><a href="javascript:;" class="search-show active"><i class="fa fa-search"></i></a></li>
					</ul>			<div class="sign">			    <div class="sign-mask"></div>			    <div class="container">			        <a href="http://www.hankcs.com/nlp/word2vec.html#" class="close-link signclose-loader"><i class="fa fa-close"></i></a>			        <div class="sign-tips"></div>			        <form id="sign-in">  			            <h3><small class="signup-loader">切换注册</small>登录</h3>			            <h6>			                <label for="inputEmail">用户名或邮箱</label>			                <input type="text" name="username" class="form-control" id="inputEmail" placeholder="用户名或邮箱">			            </h6>			            <h6>			                <label for="inputPassword">密码</label>			                <input type="password" name="password" class="form-control" id="inputPassword" placeholder="登录密码">			            </h6>			            <div class="sign-submit">			                <input type="button" class="btn btn-primary signsubmit-loader" name="submit" value="登录">  			                <input type="hidden" name="action" value="signin">			                <label><input type="checkbox" checked="checked" name="remember" value="forever">记住我</label>			            </div><div class="sign-info"><a href="http://www.hankcs.com/about/">找回密码？</a></div></form>			        <form id="sign-up"> 			            <h3><small class="signin-loader">切换登录</small>注册</h3>			            <h6>			                <label for="inputName">昵称</label>			                <input type="text" name="name" class="form-control" id="inputName" placeholder="设置昵称">			            </h6>			            <h6>			                <label for="inputEmail">邮箱</label>			                <input type="email" name="email" class="form-control" id="inputEmail" placeholder="邮箱">			            </h6>			            <div class="sign-submit">			                <input type="button" class="btn btn-primary btn-block signsubmit-loader" name="submit" value="快速注册">  			                <input type="hidden" name="action" value="signup">  			            </div>			        </form>			    </div>			</div>		</body></html>